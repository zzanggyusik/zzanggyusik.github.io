---
title:  "[Paper Review] A Challenge Dataset and Effective Models for Aspect-Based Sentiment Analysis"
excerpt: "ABSA 논문 리뷰"
toc: true
toc_label: "Capstone"
toc_sticky: true
published: true

categories:
  - Paper Review
tags:
  - Aspect Based Sentiment Analysis
last_modified_at: 2022-03-25


---

> [A Challenge Dataset and Effective Models for Aspect-Based Sentiment Analysis (2019)](https://aclanthology.org/D19-1654.pdf)를 읽고 작성한 포스팅입니다.

<br>

### 1. Introduction

Aspect-based sentiment analysis(이하 ABSA)는 문장의 특정 측면(specific aspect)에서의 감정 극성을 식별하는 것을 목적으로 한다.

예를 들어 *"The decor is not special at all but their amazing food makes up for it"* 라는 문장이 있을 때, decor와 food는 각각 부정적인 감정과 긍정적인 감정과 연관되어 있는 aspect이다.

ABSA는 이렇게 aspect를 검출하고(aspect-category sentiment analysis, ACSA), 해당 측면에 대한 opinion을 추출(aspect-term sentiment analysis, ATSA)해낸다. 이 때 aspect는 단어 혹은 구가 될 수 있다.

<br>

저자는 기존의 ABSA 데이터 세트가 하나의 감성 극성을 갖거나 또는 여러개여도 동일한 감성 극성을 갖고 있어서, 문장 수준의 감정 분석밖에 되지 않는다고 한다.

<br>

아래는 ABSA 데이터 세트로 유명한 [SemEval-2015 Task 12](https://alt.qcri.org/semeval2015/task12/index.php?id=data-and-tools) 데이터 셋에 포함된 리뷰인데, 저자가 말한 것처럼 "The food was lousy", "too sweet or too salty and the portions tiny"라는 두 개의 aspect-opinion 쌍으로 구성돼 있지만 모두 동일한 감성이다.

```xml
<sentence id="1004293:3">
  <text>The food was lousy - too sweet or too salty and the portions tiny.</text>
  <Opinions>
    <Opinion target="food" category="FOOD#QUALITY" polarity="negative" from="4" to="8"/>
    <Opinion target="portions" category="FOOD#STYLE_OPTIONS" polarity="negative" from="52" to="60"/>
  </Opinions>
</sentence>
```

이렇게 동일 감정으로 구성된 데이터 셋은 단순 ABSA를 sentiment analysis로 퇴보시켜 여러 개의 aspect와 감정이 포함된 문장에서 감정 양극성을 구별하지 못한다는게 저자의 주장이다.

<p align = "center">
  <img src = "https://user-images.githubusercontent.com/76269316/160133934-c5724b84-b2b5-4b3e-81f9-7cad8b5009d8.png">
</p>
<p align = "center">
  sentiment analysis 데이터셋 (출처:https://wikidocs.net/44249)
</p>

<br>

<p align = "center">
  <img src = "https://user-images.githubusercontent.com/76269316/160220581-f164bc99-2bff-47c2-8e84-d5eb6beb3cb3.png">
</p>
<p align = "center">
  기존 ABSA 데이터 세트의 통계(MM_size는 multi-aspect, multi-sentiment 인스턴스 수를 의미)
</p>

<br>

그래서 저자는 직접 데이터 세트를 만들었다. [MAMS(Multi-Aspect Multi-Sentiment)](https://github.com/siat-nlp/MAMS-for-ABSA) 저자 깃허브에서 확인할 수 있다.

데이터 세트는 적어도 두 개의 다른 측면(aspect), 감정 극성(sentiment polarities)을 갖는 문장으로 구성했다고 한다.

최신 ABSA 방법을 사용해 평가한 결과 기존 ABSA 데이터 세트보다 저조한 결과가 나왔다고 한다. (MAMS 데이터 셋이 더 어렵다는 얘기)

이에 저자는 새로운 캡슐 네트워크(CapsNet, CapsNet-BERT로 표기)를 제안해 최신 NLP 기법의 강점을 결합한 결과 MAMS 및 SemEval-14 레스토랑 데이터 세트에 대해 훨씬 좋은 결과를 얻었다고 한다.

<br><br>

### 2. Dataset Construction

데이터셋은 Citysearch New York 데이터 셋의 말뭉치를 몇 개의 문장으로 분할한 뒤, 직접 주석을 달았다고 한다.

<br>

##### Dataset Annotation

Aspect sentiment analysis는 크게 두 개의 task로 나뉘는데

먼저 문장에서 카테고리(aspect)에 해당하는 내용을 감지하는 aspect-category sentiment analysis(ACSA), 이후 해당 카테고리(aspect)의 감정 분석을 실시하는 aspect-term sentiment analysis(ASTA)가 있다.

<br>

**Aspect-term sentiment analysis**

저자는 ATSA 데이터 셋을 만들기 위해 자연어 처리에 종사하는 3명의 연구자를 초빙해 문장에서 aspect를 추출하고 해당 term에 대한 감정 극성을 annotation 했다고 한다. 그리고 아래와 같이 from-to로 해당 aspect term에 대한 시작 위치와 끝 위치를 표시했다.

```xml
<?xml version="1.0" encoding="utf-8"?>
<sentences>
	<sentence>
		<text>The decor is not special at all but their food and amazing prices make up for it.</text>
		<aspectTerms>
			<aspectTerm from="4" polarity="negative" term="decor" to="9"/>
			<aspectTerm from="42" polarity="positive" term="food" to="46"/>
			<aspectTerm from="59" polarity="positive" term="prices" to="65"/>
		</aspectTerms>
	</sentence>
  <sentence>
```

<br>

**Aspect-category sentiment analysis**

ACSA에서는 8개(음식, 서비스, 종업원, 가격, 분위기, 메뉴, 장소, 잡동사니)의 카테고리를 미리 정의해 aspect category에 대한 감정 극성을 라벨링했다.

```xml
<?xml version="1.0" encoding="utf-8"?>
<sentences>
	<sentence>
		<text>It might be the best sit down food I've had in the area, so if you are going to the upright citizen brigade, or the garden, it could be just the place for you.</text>
		<aspectCategories>
			<aspectCategory category="food" polarity="positive"/>
			<aspectCategory category="place" polarity="neutral"/>
		</aspectCategories>
	</sentence>
	<sentence>
```

ASTA, ASCA 모두 최소 2개의 서로 다른 감정 극성을 가진  문장들로만 구성됐다.

<br>

```xml
    <sentences>
      <sentence id="37:0">
         <text>Such a beautiful place</text>
    <Opinions>
          <Opinion target="place" category="AMBIENCE#GENERAL" polarity="positive" from="7" to="15"/>
          </Opinions>
      </sentence>
    </sentences>
```

<br>

MAMS 데이터 셋의 모든 문장은 감정 극성이 다른 multi aspect를 갖고 있지만 Restaurant, Laptop, Twitter 데이터 셋은 각각 26.58%, 9.58%, 20.05%만 multi-aspect multi-sentiment 인스턴스를 갖고 있으므로 공정한 비교를 위해  레스토랑 데이터 셋의 개수와 동일한 MAMS-small 데이터 셋도 만들었다고 합니다.

<br><br>

### 3. Methodology

<p align = "center">
  <img src = "https://user-images.githubusercontent.com/76269316/160223592-e79385ad-7240-4f34-9b6c-760806e59c12.png">
</p>
<p align = "center">
  모델의 구조
</p>

<br>

##### 3.1 Embedding Layer

embedding layer에서는 문장 S를 단어 임베딩 E로 변환한다.

ACSA(Aspect-category sentiment analysis) task의 경우 aspect category 임베딩 a가 랜덤하게 초기화 및 학습하게 되고,

ATSA(Aspect-term sentiment analysis) task는 aspect 단어 임베딩의 average pooling으로 aspect 임베딩 a가 계산된다.

<p align = "center">
  <img src = "https://user-images.githubusercontent.com/76269316/160223818-5408dbb3-6d6a-4646-afbc-16ab6894ae88.png">
</p>
<p align = "center">
  Average Pooling (출처:https://paperswithcode.com/method/average-pooling)
</p>

이 aspect 임베딩 a를 연결함으로써 aspect-aware 문장 임베딩 <img width="42" alt="스크린샷 2022-03-26 오후 1 01 17" src="https://user-images.githubusercontent.com/76269316/160223991-2862fa3e-ca5b-494a-8c9a-8b1a0e44938e.png">를 얻게된다.

<br>

##### 3.2 Encoding Layer

encoding layer에서는 <img width="42" alt="스크린샷 2022-03-26 오후 1 01 17" src="https://user-images.githubusercontent.com/76269316/160223991-2862fa3e-ca5b-494a-8c9a-8b1a0e44938e.png">를 bidirectional gated recurrent unit(BiGRU)과 residual connection을 통해 contextualized representation(문맥적 표현?)인 H로 변환한다.

![스크린샷 2022-03-26 오후 1 07 38](/Users/seominseok/Library/CloudStorage/OneDrive-한밭대학교/2.깃허브/Capstone/160224153-737d87eb-fa5f-44aa-ad98-6e1065753538.png)

문맥적 의미를 갖는 임베딩으로 만드는 과정인 것 같다.

<br>

##### 3.3 Primary Capsule Layer

primary capsule layer에서는 선형 변환과 squashing 활성 함수를 통해 primary capsule P를 얻는다.

![스크린샷 2022-03-26 오후 2 31 58](https://user-images.githubusercontent.com/76269316/160226260-c25989b4-3be6-4b57-929d-b87d5bcaa684.png)

<img width="140" alt="스크린샷 2022-03-26 오후 2 33 16" src="https://user-images.githubusercontent.com/76269316/160226294-6bd1f718-863f-4ddd-ad7e-c1057204fe18.png">는 모두 선형 파라미터이다.

squash 함수는 다음과 같이 정의된다.

![스크린샷 2022-03-26 오후 2 33 55](https://user-images.githubusercontent.com/76269316/160226313-c33f6bb5-9124-4fa7-85c9-86ec860b0d18.png)

<br>

**Aspect Aware Normalization**

문장 길이가 다양하기 때문에, 문장마다 상층 캡슐(upper layer capsules)로 보내지는 초기 캡슐(primary capsules)의 수가 달라서 훈련 절차가 불안정하다.

매우 긴 문장은 squash activation을 포화시켜 모든 카테고리에서 높은 신뢰도를 갖지만, 매우 짧은 문장은 모든 카테고리에서 낮은 신뢰도를 얻게 된다.

이러한 문제를 완화하기 위해 저자는 aspect capsule을 사용하는 aspect aware normalization을 제안했다.

 aspect aware normalization은 중요한 초기 캡슐을 선택해 weight u를 아래 식으로 정규화 한다. 이 때 <img width="34" alt="스크린샷 2022-03-26 오후 2 46 39" src="https://user-images.githubusercontent.com/76269316/160226650-583a1e99-9530-4d51-b159-77fe7b445c95.png">은 학습 파라미터로 훈련 중에 조절되는 파라미터이다.

![스크린샷 2022-03-26 오후 2 47 10](https://user-images.githubusercontent.com/76269316/160226665-f876a244-f62f-4855-b32b-85726296a674.png)

<br>

**Capsule Guided Routing**

저자는 기존 동적 라우팅 메커니즘은 라우팅의 반복적인 절차로 인해 비효율적이고, 라우팅 프로세스를 가이드하기 위해 사용되는 상위 레이어 정보가 없으므로 self-directed process와 동일하게 동작한다고 한다.

그래서 라우팅 절차를 효과적이고 효율적으로 안내하는 캡슐 유도 라우팅 메커니즘(capsule-guided routing mechanism)을 설계했다고 한다. 

캡슐 유도 라우팅 메커니즘은 초기 캡슐과 카테고리 캡슐 간 결합 계수를 계산하는 대신, 감성 카테고리에 대한 사전 지식을 활용한다고 한다. 이 때 감성 카테고리에 대한 사전 지식을 저장하기 위해 감성 캡슐 세트를 사용한다.

<br>

감성 행렬 <img width="98" alt="스크린샷 2022-03-26 오후 7 24 24" src="https://user-images.githubusercontent.com/76269316/160235322-0edb404f-012a-48f4-859a-046798ced708.png">은 감성 단어 임베딩의 평균으로 초기화 된다. (C는 감정 카테고리의 수, d는 감성 임베딩의 차원 수)

감성 행렬에 squash 활성 함수를 적용해  감성 캡슐(<img width="177" alt="스크린샷 2022-03-26 오후 7 31 19" src="https://user-images.githubusercontent.com/76269316/160235555-7e0d7d89-ed05-48fd-8cb0-a4cfebe49727.png">)을 얻을 수 있고, 초기 캡슐과 감성 캡슐의 유사도를 계산해 w(라우팅의 weights )를 계산한다.

식은 다음과 같다.

![스크린샷 2022-03-26 오후 7 32 33](https://user-images.githubusercontent.com/76269316/160235592-6a5578e7-9e47-4834-838f-8e2a36f9afd0.png)

<br>

##### 3.4 Category Capsule Layer

정규화한 초기 캡슐 weights(u)와 라우팅 weights(w)에 기초해 최종 카테고리 캡슐(<img width="185" alt="스크린샷 2022-03-26 오후 7 38 31" src="https://user-images.githubusercontent.com/76269316/160235761-3a33800a-b5ad-4d72-83b7-d9a42085be6a.png">)을 계산할 수 있다. 식은 다음과 같다.

![스크린샷 2022-03-26 오후 7 39 01](https://user-images.githubusercontent.com/76269316/160235781-76bd978d-cfba-4a96-ba24-402e3ebfe858.png)

s는 connection weight를 적정 수준으로 스케일링 하기 위한 학습 파라미터이다.

<br>

측면 기반 분류를 위한 손실 함수로 마진 손실을 사용한다. 

<img width="604" alt="스크린샷 2022-03-26 오후 7 51 02" src="https://user-images.githubusercontent.com/76269316/160236178-8e444c29-d2b9-4f8f-827a-a19f85027386.png">

카테고리 k가 존재하는 경우만 <img width="38" alt="스크린샷 2022-03-26 오후 7 51 38" src="https://user-images.githubusercontent.com/76269316/160236195-0b02e305-a12f-4b50-a817-42386839a2fb.png" style="zoom:67%;" > =1이 되고, <img width="64" alt="스크린샷 2022-03-26 오후 7 53 25" src="https://user-images.githubusercontent.com/76269316/160236266-72ca64a5-033c-4c90-bec9-9ca7359c02e1.png">는 마진 하이퍼 파라미터이다.

<img width="29" alt="스크린샷 2022-03-26 오후 7 54 26" src="https://user-images.githubusercontent.com/76269316/160236289-5e65a2de-cedf-4e02-9420-510bb7735276.png">는 카테고리가 없을 때의 손실을 관리한다. 실험에서는 <img width="45" alt="스크린샷 2022-03-26 오후 7 55 35" src="https://user-images.githubusercontent.com/76269316/160236316-f0d2b295-da5f-4b59-bd47-417914616327.png"> = 0.9, <img width="44" alt="스크린샷 2022-03-26 오후 7 55 44" src="https://user-images.githubusercontent.com/76269316/160236322-f5cffcba-4cf1-436c-adf9-c904ada7abc4.png"> = 0.1, <img width="34" alt="스크린샷 2022-03-26 오후 7 55 57" src="https://user-images.githubusercontent.com/76269316/160236335-00285f38-9f1f-4745-b127-78fb8a50ea21.png"> = 0.6으로 설정했다.

<br>

##### 3.5 CapsNet-BERT

저자는 대규모 말뭉치에서 학습한 피처를 활용하기 위해 BERT와 캡슐 네트워크의 강점을 결합한 CapsNet-BERT 모델을 설계했다.

CapsNet의 임베딩 레이어와 인코딩 레이어를 pre-trained된 BERT로 대체했다.

CapsNet-BERT 모델은 입력으로 "[CLS] sentence [SEP] aspect [SEP]"을 사용하며, pre-trained BERT를 사용해 문장과 측면의 심층 표현(deep representations)을 계산한 다음, 문장과 측면의 심층 표현을 캡슐 레이어로 공급해 그에 상응하는 감정 극성을 예측한다.

<br><br>

### 4. Experiments

**Experimental Data**

실험에는 두 개의 MAMS 데이터 셋(MAMS, MAMS-small)과 SetEval-14 Restaurant Review 데이터 셋을 사용했고, 모두 같은 전처리 과정과 같은 pre-trained 단어 임베딩을 사용했다고 합니다.

<br>

**Implementation Details**

단어 임베딩은 Glove에서 pre-trained한 300차원 단어 벡터를 사용했고, 캡슐 크기는 300으로 설정했다.

배치 사이즈는 CapsNet은 64, CapsNet-BERT는 32를 학습률은 CapsNet 0.0003, CapsNet-BERT는 0.00003을 사용했다.

optimizer는 adam을 사용했다고 한다.

테스트 셋을 다섯번씩 실행한 뒤 대한 결과를 평균해 계산했고, 파라미터 fine-tuning은 검증 데이터셋으로 했다고 한다.

<br>

**Baseline Methods**

저자는 캡슐 네트워크와 BERT의 결합 효과를 검증하기 위해 아래 모델들과 비교해 봤습니다.

<p align = "center">
  <img src = "https://user-images.githubusercontent.com/76269316/160236810-ed561570-e321-44ef-bc72-77b5505be985.png">
</p>
<p align = "center">
  모델별 성능 비교 결과
</p>

<br>

**Experimental Results and Analysis**

실험 결과를 보면 문장 수준 감성 분류기 (TextCNN, LSTM)은 SemEval-14 Restaurant Review 데이터 셋에서는 준수한 결과를 보이지만 MAMS 데이터 셋에서는 크게 성능이 떨어지는 것을 볼 수 있다.

저자는 이를 통해 MAMS 데이터 셋이 레스토랑 데이터 세트에서 발생하는 문제 (문장 수준 감성 분류로 떨어지는 것)를 완화할 수 있다고 합니다.

또한 어순을 효과적으로 모델링하지 않는 attention based model은 어순 정보를 잃어버리고, 주어진 측면을 설명할 문맥 부분을 특정할 수 없기 때문에 최악의 성능을 보이는 것을 확인할 수 있습니다.

CapsNet은 6개 중 4개의 데이터 셋에서 BERT를 제외한 모델들 중 가장 높은 성능을 보여줬기에 측면 기반 감정 분석에 적용할 수 있다는 가능성을 보여줍니다.

CapsNet-BERT는 모든 모델 중 가장 우수한 성능을 보여 CapsNet과 BERT의 결합이 추가적인 개선을 얻을 수 있다는 것을 확인했습니다.

추가적으로 캡슐 유도 라우팅(capsule-guided routing)이 동적 라우팅(dynamic-routing)보다 효과적인 것도 확인할 수 있습니다. (표 마지막 두 줄)

<br><br>

### Conclusion

MAMS 데이터 세트는 한 문장에 서로 다른 감정 극성을 가진 여러 측면을 포함함으로써, 측면 기반 감정 분석이 문장 수준 감정 분류로 전락하는 것을 방지했습니다. 또한 캡슐 네트워크와 BERT를 결합한 모델을 만들어 기존 모델들보다 높은 성능을 입증했습니다.

