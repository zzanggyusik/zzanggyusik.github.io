---
title:  "[Capstone] Attention Mechanism"
excerpt: "어텐션 메커니즘 설명"
toc: true
toc_label: "Attention Mechanism"
toc_sticky: true
published: true

categories:
  - Capstone
tags:
  - PyTorch
last_modified_at: 2022-05-05

---

> [위키독스 - 어텐션 메커니즘](https://wikidocs.net/22893)를 참고하여 작성한 내용입니다.

<br>

어텐션 메커니즘을 이해하기 위해선 먼저 seq2seq에 대해 알아야하기 때문에 seq2seq가 무엇인지 먼저 설명하도록 하겠습니다.

### Sequence to Sequence

seq2seq 모델은 입력된 시퀀스로부터 다른 도메인의 시퀀스를 출력하는 모델입니다.

한글 문장을 입력하면, 출력으로 영어로 번역된 문장이 나오는 기계 번역(machine translation), 또는 사용자가 채팅을 입력하면 이에 해당하는 답변이 나오는 챗봇(chatbot)이 대표적인 예시입니다.

아래 그림은 seq2seq 모델을 간략하게 표현한 것입니다.

<img width="628" alt="스크린샷 2022-05-05 오후 4 00 41" src="https://user-images.githubusercontent.com/76269316/166875969-5f5dbbe6-aa5e-4452-95f7-f6c2324d889d.png" style="zoom: 67%;" >

영어를 한국어로 번역하는 모델이라고 할 때, 먼저 영어 문장을 단어로 쪼갠 뒤, 인코더에서 해당 단어들의 모든 정보를 압축해서 context vector(그림에서 초록색 네모)로 만듧니다.

이후 디코더에서 context vecotr를 받아 한국어 단어를 하나씩 출력합니다.

<br>

인코더, 디코더는 실제로는 두 개의 RNN 아키텍처입니다. 입력 문장을 받는 RNN 셀을 인코더, 출력 문장을 출력하는 RNN 셀을 디코더라고 합니다. 이 때 각 셀은 LSTM 셀 또는 GRU 셀로 구성됩니다. (그림에서는 LSTM 셀로 표현했습니다)

<img width="1315" alt="스크린샷 2022-05-05 오후 4 06 31" src="https://user-images.githubusercontent.com/76269316/166876565-c5232d9e-7534-4548-bf12-f23b6a8074ff.png" style="zoom: 67%;" >

<br>

먼저 입력 문장을 받아 context vector를 만드는 과정을 살펴보겠습니다. 아래 그림은 인코더에서의 전체적인 진행 흐름도입니다.

<img width="735" alt="스크린샷 2022-05-05 오후 4 13 11" src="https://user-images.githubusercontent.com/76269316/166877362-22422b18-8a9a-4c4a-b097-cacb28fa6df8.png" style="zoom: 67%;" >

하나의 셀에서 어떤 식으로 처리하는지 보겠습니다.

첫 번째 셀에서 I를 입력받은 뒤 am을 입력 받을 때, 

현재 시점(time step)을 t라고하면 RNN 셀은 이전 시점(t-1)에서의 은닉 상태와 t에서의 입력 벡터(am의 단어 임베딩)를 입력 받아 t에서의 은닉 상태를 만듧니다.

<img width="459" alt="스크린샷 2022-05-05 오후 4 27 11" src="https://user-images.githubusercontent.com/76269316/166879041-ad60a0dd-18a5-4a89-bfde-1a9f12c015f6.png" style="zoom:67%;" >

t에서의 은닉 상태는 t+1에서 입력 벡터와 함께 t+1에서의 은닉 상태를 만듧니다.

RNN 셀에서의 은닉 상태는 이렇게 생성되기 때문에 이전 모든 셀에서의 은닉 상태 값을 누적해서 받아온 값이라고 볼 수 있습니다. 결국 인코더의 마지막 RNN 셀에서의 은닉 상태값은 입력 문장의 모든 단어 토큰들의 정보를 요약해서 담고 있다고 할 수 있습니다.

인코더에서의 마지막 은닉 상태 벡터를 context 벡터라고 하고, 이를 디코더의 첫번째 RNN 셀의 입력으로 넣어줍니다.

<br>

<img width="315" alt="스크린샷 2022-05-05 오후 4 26 57" src="https://user-images.githubusercontent.com/76269316/166879000-d629390d-20d8-461d-b23a-7925138e40ce.png" style="zoom:67%;" >

디코더의 첫번째 RNN 셀을 보면, 인코더의 마지막 셀에서 만든 은닉 상태 벡터(context 벡터)와 문장의 시작을 의미하는 심볼 \<sos>를 입력받아 다음에 등장할 확률이 높은 단어를 예측합니다. '나는'을 등장확률이 가장 높은 단어로 예측한 경우, 예측한 단어를 다음 셀의 입력으로 넣고 또 그 다음 단어를 예측합니다.

이를 반복하다가 문장의 끝을 나타내는 \<eos>이 나올 경우 예측을 종료합니다.

<img width="864" alt="스크린샷 2022-05-05 오후 4 33 03" src="https://user-images.githubusercontent.com/76269316/166879778-1cf8ff11-1328-444c-a2d6-8eb7fbab1c19.png" style="zoom:67%;" >

❗️이는 테스트 과정에서의 동작 방식이고, 실제 훈련 과정에서의 동작 방식은 조금 다릅니다.

예측 단어를 다음 셀의 입력으로 넣어준다고 했는데, 그렇게 할 경우 중간에 한 단어를 잘못 예측하면 연쇄 작용으로 이후의 단어들도 잘못 예측할 가능성이 높아집니다. 이런 상황이 반복되게 되면 훈련 시간도 오래 걸리고 성능도 좋지 않게 됩니다.

이를 방지하기 위해 **Teacher Forcing**이라는 훈련 방식을 사용합니다.

Teacher forcing은 이전 셀에서 예측을 잘못하더라도, 다음 셀에는 실제 정답 단어를 입력시키는 방식으로, 이를 이용하면 모델을 제대로 학습 시킬 수 있게 됩니다.

<br>

개념적으로 봤을 때 seq2seq 모델은 입력 문장의 정보를 가지고 출력 문장을 계산하므로, 합리적인 방식인 것 같지만 크게 두 가지 문제점이 있습니다.

첫번째는 고정된 크기의 context 벡터에 모든 정보를 압축하다보니 정보의 손실이 발생한다는 점입니다.

두번째는 RNN 구조의 문제점이라고도 할 수 있는 gradient vanishing입니다. 이전 셀의 은닉 상태를 계속 곱하는 방식이기 때문에 backpropagation 과정에서 gradient 값이 사라지는 문제가 빈번하게 발생합니다.

이 두 가지 문제점으로 인해 입력 문장이 길어질수록 성능이 떨어지게 됩니다.

<br>

이를 개선하기 위해 등장한 것이 Attention Mechanism입니다.

### Attention Mechanism

앞서 seq2seq 모델의 경우 context vector를 디코더의 첫번째 셀의 입력으로 사용했습니다. (매시점마다 사용하는 seq2seq 모델도 있습니다)

어텐션의 기본 아이디어는 디코더에서 단어를 예측하는 매시점마다 입력 문장을 참고한다는 점입니다. 이 때 모든 단어를 참고하는게 아닌, 해당 시점에서 예측해야 할 단어와 연관이 있는 입력 단어 부분을 집중(attention)해서 봅니다.

<br>

<img width="1213" alt="스크린샷 2022-05-05 오후 6 53 07" src="https://user-images.githubusercontent.com/76269316/166900568-5ce6b89b-755d-488f-b887-cbfde19ae8c6.png" style="zoom:67%;" >

위 그림은 디코더의 세번째 LSTM 셀에서 출력 단어를 예측할 때, 어텐션 메커니즘을 사용하는 모습입니다.

출력 단어를 예측하기 위해 인코더의 모든 입력 단어 정보를 확인하는데, 이 때 인코더의 각 입력 단어별로 디코더의 예측에 도움이 되는 정도를 수치화해 이를 하나의 정보(오른쪽 위의 주황색 원)로 사용합니다. 이 과정에 대해선 밑에서 자세히 설명하도록 하겠습니다.

➕ 어텐션에도 다양한 종류가 있는데, 그 중 Dot-Product Attention를 기준으로 설명하겠습니다. (다른 어텐션과 메커니즘 자체는 유사하며, 중간의 수식만 차이가 있습니다)

<br>

앞서 디코더에서 다음 단어를 예측하기 위해 어텐션 메커니즘을 사용할 때, 예측에 도움이 되는 정도를 수치화한 다음, 이를 하나의 정보로 합친 값을 사용한다고 했는데 이 값이 **attention value**입니다.

어텐션 스코어를 구하는 과정은 다음과 같습니다.

1.현재 time step이 t라고 했을 때, 인코더의 모든 은닉 상태 <img width="123" alt="스크린샷 2022-05-05 오후 6 39 57" src="https://user-images.githubusercontent.com/76269316/166898295-d8f41c9d-71cf-44eb-8d55-418378541306.png">와 현재 시점에서의 디코더의 은닉 상태 <img width="21" alt="스크린샷 2022-05-05 오후 7 14 32" src="https://user-images.githubusercontent.com/76269316/166903828-9efe5c0e-155c-4344-87af-6bb5e9f97d85.png" style="zoom:150%;" >의 유사도를 계산합니다.

이를 **attention score**라고 합니다.

수식으로 정리하면 다음과 같습니다. <img width="194" alt="스크린샷 2022-05-05 오후 6 42 41" src="https://user-images.githubusercontent.com/76269316/166898719-c0204b84-e894-4ad9-b042-0c9b03e16860.png">

인코더의 모든 은닉 상태의 어텐션 스코어 모음 값을 <img width="266" alt="스크린샷 2022-05-05 오후 6 45 33" src="https://user-images.githubusercontent.com/76269316/166899220-0afaada6-587d-4a38-bffa-078724228de7.png">라고 정의하겠습니다.

<img width="1225" alt="스크린샷 2022-05-05 오후 6 56 51" src="https://user-images.githubusercontent.com/76269316/166901216-7ce242be-e398-4ff5-aa9e-7be3b1c73e0f.png" style="zoom:67%;" >

<br>

2.계산한 어텐션 스코어에 소프트맥스 함수를 적용해 합이 1이되는 확률 분포로 변환합니다. 이를 **attention distribution**이라고 합니다.

각각의 값은 **attention weight**라고 합니다.

어텐션 분포 <img width="29" alt="스크린샷 2022-05-05 오후 6 59 20" src="https://user-images.githubusercontent.com/76269316/166901550-3e57206c-2e48-4aa0-8fe1-f5540140a23d.png" style="zoom:150%;" >를 식으로 정의하면 다음과 같습니다. <img width="164" alt="스크린샷 2022-05-05 오후 6 59 40" src="https://user-images.githubusercontent.com/76269316/166901601-7cca4ca3-e947-481c-be8f-72406ee0129e.png">

<img width="1196" alt="스크린샷 2022-05-05 오후 7 00 29" src="https://user-images.githubusercontent.com/76269316/166901717-e1b27bd6-35d1-4ccd-ab90-9fc28da8c5ee.png" style="zoom:67%;" >

<br>

3.각 인코더 셀의 어텐션 가중치와 은닉 상태를 가중합(weighted sum)한 값이 저희가 구하고자 하는 **attention value**가 되게 됩니다.

attention value <img width="25" alt="스크린샷 2022-05-05 오후 7 04 05" src="https://user-images.githubusercontent.com/76269316/166902243-d59caa7c-0a87-4406-96c5-1ff44049bf64.png" style="zoom:150%;" >는 다음과 같습니다. <img width="131" alt="스크린샷 2022-05-05 오후 7 05 03" src="https://user-images.githubusercontent.com/76269316/166902412-c589b2e4-4c9c-4159-a456-425b628aeb0a.png">

attention value는 인코더의 문맥을 포함하고 있다고하여, context vector라고도 불립니다. (seq2seq의 context vector는 인코더의 마지막 은닉 상태입니다)

<img width="1166" alt="스크린샷 2022-05-05 오후 7 08 46" src="https://user-images.githubusercontent.com/76269316/166903013-3bc35315-82c4-47f3-a35e-3dc60f4f6cd5.png" style="zoom:67%;" >

<br>

4.어텐션 값과 디코더의 t 시점의 은닉 상태를 concatenate합니다.

attention value <img width="25" alt="스크린샷 2022-05-05 오후 7 04 05" src="https://user-images.githubusercontent.com/76269316/166902243-d59caa7c-0a87-4406-96c5-1ff44049bf64.png" style="zoom:150%;" >와 디코더의 은닉 상태 <img width="21" alt="스크린샷 2022-05-05 오후 7 14 32" src="https://user-images.githubusercontent.com/76269316/166903828-9efe5c0e-155c-4344-87af-6bb5e9f97d85.png" style="zoom:150%;" >를 합쳐 하나의 벡터로 만듧니다.

<img width="1370" alt="스크린샷 2022-05-05 오후 7 13 02" src="https://user-images.githubusercontent.com/76269316/166903614-b087cc91-0ff1-43d7-9866-381f2c2cb457.png" style="zoom:67%;" >

<br>

5.가중치 행렬(스코어 가중치 X) 행렬과 곱한뒤 하이퍼볼릭 탄젠트 함수를 적용한 <img width="26" alt="스크린샷 2022-05-05 오후 7 22 21" src="https://user-images.githubusercontent.com/76269316/166905013-6e957d67-a98a-4747-84b6-b9e6451e436f.png" style="zoom:150%;" >를 출력층의 입력으로 사용합니다.

<img width="248" alt="스크린샷 2022-05-05 오후 7 22 08" src="https://user-images.githubusercontent.com/76269316/166904970-ba1a6377-3d1b-451f-96d4-fdd0f6493205.png">

<img width="643" alt="스크린샷 2022-05-05 오후 7 27 19" src="https://user-images.githubusercontent.com/76269316/166905727-85ecc9b3-21e0-4776-9298-eef84105da7f.png">

*그림에는 편향을 표시하지 않았습니다.*

6.<img width="26" alt="스크린샷 2022-05-05 오후 7 22 21" src="https://user-images.githubusercontent.com/76269316/166905013-6e957d67-a98a-4747-84b6-b9e6451e436f.png" style="zoom:150%;" >를 입력으로 사용해 예측 벡터를 얻습니다.

![스크린샷 2022-05-05 오후 7 30 39](https://user-images.githubusercontent.com/76269316/166906184-b0153ba9-b528-4ed3-a591-76882036cb0d.png)
