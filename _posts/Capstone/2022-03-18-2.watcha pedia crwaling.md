---
title:  "[Capstone] 왓챠피디아 영화 리뷰 크롤링"
excerpt: "Selenium으로 왓챠피디아 영화 리뷰 크롤링하기"
toc: true
toc_label: "왓챠피디아 영화 리뷰 크롤링"
toc_sticky: true
published: true

categories:
  - Capstone
tags:
  - Selenium
  - Movie Review Crawling
  - Chrome Driver
last_modified_at: 2022-06-01

---

왓챠피디아는 무한스크롤 방식으로 영화 리뷰를 제공하고 있는데, 네이버 영화나 cgv 영화 리뷰 크롤링은 자료가 좀 있었는데 왓챠피디아는 없었다 😢

그래서 selenium을 따로 공부해 무작정 해봤다.

<br>

### 첫 번째 시도

스크롤을 맨 밑으로 내린 다음 find_elements()를 사용해서 모두 크롤링하기

➡️ 실패

웹 드라이버의 화면 내에 있는 리뷰들만 가져와서 위에 있는 리뷰들은 크롤링이 안됐다.

<img width="1460" alt="스크린샷 2022-03-18 오후 5 36 30" src="https://user-images.githubusercontent.com/76269316/158965432-c417ae4e-e9d8-44ef-aa03-2c2885ab2f6a.png">

<br><br>

### 두 번째 시도

크롤링 한 다음 화면 내리고 -> 다시 크롤링 한 다음 화면 내리는 방식으로 크롤링하기

➡️ 실패

첫 번째 시도처럼 화면 내에 있는 리뷰들만 가져오는지 동일한 리뷰가 두 번씩 크롤링 됐다. 어떤건 안됐다.

<img width="1458" alt="스크린샷 2022-03-18 오후 5 42 08" src="https://user-images.githubusercontent.com/76269316/158966283-1bb9d820-1a7d-46f5-963d-962ce5df1536.png">

<br><br>

### 세 번째 시도

<img width="1624" alt="스크린샷 2022-03-18 오후 6 02 52" src="https://user-images.githubusercontent.com/76269316/158972726-27307411-648e-497f-bd64-bd39abbaf09d.png">

리뷰 텍스트 부분의 XPath를 하나하나 보니까 div 인덱스 번호 하나만 바뀌어서

```html
//*[@id="root"]/div/div[1]/section/section/div/div/div/ul/div[1]/div[2]/a/div
//*[@id="root"]/div/div[1]/section/section/div/div/div/ul/div[2]/div[2]/a/div
//*[@id="root"]/div/div[1]/section/section/div/div/div/ul/div[3]/div[2]/a/div
```

저 부분만 순회하면서 크롤링 할 수 있지 않을까 했는데

<img width="1462" alt="스크린샷 2022-03-18 오후 6 06 32" src="https://user-images.githubusercontent.com/76269316/158973327-0a0ade02-daa5-45be-abdc-64c1c33b3243.png">

아니였다. <img width="89" alt="스크린샷 2022-03-18 오후 6 09 16" src="https://user-images.githubusercontent.com/76269316/158973705-9a93e185-0530-40ba-814b-bab317a0981a.png">

<br><br>

### 네 번째 시도

다시 첫 번째 방법으로 돌아와서 스크롤을 맨 밑으로 내린 다음에 페이지 소스에서 BeautifulSoup의 findall 함수를 통해 리뷰 부분만 추출하기

<img width="1460" alt="스크린샷 2022-03-18 오후 11 26 25" src="https://user-images.githubusercontent.com/76269316/159021249-9c499442-e0b7-4cfe-b3dc-6b61060db35f.png">

➡️ ~~절반의 성공 (페이지 소스에서 추출하다 보니 소스가 전부 안나와서 리뷰가 일부 잘린 것 같다.)~~

~~스파이더맨 (2002) 리뷰~~

~~리뷰가 3000개 이상이라는데~~

<img width="614" alt="스크린샷 2022-03-18 오후 11 28 26" src="https://user-images.githubusercontent.com/76269316/159021606-b096671b-5e7a-419e-ab81-7f664cd9911f.png">

~~크롤링은 2517개 밖에 안됐다 😭~~

<img width="1460" alt="스크린샷 2022-03-18 오후 11 29 22" src="https://user-images.githubusercontent.com/76269316/159021793-11b06455-3938-409e-9e88-e53143ed86da.png">

<br>

➡️ 코랩에서 실행시키면 안되는데 서버(로컬)에서 실행시키니까 아주 잘된다 😀

<img width="929" alt="스크린샷 2022-04-07 오후 8 25 47" src="https://user-images.githubusercontent.com/76269316/162188352-176ac1b6-098c-43b4-8fce-725eb9195a7a.png">

<br>

**코드**

- 웹 드라이버 및 리뷰 url 로드

```python
from selenium import webdriver
from selenium.webdriver.common.by import By
import time

driver = webdriver.Chrome('chromedriver', options=chrome_options)
url = 'https://pedia.watcha.com/ko-KR/contents/mBOkBwW/comments'
driver.get(url)
```

<br>

- 무한 스크롤 맨 밑으로 내리기

```python
scroll_pane_height = driver.execute_script('return document.documentElement.scrollHeight')

while True:
    driver.execute_script('window.scrollTo(0, document.documentElement.scrollHeight)')

    time.sleep(3)
    new_scroll_pane_height = driver.execute_script('return document.documentElement.scrollHeight')
    print(scroll_pane_height, new_scroll_pane_height)

    if scroll_pane_height == new_scroll_pane_height:
        break

    scroll_pane_height = new_scroll_pane_height
```

<br>

- 페이지 소스에서 review가 담겨있는 css-1g78l7j 클래스의 모든 요소를 가져옴
- <img width="1624" alt="스크린샷 2022-03-18 오후 11 32 25" src="https://user-images.githubusercontent.com/76269316/159022308-1ee92475-83d2-40b0-aad5-5c883858ea2b.png">

```python
import re
from bs4 import BeautifulSoup

html = driver.page_source
soup = BeautifulSoup(html, 'lxml')
reviews = soup.find_all("div", {"class":"css-1g78l7j"})

for review in reviews:
    print(review.get_text())
```

<br>

### Trouble Shooting

##### 5/31

오랜만에 크롤링할 일이 생겨서 selenium으로 크롤링하려는데, 다음과 같은 에러가 발생했다.

SessionNotCreatedException: Message: session not created: This version of ChromeDriver only supports Chrome version 100

<br>

```shell
# 크롬 버전 확인
$ google-chrome --version
```

크롬 버전 확인하고 [https://chromedriver.chromium.org/downloads](https://chromedriver.chromium.org/downloads)에서 크롬과 같은 드라이버를 설치해 줬는데도 계속 에러가 발생했다.

삽질 좀 하다가 에러 메시지를 다시 보니 내 크롬 버전은 102였고, 버전 100만 지원한다는 내용이였다 🤦🏻‍♂️

<br>

[https://www.ubuntuupdates.org/package/google_chrome/stable/main/base/google-chrome-stable](https://www.ubuntuupdates.org/package/google_chrome/stable/main/base/google-chrome-stable) 여기 있는 버전 중 에러 메시지와 같은 버전으로 Version 변수를 맞춰주고, 아래 명령어를 실행하니 잘된다.

```shell
$ Version ="100.0.4896.127-1" # 에러 메시지와 같은 버전으로 수정
$ wget "https://dl.google.com/linux/chrome/deb/pool/main/g/google-chrome-stable/google-chrome-stable_${Version}_amd64.deb"
$ sudo dpkg -i "google-chrome-stable_${Version}_amd64.deb"
$ rm -i "google-chrome-stable_${Version}_amd64.deb"
```

에러 메시지를 잘 확인하자 .. ❗️
