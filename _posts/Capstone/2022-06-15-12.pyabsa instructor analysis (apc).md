---
title:  "[Capstone] pyABSA 프레임워크 분석 - Instructor (APC)"
excerpt: "pyABSA 프레임워크 분석"
toc: true
toc_label: "pyABSA 프레임워크 분석 - Instructor (APC)"
toc_sticky: true
published: true

categories:
  - Capstone
tags:
  - PyTorch
  - pyABSA
last_modified_at: 2022-06-19

---

> 이전 포스팅에서 이어지는 내용입니다. [pyABSA 프레임워크 분석 - ABSADatasetList](https://seominseok4834.github.io/capstone/11.pyabsa-dataset-item-analysis/)
>
> 모든 코드는 [PyABSA github](https://github.com/yangheng95/PyABSA)에서 가져왔습니다.

<br>

아래 코드는 데모 코드로 다음과 같은 순서로 실행됩니다.

```python
from pyabsa.functional import APCModelList
from pyabsa.functional import Trainer, ATEPCTrainer
from pyabsa.functional import ABSADatasetList
from pyabsa.functional import APCConfigManager

apc_config = APCConfigManager.get_apc_config_english()  # 1 환경변수 설정

apc_config.pretrained_bert = 'microsoft/deberta-v3-base'
apc_config.model = ATEPCModelList.FAST_LCF_ATEPC
dataset_path = ABSADatasetList.Restaurant14  # 2 데이터셋 설정
# or your local dataset: dataset_path = 'your local dataset path'

# 모델 로드 및 훈련
aspect_extractor = APCTrainer(config=apc_config,
                                dataset=dataset_path,
                                from_checkpoint='',  # set checkpoint to train on the checkpoint.
                                checkpoint_save_mode=1,
                                auto_device=True
                                ).load_trained_model()
```

먼저 APConfigManager라는 클래스의 get_apc_config_english 메소드를 통해 configuration 변수를 가져온 뒤(#1), ABSADatasetList 클래스의 멤버 변수 Restaurant14 데이터셋의 경로를 가져온 뒤(#2), APCTrainer 클래스를 통해 모델을 생성, 훈련을 진행합니다.(#3)

이번 포스팅에서는 #3 부분에 대해서 다룹니다.

<br>

❗️configuration에 저장된 값들을 불러와 사용하는 부분이 많습니다. 어떤 값이 들어가는지 궁금하다면 아래 configuration을 참고해주세요.

```python
ATEPCConfigManager(args={'model': <class 'pyabsa.core.atepc.models.fast_lcf_atepc.FAST_LCF_ATEPC'>, 'optimizer': 'adamw', 'learning_rate': 2e-05, 'pretrained_bert': 'microsoft/deberta-v3-base', 'cache_dataset': True, 'warmup_step': -1, 'use_bert_spc': False, 'show_metric': False, 'max_seq_len': 80, 'SRD': 3, 'use_syntax_based_SRD': False, 'lcf': 'cdw', 'window': 'lr', 'dropout': 0.5, 'l2reg': 1e-05, 'num_epoch': 10, 'batch_size': 16, 'initializer': 'xavier_uniform_', 'seed': [52], 'polarities_dim': 3, 'log_step': 50, 'patience': 99999, 'gradient_accumulation_steps': 1, 'dynamic_truncate': True, 'srd_alignment': True, 'evaluate_begin': 0, 'hidden_dim': 768, 'embed_dim': 768, 'ABSADatasetsVersion': '2022.06.10', 'dataset_name': 'Restaurant14', 'dataset_file': {'train': ['integrated_datasets/atepc_datasets/110.SemEval/114.restaurant14/Restaurants_Train.xml.seg.atepc'], 'test': ['integrated_datasets/atepc_datasets/110.SemEval/114.restaurant14/Restaurants_Test_Gold.xml.seg.atepc'], 'valid': []}, 'device': device(type='cuda', index=0), 'device_name': 'NVIDIA GeForce RTX 2080 Ti', 'auto_device': True, 'model_name': 'fast_lcf_atepc', 'PyABSAVersion': '1.14.8', 'TransformersVersion': '4.18.0', 'TorchVersion': '1.10.2+cu102+cuda10.2', 'MV': <metric_visualizer.metric_visualizer.MetricVisualizer object at 0x7fe8bef1aee0>, 'save_mode': 1, 'model_path_to_save': 'checkpoints', 'sep_indices': 2, 'spacy_model': 'en_core_web_sm', 'IOB_label_to_index': {'B-ASP': 1, 'I-ASP': 2, 'O': 3, '[CLS]': 4, '[SEP]': 5}, 'index_to_label': {0: 'Negative', 1: 'Neutral', 2: 'Positive'}, 'label_to_index': {'Negative': 0, 'Neutral': 1, 'Positive': 2}, 'index_to_IOB_label': {1: 'B-ASP', 2: 'I-ASP', 3: 'O', 4: '[CLS]', 5: '[SEP]'}, 'label_list': ['B-ASP', 'I-ASP', 'O', '[CLS]', '[SEP]'], 'num_labels': 6, 'max_test_metrics': {'max_apc_test_acc': 87.12, 'max_apc_test_f1': 80.93, 'max_ate_test_f1': 88.81}, 'metrics_of_this_checkpoint': {'apc_acc': 86.23, 'apc_f1': 79.56, 'ate_f1': 87.69}}, args_call_count={'model': 5, 'optimizer': 2, 'learning_rate': 1, 'pretrained_bert': 4, 'cache_dataset': 1, 'warmup_step': 2261, 'use_bert_spc': 14860, 'show_metric': 0, 'max_seq_len': 50176, 'SRD': 9444, 'use_syntax_based_SRD': 4722, 'lcf': 17146, 'window': 0, 'dropout': 1, 'l2reg': 2, 'num_epoch': 2, 'batch_size': 5, 'initializer': 0, 'seed': 7, 'polarities_dim': 91, 'log_step': 2261, 'patience': 27, 'gradient_accumulation_steps': 3, 'dynamic_truncate': 9444, 'srd_alignment': 0, 'evaluate_begin': 91, 'hidden_dim': 6, 'embed_dim': 0, 'ABSADatasetsVersion': 0, 'dataset_name': 30, 'dataset_file': 95, 'device': 77072, 'device_name': 0, 'auto_device': 14861, 'model_name': 4855, 'PyABSAVersion': 0, 'TransformersVersion': 0, 'TorchVersion': 0, 'MV': 5, 'save_mode': 53, 'model_path_to_save': 55, 'sep_indices': 136660, 'spacy_model': 3, 'IOB_label_to_index': 1, 'index_to_label': 2, 'label_to_index': 0, 'index_to_IOB_label': 0, 'label_list': 2135162, 'num_labels': 3, 'max_test_metrics': 629, 'metrics_of_this_checkpoint': 270})
```

<br><br>

### Trainer

Trainer 클래스는 [PyABSA/pyabsa/functional/trainer/trainer.py](https://github.com/yangheng95/PyABSA/blob/release/pyabsa/functional/trainer/trainer.py#L59)에 정의돼 있습니다.

원래 이번 포스팅에서 Trainer 클래스에 대해 정리하려고 했는데, Trainer에서 train4apc 메소드를 호출하면 Instructor 클래스가 생성되고 훈련까지 진행됩니다. 그래서 이번 포스팅에서는 실제 모델 생성 및 훈련이 주된 내용이 될 것 같습니다.

<br>

데모 코드에서 생성한 APCTrainer 클래스는 Trainer 클래스를 상속 받은 클래스입니다.

```python
class APCTrainer(Trainer):
    pass


class ATEPCTrainer(Trainer):
    pass


class TCTrainer(Trainer):
    pass


class AOTCTrainer(Trainer):
    pass
```

cf) [pass, continue, break 차이점 알아보기](https://chancoding.tistory.com/7)

<br>

Trainer 클래스의 생성자를 먼저 살펴보겠습니다.

전체 코드가 너무 기니까 line by line으로 보겠습니다.

**trainer.py**

59 ~ 68 line

```python
class Trainer:
    def __init__(self,
                 config: ConfigManager = None,
                 dataset=None,
                 from_checkpoint: str = None,
                 checkpoint_save_mode: int = 0,
                 auto_device=True,
                 path_to_save=None,
                 load_aug=False
                 ):
```

먼저 함수 인자입니다. 데모 코드에서와 동일하게 ConfigManager, ABSADatasetList, checkpoint, auto_device 등을 넘겨받습니다.

```python
aspect_extractor = APCTrainer(config=apc_config,
                                dataset=dataset_path,
                                from_checkpoint='',  # set checkpoint to train on the checkpoint.
                                checkpoint_save_mode=1,
                                auto_device=True
                                ).load_trained_model()
```

<br>

**trainer.py**

84 ~ 86 line

```python
if not torch.cuda.device_count() > 1 and auto_device == 'allcuda':
  print('Cuda count <= 1, reset auto_device=True')
  auto_device = True
```

다음 라인에서는 GPU를 확인합니다. 사용할 수 있는 GPU가 없고, auto_device가 allcuda로 설정돼 있으면, auto_device를 True로 변경합니다.

+torch.cuda.device_count()는 사용가능한 GPU 개수를 반환합니다.

<br>

**trainer.py**

87 ~ 91 line

```python
if 'hidden_dim' not in config.args or 'embed_dim' not in config.args:
  pretrain_config = AutoConfig.from_pretrained(config.pretrained_bert)  # Hugging Face의 configuration 파일 로드
  config.hidden_dim = pretrain_config.hidden_size  # Hugging Face Bert Model의 hidden dim
  config.embed_dim = pretrain_config.hidden_size
  config.ABSADatasetsVersion = query_local_version()
```

87 ~ 91 line에서는 hidden_dim과 embed_dim이 configuration에 정의돼 있지 않는 경우,

데모 코드에서 pertained_bert로 'microsoft/deberta-v3-base'를 사용했는데 해당 Hugging Face의 configuration 파일을 불러와 configuration의 hidden_dim과 embed_dim으로 저장합니다.

```python
atepc_config.pretrained_bert = 'microsoft/deberta-v3-base'
```

<br>

query_local_version 메소드는 [PyABSA/pyabsa/utils/file_utils.py](https://github.com/yangheng95/PyABSA/blob/42aac7857fd6fb781184433f68063581ed1c3cc4/pyabsa/utils/file_utils.py#L310)에 정의돼 있습니다.

**file_utils.py**

310 ~ 317 line

```python
def query_local_version():
    try:
        fin = open(find_cwd_file(['__init__.py', 'integrated_datasets']))
        local_version = fin.read().split('\'')[-2]
        fin.close()
    except:
        return None
    return local_version
```

find_cwd_file은 [findfile](https://github.com/yangheng95/findfile) 프레임워크의 메소드로, 파일 경로를 리턴합니다. 리턴 받은 경로의 파일을 읽은 뒤, version을 가져와 configuration에 저장합니다.

+findfile 프레임워크는 추후 따로 정리하도록 하겠습니다.

<br>

**trainer.py**

92 ~ 95 line

```python
if isinstance(config, APCConfigManager):
  self.train_func = train4apc
  self.model_class = SentimentClassifier
  self.task = 'apc'

elif isinstance(config, ATEPCConfigManager):  # 현재 config는 ATEPCConfigManager
  self.train_func = train4atepc
  self.model_class = AspectExtractor
  self.task = 'atepc'

elif isinstance(config, TCConfigManager):
  self.train_func = train4tc
  self.model_class = TextClassifier
  self.task = 'classification'

elif isinstance(config, AOTCConfigManager):
  self.train_func = train4ao_tc
  self.model_class = AOTCTextClassifier
  self.task = 'ao_tc'
```

config가 어떤 태스크에 대한 config 클래스인지 체크합니다. 저희는 APC 태스크를 진행 할 예정이기 때문에 if isinstance(config, APCConfigManager) 부분이 실행됩니다.

<br>

train_func에 train4apc가 들어가게 되는데, train4apc를 이해하기 위해선 데코레이터를 알아야 합니다.

데코레이터 함수에 대한 자세한 설명은 다음 세 개의 글을 참고해주세요.

> [파이썬 - 퍼스트클래스 함수 (First Class Function)](https://schoolofweb.net/blog/posts/%ed%8c%8c%ec%9d%b4%ec%8d%ac-%ed%8d%bc%ec%8a%a4%ed%8a%b8%ed%81%b4%eb%9e%98%ec%8a%a4-%ed%95%a8%ec%88%98-first-class-function/)
>
> [파이썬 - 클로저 (Closure)](https://schoolofweb.net/blog/posts/%ED%8C%8C%EC%9D%B4%EC%8D%AC-%ED%81%B4%EB%A1%9C%EC%A0%80-closure/)
>
> [파이썬 - 데코레이터 (Decorator)](https://schoolofweb.net/blog/posts/%ed%8c%8c%ec%9d%b4%ec%8d%ac-%eb%8d%b0%ec%bd%94%eb%a0%88%ec%9d%b4%ed%84%b0-decorator/)

<br>

train4apc 메소드는 [PyABSA/pyabsa/core/apc/training/apc_trainer.py](https://github.com/yangheng95/PyABSA/blob/42aac7857fd6fb781184433f68063581ed1c3cc4/pyabsa/core/apc/training/apc_trainer.py#L566)에 정의돼 있는데, @retry라는 심볼이 붙어있습니다.

**train4apc**

565 ~ 578 line

```python
@retry
def train4apc(opt, from_checkpoint_path, logger):
    random.seed(opt.seed)
    numpy.random.seed(opt.seed)
    torch.manual_seed(opt.seed)
    torch.cuda.manual_seed(opt.seed)

    opt.device = torch.device(opt.device)

    # in case of handling ConnectionError exception
    trainer = Instructor(opt, logger)
    resume_from_checkpoint(trainer, from_checkpoint_path)

    return trainer.run()
```

이는 [PyABSA/pyabsa/utils/pyabsa_utils.py](https://github.com/yangheng95/PyABSA/blob/42aac7857fd6fb781184433f68063581ed1c3cc4/pyabsa/utils/pyabsa_utils.py#L155)에 정의된 retry 데코레이터 함수의 인자로 넘겨 실행하는 구문입니다.

**retry**

155 ~ 177 line

```python
def retry(f):
    @wraps(f)
    def decorated(*args, **kwargs):
        count = 5
        while count:

            try:
                return f(*args, **kwargs)
            except (
                TransformerConnectionError,
                requests.exceptions.RequestException,
                requests.exceptions.ConnectionError,
                requests.exceptions.HTTPError,
                requests.exceptions.ConnectTimeout,
                requests.exceptions.ProxyError,
                requests.exceptions.SSLError,
                requests.exceptions.BaseHTTPError,
            ) as e:
                print('Training Exception: {}, will retry later'.format(e))
                time.sleep(60)
                count -= 1

    return decorated
```

retry 함수는 단순히 인자로 받은 메소드를 실행하는 역할을 합니다. exception 발생시 5번까지 재실행 합니다.

<br>

다시 train4apc 메소드로 돌아오면

```python
@retry
def train4apc(opt, from_checkpoint_path, logger):
    random.seed(opt.seed)
    numpy.random.seed(opt.seed)
    torch.manual_seed(opt.seed)
    torch.cuda.manual_seed(opt.seed)

    opt.device = torch.device(opt.device)

    # in case of handling ConnectionError exception
    trainer = Instructor(opt, logger)
    resume_from_checkpoint(trainer, from_checkpoint_path)

    return trainer.run()
```

먼저 훈련 결과 재현을 위해 시드를 고정하고, 디바이스를 설정한 뒤, Instructor 클래스의 인스턴스를 생성합니다. 리턴으로 run 메소드를 실행하기 때문에 생성자부터 run 메소드까지 이어서 설명하도록 하겠습니다.

추가적으로 trainer의 파라미터로 들어가는 opt와 logger는 ConfigManager와 파이썬 기본 내장 모듈인 logging의 logger입니다. (trainer.py 163 ~ 167 line)

```python
if self.checkpoint_save_mode:
  model_path.append(self.train_func(self.config, self.from_checkpoint, self.logger))
else:
  # always return the last trained model if dont save trained model
  model = self.model_class(model_arg=self.train_func(self.config, self.from_checkpoint, self.logger))
```

<br><br>

이번 포스팅에서 집중적으로 다룰 Instructor 클래스입니다.

### Instructor

##### __init__

Instructor 클래스는 [PyABSA/pyabsa/core/apc/training/apc_trainer.py](https://github.com/yangheng95/PyABSA/blob/42aac7857fd6fb781184433f68063581ed1c3cc4/pyabsa/core/apc/training/apc_trainer.py#L39)에 정의돼 있습니다.

코드가 길어서 생성자 부분을 먼저 보겠습니다. (39 ~ 60 line)

**apc_trainer.py**

```python
class Instructor:
    def __init__(self, opt, logger):
        self.logger = logger
        self.opt = opt  # opt는 configuration

        self.logger = logger

        self.model = APCEnsembler(self.opt)  # APCEnsembler 클래스
        self.opt = self.model.opt  # ※self.opt가 model의 opt로 바뀜
        self.train_set = self.model.train_set
        self.test_set = self.model.test_set
        self.test_dataloader = self.model.test_dataloader
        self.val_dataloader = self.model.val_dataloader
        self.train_dataloader = self.model.train_dataloader
        self.tokenizer = self.model.tokenizer
        
        initializers = {
            'xavier_uniform_': torch.nn.init.xavier_uniform_,
            'xavier_normal_': torch.nn.init.xavier_normal_,
            'orthogonal_': torch.nn.init.orthogonal_,
        }
        self.initializer = initializers[self.opt.initializer]
```

멤버 변수들을 정의한 부분인데 APCEnsembler 클래스의 인스턴스를 model로 정의한 뒤, APCEnsembler의 멤버 변수들을 저장합니다.

✚ APCEnsembler는 [PyABSA/pyabsa/core/apc/models/ensembler.py](https://github.com/yangheng95/PyABSA/blob/42aac7857fd6fb781184433f68063581ed1c3cc4/pyabsa/core/apc/models/ensembler.py#L40)에 정의돼 있습니다. 해당 코드는 실제 모델을 정의한 부분으로 추후에 따로 정리하도록 하겠습니다. (forward 함수가 정의돼 있음)

<br>

**apc_trainer.py**

63 ~ 67 line

```python
# use DataParallel for training if device count larger than 1
if self.opt.auto_device == 'allcuda':
  self.model.to(self.opt.device)
  self.model = torch.nn.parallel.DataParallel(self.model)
else:
  self.model.to(self.opt.device)
```

이후 모델의 gpu 설정에 따라 gpu에 모델을 로드합니다.

모델의 auto_device가 allcuda로 돼 있으면(모든 gpu를 사용), 데이터 병렬 처리를 위해 DataParallel을 사용합니다.

<br>

69 ~ 76 line

```python
if hasattr(self.model.models[0], 'eta1') and hasattr(self.model.models[0], 'eta2'):  # 1
  if self.opt.eta == 0:  # 2
    torch.nn.init.uniform_(self.model.models[0].eta1)
    torch.nn.init.uniform_(self.model.models[0].eta2)

    eta1_id = id(self.model.models[0].eta1)  # 3
    eta2_id = id(self.model.models[0].eta2)

    base_params = filter(lambda p: id(p) != eta1_id and id(p) != eta2_id, self.model.models[0].parameters())  # 4
    self.opt.eta_lr = self.opt.learning_rate * 1000 if 'eta_lr' not in self.opt.args else self.opt.args['eta_lr']  # 5
```

#1: model에는 models라는 [ModuleList](https://github.com/yangheng95/PyABSA/blob/42aac7857fd6fb781184433f68063581ed1c3cc4/pyabsa/core/apc/models/ensembler.py#L54)가 존재합니다. 구글링한 바에 따르면, 리스트 컨테이너 방식으로 모델의 구성 요소를 담으려면 nn.Module의 파라미터로 등록돼야 하는데, 이를 처리하기 위해 nn.ModuleList를 사용한다고 합니다. [Pytorch-ModuleList vs List](https://hongl.tistory.com/279)

사용 방법은 리스트와 동일하게 인덱스로 접근합니다.

#1에서 이 models라는 ModuleList가 eta1, eta2라는 속성을 갖고 있는지 확인한다. eta는 estimated time of arrival의 약자로 1 epoch의 예상 학습 시간을 의미합니다.

eta1과 eta2가 존재하면 모델 configuration의 eta가 0인지 확인합니다.

0이라면 #2가 실행돼 model.models[0].eta1과 model.models[0].eta2를 0에서 1사이의 값으로 균등(uniform)하게 초기화 됩니다.

<p align = "center">
  <img src = "https://user-images.githubusercontent.com/76269316/174199111-dac3bc4d-2ff9-48a0-91d0-aacf369393d7.png">
</p>
<p align = "center">
  torch.nn.init.uniform_
</p>

이후 #3에서 id 메소드를 통해 eta1과 eta2가 저장된 고유 주소 값을 저장한 뒤, #4에서 model.models[0].parameters()를 filter 함수를 통해 eta1과 eta2를 제거하고 추려냅니다.

+[파이썬 filter 내장 함수 사용법](https://www.daleseo.com/python-filter/)

#5에서는 model.opt에 eta_lr이라는 변수가 있다면 그걸 opt.eta_lr로 저장하고 그렇지 않다면, 모델 opt에 저장된 learning_rate를 가져와 1,000을 곱한 값을 opt.eta_lr로 사용합니다.

<br>

77 ~ 85 line

```python
self.optimizer = init_optimizer(self.opt.optimizer)(  # 6
  [
    {'params': base_params},
    {'params': self.model.models[0].eta1, 'lr': self.opt.eta_lr, 'weight_decay': self.opt.l2reg},
    {'params': self.model.models[0].eta2, 'lr': self.opt.eta_lr, 'weight_decay': self.opt.l2reg}
  ],
  lr=self.opt.learning_rate,
  weight_decay=self.opt.l2reg
)
```

이후 opt.optimizer를 인자로 init_optimizer 메소드를 실행합니다.

<br>

init_optimizer는 [PyABSA/pyabsa/utils/pyabsa_utils.py](https://github.com/yangheng95/PyABSA/blob/42aac7857fd6fb781184433f68063581ed1c3cc4/pyabsa/utils/pyabsa_utils.py#L227)에 정의돼 있습니다.

**pyabsa_utils.py**

227 ~ 257 line

```python
def init_optimizer(optimizer):
    optimizers = {
        'adadelta': torch.optim.Adadelta,  # default lr=1.0
        'adagrad': torch.optim.Adagrad,  # default lr=0.01
        'adam': torch.optim.Adam,  # default lr=0.001
        'adamax': torch.optim.Adamax,  # default lr=0.002
        'asgd': torch.optim.ASGD,  # default lr=0.01
        'rmsprop': torch.optim.RMSprop,  # default lr=0.01
        'sgd': torch.optim.SGD,
        'adamw': torch.optim.AdamW,
        # 'radam': torch.optim.Adam if torch.version.__version__ <= '1.9.1' else torch.optim.RAdam,
        # 'nadam': torch.optim.Adam if torch.version.__version__ <= '1.9.1' else torch.optim.NAdam,
        # 'sparseadam': torch.optim.Adam if torch.version.__version__ <= '1.9.1' else torch.optim.SparseAdam,
        torch.optim.Adadelta: torch.optim.Adadelta,  # default lr=1.0
        torch.optim.Adagrad: torch.optim.Adagrad,  # default lr=0.01
        torch.optim.Adam: torch.optim.Adam,  # default lr=0.001
        torch.optim.Adamax: torch.optim.Adamax,  # default lr=0.002
        torch.optim.ASGD: torch.optim.ASGD,  # default lr=0.01
        torch.optim.RMSprop: torch.optim.RMSprop,  # default lr=0.01
        torch.optim.SGD: torch.optim.SGD,
        torch.optim.AdamW: torch.optim.AdamW,
        # torch.optim.RAdam: torch.optim.RAdam,
        # torch.optim.NAdam: torch.optim.NAdam,
        # torch.optim.SparseAdam: torch.optim.SparseAdam,
    }
    if optimizer in optimizers:  # 1
        return optimizers[optimizer]
    elif hasattr(torch.optim, optimizer.__name__):  # 2
        return optimizer
    else:
        raise KeyError('Unsupported optimizer: {}. Please use string or the optimizers in torch.optim as your optimizer'.format(optimizer))
```

init_optimizer는 인자로 넘겨받은 optimizer를 미리 정의해놓은 optimizers에서 찾아 반환해주는 함수로, 정의해놓은 리스트 안에 있는 경우 해당 값을 리턴하고 (#1) torch.optim.SparseAdam과 같이 정의해놓지는 않았지만, torch.optim에 정의된 모듈들은 hasattr로 확인한 뒤, 해당 optimizer를 그대로 사용한다.

+pytorch의 optimizer는 \_\_name__이라는 속성이 존재합니다. [Name of the optimizer being used](https://discuss.pytorch.org/t/name-of-the-optimizer-being-used/100341)

![스크린샷 2022-06-17 오전 10 08 24](https://user-images.githubusercontent.com/76269316/174202381-7f6276a1-3ea2-439b-b491-0c8616e9e723.png)

<br>

init_optimizer를 통해 pytorch optimizer 모듈을 리턴받아 리스트로 담긴 params와 lr, weight_decay를 파라미터로 넘겨 optimizer를 생성합니다.

<br>

다시 생성자로 돌아와서 ❗️

**apc_trainer.py**

86 line

```python
else:  # 69 line if
  self.optimizer = init_optimizer(self.opt.optimizer)(
    self.model.parameters(),
    lr=self.opt.learning_rate,
    weight_decay=self.opt.l2reg
  )
```

다시 apc_trainer 코드로 돌아와서, 해당 else문은 69 line에 있는 if문과 매칭되는 else문으로 model.models에 eta1과 eta2가 없는 경우 실행됩니다.

eta1과 eta2가 없는 경우 77 ~ 85 line과 동일하게 optimizer를 생성합니다. 이 때는 eta1과 eta2가 없으므로 filter 함수를 사용하지 않고, 바로 model.parameters로 넘겨줍니다.

<br>

92 ~ 93 line

```python
self.train_dataloaders = []
self.val_dataloaders = []
```

이후 train_dataloaders, val_dataloaders를 빈 리스트로 생성합니다.

<br>

95 ~ 96 line

```python
if amp:
  self.model, self.optimizer = amp.initialize(self.model, self.optimizer, opt_level="O1")
```

amp는 클래스 위에 import한 라이브러리로, 30 ~ 36 line에 있습니다.

```python
try:
    import apex.amp as amp

    # assert torch.version.__version__ < '1.11.0'
    print('Use FP16 via Apex!')
except Exception:
    amp = None
```

만약 이 때, 정상적으로 import 됐다면 95 line의 if 문이 실행돼 amp.initialize가 실행될 것입니다.

+amp는 automatic mixed precision의 약자로 mixed precision training을 통해 학습 속도를 증가시켜주는 라이브러리입니다. [Amp에 대해 알아보자 (Automatic Mixed Precision)](https://cvml.tistory.com/8)

<br>

98 ~ 101 line

```python
if os.path.exists('init_state_dict.bin'):  # 1
  os.remove('init_state_dict.bin')
if self.opt.cross_validate_fold > 0:  # 2
  torch.save(self.model.state_dict(), 'init_state_dict.bin')
```

이어서 살펴보면, #1에서 현재 경로에 init_state_dict.bin 파일이 있는지 확인해 있을 경우 제거합니다.

#2에서는 opt의 cross_validate_fold가 0보다 클 경우 torch.save 메소드로 모델을 저장합니다.

<br>

103 ~ 107 line

```python
self.opt.device = torch.device(self.opt.device)  # 1
if self.opt.device.type == 'cuda':
  self.logger.info("cuda memory allocated:{}".format(torch.cuda.memory_allocated(device=self.opt.device)))

print_args(self.opt, self.logger)  # 2
```

#1 디바이스를 설정하고, gpu를 사용할 경우 log를 남깁니다.

#2 print_args 메소드를 사용해 로그와 프롬프트에 출력합니다.

<br>

[PyABSA/pyabsa/utils/pyabsa_utils.py](https://github.com/yangheng95/PyABSA/blob/42aac7857fd6fb781184433f68063581ed1c3cc4/pyabsa/utils/pyabsa_utils.py#L35)

```python
def print_args(config, logger=None, mode=0):
    args = [key for key in sorted(config.args.keys())]
    for arg in args:
        if logger:  # logger에 INFO로 추가
            logger.info('{0}:{1}\t-->\tCalling Count:{2}'.format(arg, config.args[arg], config.args_call_count[arg]))
        else:  # 프롬프트에 출력
            print('{0}:{1}\t-->\tCalling Count:{2}'.format(arg, config.args[arg], config.args_call_count[arg]))
```

![스크린샷 2022-06-26 오후 3 05 58](https://user-images.githubusercontent.com/76269316/175801751-a86561ea-80c9-4ec7-9884-9b832e13c197.png)

![스크린샷 2022-06-26 오후 3 06 45](https://user-images.githubusercontent.com/76269316/175801784-49b5b479-6797-4402-bb4d-5db9f03e888a.png)

여기까지가 Instructor 클래스 인스턴스 생성 과정이고, train4apc 메소드에서 run 메소드의 실행 결과를 리턴하기 때문에 그 부분을 이어서 보겠습니다.

<br>

##### run

**apc_trainer.py**

559 ~ 562 line

```python
def run(self):
  # Loss and Optimizer
  criterion = nn.CrossEntropyLoss()
  return self._train(criterion)
```

run 메소드는 loss 계산을 위해 nn.CrossEntropyLoss 모듈을 생성하고 \_train 메소드를 호출합니다.

<br>

##### _train

**apc_trainer.py**

155 ~ 156 line

```python
def _train(self, criterion):
  self.prepare_dataloader(self.train_set)
```

먼저 prepare_dataloader 메소드를 실행합니다. 코드가 길어서 조건별로 나눠서 살펴보겠습니다.

<br>

**prepare_dataloader**

127 ~ 130 line

```python
def prepare_dataloader(self, train_set):
  if self.train_dataloader and self.val_dataloader:  # 1
    self.val_dataloaders = [self.val_dataloader]
    self.train_dataloaders = [self.train_dataloader]
```

**train_dataloader, val_dataloader가 존재하는 경우 #1이 실행됩니다.**

train_dataloader와 val_dataloader는 pytorch DataLoader인데, 이를 리스트로 감쌉니다.

<br>

132 ~ 137 line

```python
elif self.opt.cross_validate_fold < 1:  # 2
  train_sampler = RandomSampler(self.train_set if not self.train_set else self.train_set)  # shuffle을 위해 sampler 생성
  self.train_dataloaders.append(DataLoader(dataset=train_set,
                                           batch_size=self.opt.batch_size,
                                           sampler=train_sampler,
                                           pin_memory=True))
```

**만약 dataloader가 존재하지 않고, cross_validate_fold가 0 이하이면 elif 구문(#2)이 실행됩니다.**

DataLoader를 새로 생성해 train_dataloaders에 추가합니다. shuffle을 하기 위해 RandomSampler를 생성해 dataloader 파라미터로 넘겨줬습니다.

<br>

139 ~ 143 line

```python
else:  # 3
  split_dataset = train_set
  len_per_fold = len(split_dataset) // self.opt.cross_validate_fold + 1  # train_set (전체 개수 / cross_validate_fold 횟수) + 1
  folds = random_split(split_dataset, tuple([len_per_fold] * (self.opt.cross_validate_fold - 1) + [
    len(split_dataset) - len_per_fold * (self.opt.cross_validate_fold - 1)]))  # 4 random_split 메소드로 train/validation 데이터셋을 분할
```

**dataloader가 존재하지 않고 cross_validate_fold가  2 이상인 경우,  else 구문(#3)이 실행됩니다.**

train_set의 전체 개수를 cross_validate_fold 횟수로 나눈 몫을 len_per_fold에 저장합니다.

이후 #4에서 random_split 메소드를 사용해 훈련/검증 데이터셋으로 분할합니다.

ex) train_set이 500개이고, cross_validate_fold가 3인 경우, len_per_fold와 folds는 다음과 같이 됩니다.

![스크린샷 2022-06-17 오후 9 55 20](https://user-images.githubusercontent.com/76269316/174302467-23b93502-439e-41ca-a001-127811f1f23a.png)

이어서, 145 ~ 153 line을 보겠습니다.

```python
for f_idx in range(self.opt.cross_validate_fold):
  train_set = ConcatDataset([x for i, x in enumerate(folds) if i != f_idx])  # 1
  val_set = folds[f_idx]  # 2
  train_sampler = RandomSampler(train_set if not train_set else train_set)  # 3
  val_sampler = SequentialSampler(val_set if not val_set else val_set)
  self.train_dataloaders.append(  # 4
    DataLoader(dataset=train_set, batch_size=self.opt.batch_size, sampler=train_sampler))
  self.val_dataloaders.append(
    DataLoader(dataset=val_set, batch_size=self.opt.batch_size, sampler=val_sampler))
```

이 부분을 이해하기 위해서는 교차 검증에 대해 알아야 합니다. 제가 정리해놓은 [포스팅](https://seominseok4834.github.io/machine%20learning/2.scikit-learn-machine-learning-in-python/#%EA%B5%90%EC%B0%A8-%EA%B2%80%EC%A6%9D)을 참고하시기 바랍니다.

#1: 위에서 나눈 데이터셋에서 f_idx번째 데이터를 제외한 모든 데이터를 ConcatDataset으로 생성합니다.

#2: f_idx번째 데이터는 validation 데이터셋으로 정의합니다.

이를 그림으로 나타내면 다음과 같습니다.

<img width="1512" alt="스크린샷 2022-06-17 오후 10 19 57" src="https://user-images.githubusercontent.com/76269316/174306266-63a3c5c2-1c2e-4a60-b7de-7d0c95917185.png" style="zoom:50%;" >

#3: shuffle을 위해 train_sampler, val_sampler를 생성합니다. *¿ 그런데 왜 train_set이랑 val_set이 비어있을 때 sampler를 생성하는 걸까요*

#4: DataLoader를 정의한 뒤, 각각 train_dataloaders, val_dataloaders에 추가해줍니다.

여기까지가 prepare_dataloader 메소드이고, 다시 \_train 메소드로 돌아가겠습니다.

<br>

##### \_train

158 ~ 160 line

```python
if self.opt.warmup_step >= 0:
  self.lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=len(self.train_dataloaders[0]) * self.opt.num_epoch)
  self.warmup_scheduler = warmup.UntunedLinearWarmup(self.optimizer)
```

model opt의 warumup_step이 0 이상인 경우, lr_scheduler는 [cosine annealing scheduler](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.CosineAnnealingLR.html#cosineannealinglr)를 사용하고, warmup_scheduler는 [pytorch_warmup](https://github.com/Tony-Y/pytorch_warmup)의 UntunedLinearWarmup을 사용합니다.

cf) [Pytorch Learning Rate Scheduler 정리](https://gaussian37.github.io/dl-pytorch-lr_scheduler/)

<br>

162 ~ 165 line

```python
if len(self.val_dataloaders) > 1:
  return self._k_fold_train_and_evaluate(criterion)
else:
  return self._train_and_evaluate(criterion)
```

val_dataloaders에 2개 이상의 dataloader가 담겨 있는 경우 \_k_fold_train_and_evaluate 메소드를, 그렇지 않은 경우 \_train_and_evaluate 메소드를 실행합니다.

먼저 \_train_and_evaluate 메소드를 살펴보겠습니다 .. 🥲

<br><br>

##### _train_and_evaluate

코드가 아주 길기 때문에 라인별로 차근차근 살펴보겠습니다.

167 ~ 181 line

```python
global_step = 0
max_fold_acc = 0
max_fold_f1 = 0
save_path = '{0}/{1}_{2}'.format(self.opt.model_path_to_save,
                                 self.opt.model_name,
                                 self.opt.dataset_name
                                )

self.opt.metrics_of_this_checkpoint = {'acc': 0, 'f1': 0}
self.opt.max_test_metrics = {'max_apc_test_acc': 0, 'max_apc_test_f1': 0}

Total_params = 0
Trainable_params = 0
NonTrainable_params = 0
```

훈련시 사용할 변수들을 정의한 부분입니다.

<br>

183 ~ 189 line

```python
for param in self.model.parameters():
  mulValue = numpy.prod(param.size())  # 1
  Total_params += mulValue  # 2
  if param.requires_grad:  # 3
    Trainable_params += mulValue
  else:
    NonTrainable_params += mulValue
```

model.parameters로 파라미터들을 순회하며, 파라미터의 개수를 구합니다.

#1에서 numpy.prod 메소드를 사용해 param.size로 리턴 받은 파라미터의 size를 곱해준다.

cf) [numpy.prod](https://codetorial.net/numpy/functions/numpy_prod.html), [torch.nn.Module.parameters](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.parameters)

이를 전체 파라미터 개수를 나타내는 Total_params에 더해주고(#2), 파라미터의 requires_grad를 확인해(#3) True인 경우(gradient를 계산하는 파라미터인 경우) Trainable_params에 더하고, 그렇지 않은 경우에는 NonTrainable_params에 더합니다.

<br>

191 ~ 193 line

```python
patience = self.opt.patience + self.opt.evaluate_begin
if self.opt.log_step < 0:
  self.opt.log_step = len(self.train_dataloaders[0]) if self.opt.log_step < 0 else self.opt.log_step
```

patience는 학습 과정에서 metric이 향상되지 않을 때 몇 에폭을 참은 뒤 learning rate를 줄일 것인지를 나타내는 파라미터입니다.

cf) [PyTorch가 제공하는 Learning rate scheduler 정리](https://sanghyu.tistory.com/113)

*그런데 patience에 왜 evaluate_begin을 더할까요 ¿ ..*

어쨌든 patience를 정의한 다음, log_step이 0보다 작으면 log_step을 train_dataloaders의 0번째 인덱스에 있는 훈련 데이터셋의 길이를 log_step으로 지정합니다.

<br>

195 ~ 203 line

```python
self.logger.info("***** Running training for Aspect Polarity Classification *****")
self.logger.info("Training set examples = %d", len(self.train_set))
if self.test_set:
  self.logger.info("Test set examples = %d", len(self.test_set))
  self.logger.info("Total params = %d, Trainable params = %d, Non-trainable params = %d", Total_params,
                   Trainable_params, NonTrainable_params)
  self.logger.info("Batch size = %d", self.opt.batch_size)
  self.logger.info("Num steps = %d", len(self.train_dataloaders[0]) // self.opt.batch_size * self.opt.num_epoch)
  postfix = ''
```

이후 훈련데이터, 테스트데이터 개수, 배치 사이즈 등을 information log로 저장합니다.

postfix는 tqdm 프로세스바에서 메시지를 추가할 때 사용할 변수입니다.

<br>

204 ~ 209 line

```python
for epoch in range(self.opt.num_epoch):
  patience -= 1
  iterator = tqdm(self.train_dataloaders[0], postfix='Epoch:{}'.format(epoch))
```

모델에 정의된 에폭 수만큼 반복되고, 에폭마다 patience가 1 감소합니다. (metric이 향상되든, 안되든 에폭마다 patience를 줄이기 때문에 patience에 evaluate_begin을 더해줬나 ?)

이후 train_dataloaders를 tqdm으로 감쌉니다. cf) [tqdm 사용법](https://skillmemory.tistory.com/entry/tqdm-%EC%82%AC%EC%9A%A9%EB%B2%95-python-%EC%A7%84%ED%96%89%EB%A5%A0-%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4%EB%B0%94)

<br>

210 ~ 217 line

```python
for i_batch, sample_batched in enumerate(iterator):
  global_step += 1
  # switch model to training mode, clear gradient accumulators
  self.model.train()  # 1
  self.optimizer.zero_grad()  # 2
  inputs = {col: sample_batched[col].to(self.opt.device) for col in self.opt.inputs_cols}  # 3
  outputs = self.model(inputs)  # 4
  targets = sample_batched['polarity'].to(self.opt.device)  # 5
```

이번 라인부터가 실제로 gradient와 loss를 계산해 모델을 훈련하는 코드로, Iterator(train_dataloaders[0])를 enumerate로 순회합니다.

#1: 모델을 훈련 모드로 변경한 뒤, gradient 값을 0으로 초기화 합니다.(#2)

#3: sample_batched 데이터의 opt.inputs_cols 열들을 device로 할당합니다. *¿ opt.inputs_cols가 뭔지 모르겠습니다 ..*

#4: outputs는 model에 입력 데이터를 넣었을 때의 예측값으로, logits와 loss 값이 dictionary로 담겨있습니다. (이 부분은 AOCEnsembler를 다룰때 나옵니다) target은 실제 정답 레이블인데, 레이블도 입력 데이터처럼 device로 할당합니다.(#5)

<br>

219 ~ 222 line

```python
sen_logits = outputs['logits']  # 1
loss = criterion(sen_logits, targets)  # 2
if isinstance(outputs, dict) and 'loss' in outputs:
  loss += torch.sum(outputs['loss'])
```

outputs에서 logits을 꺼내 loss를 계산한 뒤(#1 ~ #2), outputs 안에 계산된 loss가 있는 경우 이를 더해줍니다.

<br>

224 ~ 225 line

```python
if self.opt.auto_device == 'allcuda':
  loss = loss.mean()
```

이후 만약 모든 gpu를 사용하기로 했다면, 이를 평균냅니다.

<br>

227 ~ 232 line

```python
if amp:  # 1
  with amp.scale_loss(loss, self.optimizer) as scaled_loss:
    scaled_loss.backward()
  else:
    loss.backward()
    self.optimizer.step()
```

#1: amp(automatic mixed precision)가 설정된 경우 amp.scale_loss로 backward를 진행하고, 그렇지 않은 경우 pytorch를 사용해 backward를 진행합니다.

<br>

234 ~ 236 line

```python
if self.opt.warmup_step >= 0:
  with self.warmup_scheduler.dampening():  # 1
    self.lr_scheduler.step()
```

warm up은 [Bag of Tricks for Image Classification with Convolutional Neural Networks](https://arxiv.org/abs/1812.01187)에서 등장한 학습 방법으로, 모든 파라미터는 초기에 랜덤 값으로 설정되는데, 학습 초기부터 큰 learning rate를 사용하면 학습의 불안정성을 초래할 수 있다고 한다. 따라서 초기에는 작은 학습률로 시작해, 훈련이 안정화되면 초기 학습률로 돌아가는 방법론이다.

![스크린샷 2022-06-18 오후 10 53 31](https://user-images.githubusercontent.com/76269316/174441623-1cf13f57-7baa-4dd6-869c-e7b989a8d018.png)

<br>

학습 속도는 warm up factor에 의해 약화(dampen)되는데 이 부분을 담당하는 코드가 #1이다.

<img src="https://user-images.githubusercontent.com/76269316/174441762-bad9871d-dd0b-40a5-8ed7-d652ac6c2973.png" alt="image" style="zoom: 33%;" />

<br>

239 ~ 244 line

```python
if global_step % self.opt.log_step == 0:  # 1
  if self.opt.dataset_file['test'] and epoch >= self.opt.evaluate_begin:  # 2
    if self.val_dataloaders:  # 3
      test_acc, f1 = self._evaluate_acc_f1(self.val_dataloaders[0])
    else:
      test_acc, f1 = self._evaluate_acc_f1(self.test_dataloader)
```

global_step을 log_step으로 나눴을 때 나누어 떨어지는 경우(#1) 테스트를 진행합니다.

#2: test 데이터셋이 존재하는지 확인하고, 에폭이 evaluate_begin보다 큰 경우 테스트를 진행합니다.

#3: 만약 검증 데이터셋이 존재한다면 검증 데이터셋을 사용해 평가하고, 그렇지 않은 경우 테스트 데이터셋을 사용합니다.

<br>

##### _evaluate_acc_f1

**[apc_trainer.py](https://github.com/yangheng95/PyABSA/blob/4320db7dd0cfa0053a48169e59ff44403482eaf1/pyabsa/core/apc/training/apc_trainer.py#L509)**

525 ~ 557 line

```python
def _evaluate_acc_f1(self, test_dataloader):
    # switch model to evaluation mode
    self.model.eval()  # 1
    n_test_correct, n_test_total = 0, 0  # 2
    t_targets_all, t_outputs_all = None, None
    with torch.no_grad():  # 3
        for t_batch, t_sample_batched in enumerate(test_dataloader):  # 4
            # 5
            t_inputs = {col: t_sample_batched[col].to(self.opt.device) for col in self.opt.inputs_cols}

            t_targets = t_sample_batched['polarity'].to(self.opt.device)

            t_outputs = self.model(t_inputs)

            if isinstance(t_outputs, dict):  # 6
                sen_outputs = t_outputs['logits']
            else:
                sen_outputs = t_outputs

            n_test_correct += (torch.argmax(sen_outputs, -1) == t_targets).sum().item()  # 7
            n_test_total += len(sen_outputs)

            if t_targets_all is None:  # 8
                t_targets_all = t_targets
                t_outputs_all = sen_outputs
            else:
                t_targets_all = torch.cat((t_targets_all, t_targets), dim=0)
                t_outputs_all = torch.cat((t_outputs_all, sen_outputs), dim=0)

    # 9
    test_acc = n_test_correct / n_test_total
    f1 = metrics.f1_score(t_targets_all.cpu(), torch.argmax(t_outputs_all, -1).cpu(), labels=list(range(self.opt.polarities_dim)), average='macro')
    return test_acc, f1
```

#1: 모델을 평가하기 위해, eval 모드로 변경합니다.

#2: 정확도를 측정하기 위해 맞춘 개수, 전체 테스트 개수를 0으로 초기화합니다.

#3: no_grad 메소드로 pytorch의 autograd 엔진을 종료 시킨다. cf) [Pytorch에서 no_grad()와 eval()의 정확한 차이는 무엇일까?](https://coffeedjimmy.github.io/pytorch/2019/11/05/pytorch_nograd_vs_train_eval/)

#4: 배치 사이즈만큼 데이터를 뽑아 테스트를 진행합니다.

#5: 훈련 코드와 동일하게 데이터에서 inputs_cols 열들을 뽑은 뒤, device로 할당합니다. 또한 실제 정답 레이블(감성 극성)도 device로 할당하고, model 입력으로 t_inputs를 넣어 outputs를 리턴 받습니다. outputs는 model에 입력 데이터를 넣었을 때의 예측값으로, logits와 loss 값이 dictionary로 담겨있습니다.

#6: outputs가 dictionary인지 확인하고 logits을 sen_outputs로 정의합니다.

#7: torch.argmax는 최대값을 갖는 인덱스를 반환하는데, 정답 레이블(t_targets)과 비교해 같은 것들을 sum 메소드로 더해 맞춘 개수를 계산한 뒤 이를 n_test_correct에 더해줍니다. sen_outputs의 길이는 n_test_total로 저장합니다.

#8: f1 score를 계산하기 위해 t_targets와 sen_outputs를 t_targets_all과 t_outputs_all에 저장합니다.

#9: 맞춘 개수 / 전체 개수로 정확도를 계산하고, scikit-learn의 metrics.f1_score를 이용해 f1 score를 계산한 뒤 결과를 리턴합니다.

<br>

다시 \_train_and_evaluate 메소드로 돌아와서,

##### _train_and_evaluate

244 ~ 251 line

```python
if global_step % self.opt.log_step == 0:
  if self.opt.dataset_file['test'] and epoch >= self.opt.evaluate_begin:
    if self.val_dataloaders:
      test_acc, f1 = self._evaluate_acc_f1(self.val_dataloaders[0])
    else:
      test_acc, f1 = self._evaluate_acc_f1(self.test_dataloader)

      # 1
      self.opt.metrics_of_this_checkpoint['acc'] = test_acc
      self.opt.metrics_of_this_checkpoint['f1'] = f1

      # 2
      sum_acc += test_acc
      sum_f1 += f1
```

\_evaluate_acc_f1 메소드로 리턴받은 test_acc와 f1을 opt에 저장한 뒤(#1) sum_acc와 sum_f1에 각각 더해줍니다.(#2)

<br>

256 ~ 302 line

코드가 좀 긴데, 테스트 정확도와 f1 score 둘 중 하나가 이전 기록보다 높은 경우(#1), 그렇지 않은 경우(#2)로 나눠서 보겠습니다.

```python
if test_acc > max_fold_acc or f1 > max_fold_f1:  # 1

    if test_acc > max_fold_acc:
        patience = self.opt.patience
        max_fold_acc = test_acc

    if f1 > max_fold_f1:
        max_fold_f1 = f1
        patience = self.opt.patience

    if self.opt.model_path_to_save:
        if not os.path.exists(self.opt.model_path_to_save):
            os.makedirs(self.opt.model_path_to_save)
        if save_path:
            try:
                shutil.rmtree(save_path)
                # logger.info('Remove sub-optimal trained model:', save_path)
            except:
                # logger.info('Can not remove sub-optimal trained model:', save_path)
                pass
        save_path = '{0}/{1}_{2}_acc_{3}_f1_{4}/'.format(self.opt.model_path_to_save,
                                                         self.opt.model_name,
                                                         self.opt.dataset_name,
                                                         round(test_acc * 100, 2),
                                                         round(f1 * 100, 2)
                                                         )

        if test_acc > self.opt.max_test_metrics['max_apc_test_acc']:
            self.opt.max_test_metrics['max_apc_test_acc'] = test_acc
        if f1 > self.opt.max_test_metrics['max_apc_test_f1']:
            self.opt.max_test_metrics['max_apc_test_f1'] = f1

        save_model(self.opt, self.model, self.tokenizer, save_path)

postfix = ('Epoch:{} | Loss:{:.4f} | Acc:{:.2f}(max:{:.2f}) |'
           ' F1:{:.2f}(max:{:.2f})'.format(epoch,
                                           loss.item(),
                                           test_acc * 100,
                                           max_fold_acc * 100,
                                           f1 * 100,
                                           max_fold_f1 * 100
                                           ))

else:  # 2
    if self.opt.save_mode and epoch >= self.opt.evaluate_begin:
        save_model(self.opt, self.model, self.tokenizer, save_path + '_{}/'.format(loss.item()))
    postfix = 'Epoch:{} | Loss: {} | No evaluation until epoch:{}'.format(epoch, round(loss.item(), 8), self.opt.evaluate_begin)
```

<br>

256 ~ 288 line

```python
if test_acc > max_fold_acc or f1 > max_fold_f1:  # 1
    # 2
    if test_acc > max_fold_acc:
        patience = self.opt.patience
        max_fold_acc = test_acc

    if f1 > max_fold_f1:
        max_fold_f1 = f1
        patience = self.opt.patience

    if self.opt.model_path_to_save:  # 3
        if not os.path.exists(self.opt.model_path_to_save):  # 4
            os.makedirs(self.opt.model_path_to_save)
        if save_path:
            try:  # 5
                shutil.rmtree(save_path)
                # logger.info('Remove sub-optimal trained model:', save_path)
            except:
                # logger.info('Can not remove sub-optimal trained model:', save_path)
                pass
        # 6
        save_path = '{0}/{1}_{2}_acc_{3}_f1_{4}/'.format(self.opt.model_path_to_save,
                                                         self.opt.model_name,
                                                         self.opt.dataset_name,
                                                         round(test_acc * 100, 2),
                                                         round(f1 * 100, 2))
        if test_acc > self.opt.max_test_metrics['max_apc_test_acc']:
            self.opt.max_test_metrics['max_apc_test_acc'] = test_acc
        if f1 > self.opt.max_test_metrics['max_apc_test_f1']:
            self.opt.max_test_metrics['max_apc_test_f1'] = f1

        # 8
        save_model(self.opt, self.model, self.tokenizer, save_path)

# 9
postfix = ('Epoch:{} | Loss:{:.4f} | Acc:{:.2f}(max:{:.2f}) |'
           ' F1:{:.2f}(max:{:.2f})'.format(epoch,
                                           loss.item(),
                                           test_acc * 100,
                                           max_fold_acc * 100,
                                           f1 * 100,
                                           max_fold_f1 * 100
                                           ))
```

#1: 정확도나 f1 score가 이전 기록보다 높은 경우 해당 조건문이 실행됩니다.

#2: 정확도와 f1 score 중 향상된 평가 지의 최대 스코어를 갱신하고, patience를 재설정합니다.

#3: 모델을 저장할 경로를 확인합니다. 만약 존재하지 않는다면, 새로 생성한 뒤(#4) 저장 경로의 하위 디렉토리와 파일을 모두 삭제합니다(#5)

#6: 저장할 경로와 파일명을 설정합니다.

#7: 이번에는 opt에 저장된 정확도와 f1 score 중 향상된 평가 지의 최대 스코어를 갱신합니다.

#8: save_model 메소드로 모델을 저장하고 마지막으로 tqdm 프로세스바에 표시할 메시지를 postfix로 설정합니다(#9)

<br>

299 ~ 307 line

```python
        else:  # 정확도나 f1 score가 향상되지 않은 경우
            if self.opt.save_mode and epoch >= self.opt.evaluate_begin:
                save_model(self.opt, self.model, self.tokenizer, save_path + '_{}/'.format(loss.item()))
            postfix = 'Epoch:{} | Loss: {} | No evaluation until epoch:{}'.format(epoch, round(loss.item(), 8), self.opt.evaluate_begin)

    # tqdm refresh
    iterator.postfix = postfix
    iterator.refresh()
if patience < 0:
    break
```

정확도나 f1 score가 향상되지 않은 경우 해당 코드가 실행됩니다. evaluate_begin보다 에폭이 큰 경우 save_model 메소드를 통해 모델을 저장합니다.

마찬가지로 tqdm 프로세스바에 표시할 메시지를 postfix로 설정합니다. 이후 tqdm 프로세스바를 리프레쉬 해줍니다.

만약 훈련을 진행하다 patience가 0보다 작아지면, 훈련을 중지합니다.

<br>

모델을 저장하는 save_model 메소드를 간단하게 살펴보겠습니다.

save_model 메소드는 [PyABSA/pyabsa/utils/file_utils.py](https://github.com/yangheng95/PyABSA/blob/42aac7857fd6fb781184433f68063581ed1c3cc4/pyabsa/utils/file_utils.py#L242)에 정의돼 있습니다.

**file_utils.py**

242 ~ 290 line

```python
def save_model(opt, model, tokenizer, save_path):
    # Save a trained model, configuration and tokenizer
    if hasattr(model, 'module') or hasattr(model, 'core'):  # 1
        # print("save model from data-parallel!")
        model_to_save = model.module
    else:
        # print("save a single cuda model!")
        model_to_save = model
```

#1: model이 module이나 core 속성을 갖고 있는지 확인한 뒤 model_to_save에 저장합니다.

configuration에 save_mode라는 변수가 저장돼 있는데, 이에 따라 save_model 메소드가 다르게 동작합니다. save_mode별로 어떻게 동작하는지 나눠서 보겠습니다.

<br>

**file_utils.py**

250 ~ 263 line

```python
if opt.save_mode == 1 or opt.save_mode == 2:
  if not os.path.exists(save_path):  # 1
    os.makedirs(save_path)
    # 2
    f_config = open(save_path + opt.model_name + '.config', mode='wb')
    f_tokenizer = open(save_path + opt.model_name + '.tokenizer', mode='wb')
    pickle.dump(opt, f_config)
    pickle.dump(tokenizer, f_tokenizer)
    f_config.close()
    f_tokenizer.close()
    # 3
    save_args(opt, save_path + opt.model_name + '.args.txt')
    if opt.save_mode == 1:  # 4
      torch.save(model_to_save.state_dict(), save_path + opt.model_name + '.state_dict')  # save the state dict
    elif opt.save_mode == 2:
      torch.save(model.cpu(), save_path + opt.model_name + '.model')  # save the state dict
```

먼저 save_mode가 1이나 2인 경우입니다.

#1: 저장 경로가 존재하는지 확인하고 없는 경우 디렉토리를 생성합니다.

#2: configurationr과 tokenizer를 pickle 모듈로 dump합니다.

#3: save_args 메소드는 [PyABSA/pyabsa/utils/pyabsa_utils.py](https://github.com/yangheng95/PyABSA/blob/42aac7857fd6fb781184433f68063581ed1c3cc4/pyabsa/utils/pyabsa_utils.py#L27)에 정의된 메소드로 txt 파일로 configuration에 저장된 인자들을 저장합니다.

```python
def save_args(config, save_path):
    f = open(os.path.join(save_path), mode='w', encoding='utf8')
    for arg in config.args:
        if config.args_call_count[arg]:
            f.write('{}: {}\n'.format(arg, config.args[arg]))
    f.close()
```

save_mode가 1인 경우(#4) state_dict 형태로, save_mode가 2인 경우(#5)에는 model.cpu로 저장합니다.

<br>

**file_utils.py**

265 ~ 286 line

```python
  elif opt.save_mode == 3:
      # save the fine-tuned bert model
      # 1
      model_output_dir = save_path + 'fine-tuned-pretrained-model'
      if not os.path.exists(model_output_dir):
          os.makedirs(model_output_dir)

      # 2
      output_model_file = os.path.join(model_output_dir, 'pytorch_model.bin')
      output_config_file = os.path.join(model_output_dir, 'config.json')

      # 3
      if hasattr(model_to_save, 'bert4global'):
          model_to_save = model_to_save.bert4global
      elif hasattr(model_to_save, 'bert'):
          model_to_save = model_to_save.bert
      else:
          model_to_save = model_to_save
          # raise RuntimeError('No pretrained model found to save')

      torch.save(model_to_save.state_dict(), output_model_file)
      model_to_save.config.to_json_file(output_config_file)

      # 4
      if hasattr(tokenizer, 'tokenizer'):
          tokenizer.tokenizer.save_pretrained(model_output_dir)
      else:
          tokenizer.save_pretrained(model_output_dir)
```

다음은 save_mode가 3인 경우입니다. fine-tuning한 모델을 저장할 때 사용하는 것 같습니다.

#1: 저장 경로를 fine-tuned-pretrained-model로 바꾸고, 경로가 없는 경우 디렉토리를 생성합니다.

#2: 모델과 configuration을 저장하기 위해 os.path.join으로 경로를 생성합니다.

#3: 모델이 bert4global, bert 속성을 갖고 있는 경우(저 속성이 뭘까요 ¿) 모델을 변경해주고, torch.save로 저장합니다.

또 config.to_json_file 메소드로 configuration을 json 파일로 저장합니다.

#4: 마지막으로 토크나이저를 저장합니다.

<br>

**file_utils.py**

288 ~ 290 line

```python
  else:
      raise ValueError('Invalid save_mode: {}'.format(opt.save_mode))
  model.to(opt.device)
```

만약 save_mode가 1, 2, 3이 아닌 경우 ValueError를 발생시킵니다.

<br>

다시 \_train_and_evaluate 메소드로 돌아와서 ❗️

309 ~ 311 line

```python
if not self.val_dataloaders:
  self.opt.MV.add_metric('Max-Test-Acc w/o Valid Set', max_fold_acc * 100)
  self.opt.MV.add_metric('Max-Test-F1 w/o Valid Set', max_fold_f1 * 100)
```

검증 데이터셋이 없는 경우 opt에 MetricVisualizer를 Max-Test로 추가합니다.

<br>

313 ~ 319 line

```python
if self.val_dataloaders:
  print('Loading best model: {} and evaluating on test set ...'.format(save_path))r
  self.reload_model(find_file(save_path, '.state_dict'))
  max_fold_acc, max_fold_f1 = self._evaluate_acc_f1(self.test_dataloader)

  self.opt.MV.add_metric('Max-Test-Acc', max_fold_acc * 100)
  self.opt.MV.add_metric('Max-Test-F1', max_fold_f1 * 100)
```

검증 데이터셋이 있는 경우에는 reload_model 메소드로 모델을 로드한 뒤, 테스트 데이터셋을 테스트 한 결과를 MetricVisualizer로 저장합니다.

이렇게 하는 이유는 246 ~ 247 line에서 검증 데이터셋이 있는 경우 검증 데이터셋으로 테스트 했기 때문입니다.

<br>

reload_model 메소드는 Instructor 클래스 멤버 함수로 120 ~ 125 line에 정의돼 있습니다.

```python
def reload_model(self, ckpt='./init_state_dict.bin'):
  if os.path.exists(ckpt):
    if self.opt.auto_device == 'allcuda':
      self.model.module.load_state_dict(torch.load(ckpt))
    else:
      self.model.load_state_dict(torch.load(ckpt))
```

<br>

다시 \_train_and_evaluate 메소드로 돌아와서 ❗️

322 ~ 325 line

```python
self.logger.info(self.opt.MV.summary(no_print=True))

print('Training finished, we hope you can share your checkpoint with community, please see:',
      'https://github.com/yangheng95/PyABSA/blob/release/demos/documents/share-checkpoint.md')
```

log를 기록하고 훈련을 마쳤다고 프롬프트에 출력합니다.

<br>

327 ~ 347 line

```python
if self.val_dataloader or self.opt.save_mode:  # 1
  del self.train_dataloaders
  del self.test_dataloader
  del self.val_dataloaders
  del self.model
  cuda.empty_cache()
  time.sleep(3)
  return save_path
else:  # 2
  # direct return model if do not evaluate
  # if self.opt.model_path_to_save:
  #     save_path = '{0}/{1}/'.format(self.opt.model_path_to_save,
  #                                   self.opt.model_name
  #                                   )
  #     save_model(self.opt, self.model, self.tokenizer, save_path)
  del self.train_dataloaders
  del self.test_dataloader
  del self.val_dataloaders
  cuda.empty_cache()
  time.sleep(3)
  return self.model, self.opt, self.tokenizer
```

#1: 검증 데이터로더 또는 opt에 save_mode가 존재하는 경우 데이터로더, 모델을 제거한 뒤 저장 경로를 리턴합니다.

#2: 데이터로더만 제거하고, gpu 캐시를 정리한 뒤 model, opt, tokenizer를 리턴합니다.

<br>

🧑‍🏫

##### 포스팅 내용 요약

Trainer 클래스 생성 ➡️ train4apc 메소드 호출 ➡️ Instructor 클래스 인스턴스 생성 ➡️ Instructor.run 메소드 실행 ➡️ Instructor.\_train 메소드 실행 ➡️  Instructor._k_fold_train_and_evaluate 또는 Instructor.\_train_and_evaluate 실행 (이 부분에서 gradient 계산 및 loss 값 계산) ➡️ self.model, self.opt, self.tokenizer 리턴 ➡️ model, opt, tokenizer를 인자로 Trainer 클래스에서 Aspect Extractor 클래스를 생성

<br>

##### Trainer, Instructor, APCEnsembler, AspectExtractor 정리

- Trainer: 모델과 관련된 다양한 클래스들(Instructor, AspectExtractor)을 생성
- Instructor: 실제 모델 생성(APCEnsembler) 및 훈련
- APCEnsembler: 모델 정의
- AspectExtractor: Aspect Term Extract & Sentiment Inference

<br>

아무래도 프레임워크다보니까 대부분의 함수가 모듈화 돼 있어, 왔다갔다 해서 헷갈릴 것 같습니다 😢

추후 시간이 된다면 다시 잘 정리해서 업로드 하도록 하겠습니다 ..
