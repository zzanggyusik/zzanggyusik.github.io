---
title:  "3.Evaluation"
excerpt: "평가"
toc: true
toc_label: "Evaluation"
toc_sticky: true

categories:
  - Machine Learning
tags:
  - Machine Learning
last_modified_at: 2021-07-05

---



>![파이썬 머신러닝 완벽 가이드](https://user-images.githubusercontent.com/76269316/122906446-1fa9c000-d38d-11eb-9cab-1eb7e347a1e6.png)
>
>파이썬 머신러닝 완벽 가이드를 읽고 공부한 내용을 정리한 포스팅입니다.



### 평가

머신러닝은 데이터 가공/변환, 모델 학습/예측, 평가의 프로세스로 구성됩니다.

이전 포스팅 [타이타닉 생존자 예제](https://seominseok4834.github.io/machine%20learning/2.scikit-learn-machine-learning-in-python/#%EC%82%AC%EC%9D%B4%ED%82%B7%EB%9F%B0%EC%9C%BC%EB%A1%9C-%EC%88%98%ED%96%89%ED%95%98%EB%8A%94-%ED%83%80%EC%9D%B4%ED%83%80%EB%8B%89-%EC%83%9D%EC%A1%B4%EC%9E%90-%EC%98%88%EC%B8%A1)에서는 모델 예측 성능 평가를 위해 정확도(Accuracy)를 사용했습니다.



성능 평가 지표(Evaluation Metric)는 일반적으로 모델이 분류냐 회귀냐에 따라 여러 종류로 나뉘는데,

회귀의 경우 대부분 실제값과 예측값의 오차 평균값에 기반하는데 (오차에 절댓값을 씌운 다음 평균 오차를 구하거나, 오차의 제곱값에 루트를 씌운 뒤 평균 오차를 구하는 방법등) 이는 이후 포스팅에서 설명하겠습니다.



이번 포스팅에서는 분류의 성능 평가 지표에 대해  다루도록 하겠습니다.

분류는 결정 클래스 값 종류의 유형에 따라 긍정/부정 2개 결괏값만을 갖는 이진 분류와 여러 개의 결정 클래스 값을 갖는 멀티 분류로 나뉩니다.

아래의 분류 성능 평가 지표는 이진/멀티 분류에 모두 적용할 수 있지만, 특히 이진 분류에서 중요합니다.

왜 이진 분류에서 중요한지 하나씩 설명하도록 하겠습니다.



분류의 성능 평가 지표

- 정확도 (Accuracy)
- 오차행렬 (Confusion Matrix)
- 정밀도 (Precision)
- 재현율 (Recall)
- F1 스코어
- ROC AUC



### 1. 정확도 (Accuracy)

<img src="https://user-images.githubusercontent.com/76269316/124422386-2a595180-dd9e-11eb-9ce0-3e76a6957078.png" alt="image" style="zoom: 80%;" />



정확도는 실제 데이터에서 예측 데이터가 얼마나 같은지를 판단하는 지표입니다.

직관적으로 모델 예측 성능을 평가할 수 있지만, 이진 분류의 경우 데이터 구성에 따라 ML 모델 성능을 왜곡할 수 있기 때문에 정확도 하나만 가지고 성능을 평가하진 않습니다.



타이타닉 생존자 예측 모델에서 여자인 경우 무조건 생존한다고 예측하고, 남자인 경우 사망한다고 예측할 경우 정확도를 측정해보겠습니다.



**transform_features()**

데이터 전처리를 위한 메소드

```python
from sklearn.preprocessing import LabelEncoder

#Null 처리 함수
def fillna(df):
    df['Age'].fillna(titanic_df['Age'].mean(), inplace=True)
    df['Cabin'].fillna('N', inplace=True)
    df['Embarked'].fillna('N', inplace=True)
    return df

#머신러닝 알고리즘에 불필요한 속성 제거
def drop_features(df):
    df.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)
    return df

#레이블 인코딩 수행
def format_features(df):
    df['Cabin'] = df['Cabin'].str[:1]
    features = ['Cabin', 'Sex', 'Embarked']
    for feature in features:
        le = LabelEncoder()
        le = le.fit(df[feature])
        df[feature] = le.transform(df[feature])
    return df

def transform_features(df):
    df = fillna(df)
    df = drop_features(df)
    df = format_features(df)
    return df
```



**MyDummyClassifier**

사이킷런 BaseEstimator 클래스를 상속받아 아무런 학습을 하지 않고, 성별에 따라 생존자를 예측하는 MyDummyClassifier 생성

```python
import numpy as np
import sklearn
from sklearn.base import BaseEstimator

class MyDummyClassifier(BaseEstimator):
    #fit 메소드는 아무것도 학습하지 않음
    def fit(self, X, y=None):
        pass
    
    #predict() 메소드는 단순히 Sex 피처값이 1이면 0, 0이면1로 예측
    def predict(self, X):
        pred = np.zeros((X.shape[0], 1))  #179X1개의 0으로 초기화된 ndarray 생성
        for i in range(X.shape[0]):
            if X['Sex'].iloc[i] == 1:  #i번째 Sex 피처값이 1이면 0으로 예측
                pred[i] = 0
            else:  #0이면 1로 예측
                pred[i] = 1  
        return pred
```



```python
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

#원본 데이터를 재로딩, 데이터 가공, 학습 데이터/테스트 데이터 분할
titanic_df = pd.read_csv('./titanic_train.csv')
y_titanic_df = titanic_df['Survived']
X_titanic_df = titanic_df.drop('Survived', axis=1)
X_titanic_df = transform_features(X_titanic_df)
X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, test_size=0.2, random_state=0)  #712개의 학습 데이터, 179개의 테스트 데이터

#MyDummyClassifier를 통해 학습/예측/정확도 평가
myclf = MyDummyClassifier()
myclf.fit(X_train, y_train)  #실제로는 아무것도 안함

mypredictions = myclf.predict(X_test)
print('Dummy Classifier 정확도: {0:.4f}'.format(accuracy_score(y_test, mypredictions)))
```

![image](https://user-images.githubusercontent.com/76269316/124424136-7954b600-dda1-11eb-8750-d9d42e6b0721.png)



실행 결과 78.77%의 정확도가 나왔습니다.

이렇게 단순한 알고리즘으로 예측하더라도, 데이터 구성에 따라 이렇게 높은 수치가 나올 수 있기 때문에 정확도를 평가 지표로 사용할 경우 조심해야합니다. (불균형한(imbalanced) 레이블 값 분포에서 ML 모델 성능 평가시 정확도는 적합한 평가 지표가 아님)



이번에는 MNIST 데이터 세트를 변한해 불균형한 데이터 세트로 만든 다음, 정확도를 측정해보겠습니다.

MNIST 데이터 세트는 0부터 9까지 숫자 이미지의 픽셀 정보를 갖고 있으며, 이를 기반으로 숫자 digit를 예측하는데 사용됩니다.

따라서 0부터 9까지의 멀티 label 값을 갖는데, 이것을 7만 true로하고 나머지 값은 모두 false로 변환해 이진 분류 문제로 바꾸겠습니다.

![image](https://user-images.githubusercontent.com/76269316/124425364-6511b880-dda3-11eb-9203-f19bfcce9ecd.png)



MNIST 데이터 세트의 label 분포를 보면

```python
import pandas as pd
import sklearn
from sklearn.datasets import load_digits

digits = load_digits()

digits_df = pd.DataFrame(data=digits, columns=digits.feature_names)
digits_df['label'] = digits.target
digits_df['label'].value_counts()
```

![image](https://user-images.githubusercontent.com/76269316/124428246-6b099880-dda7-11eb-89e4-ba71da6234ff.png)

7이 179개이고, 7을 제외한 나머지 숫자들이1618개입니다.

저희는 이 중 label 값이 7인 것들만 1로 변환하고 나머지는 0으로 변환하겠습니다.



**MyFakeClassifier**

```python
import numpy as np
import pandas as pd
import sklearn
from sklearn.datasets import load_digits
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.base import BaseEstimator

class MyFakeClassifier(BaseEstimator):
    def fit(self, X, y):  #fit 메소드는 아무것도 학습하지 않음
        pass
    
    #입력값으로 들어오는 X 데이터 세트의 크기만큼 모두 0 값으로 만들어서 반환 (전부 0으로 예측)
    def predict(self, X):
        return np.zeros((len(X), 1), dtype=bool)
    
#사이킷런 내장 데이터 세트인 load_digits()를 이용해 MNIST 데이터 로딩
digits = load_digits()

#digits 번호가 7이면 True이고 이를 astype(int)로 변환, 7이 아니면 False이고 0으로 변환
y = (digits.target == 7).astype(int)
print('0과 1의 분포도')
print(pd.Series(y).value_counts())
X_train, X_test, y_train, y_test = train_test_split(digits.data, y, random_state=11)
```

![image](https://user-images.githubusercontent.com/76269316/124428072-2e3da180-dda7-11eb-85b4-331323c54515.png)



다음과 같이 0이 1618개, 1이 179개인 이진 label로 변환 됐습니다.

이 데이터 세트를 가지고 MyFakeClassifier를 사용해 전부 다 0으로 예측한 다음, 정확도를 측정해보겠습니다.



```python
#불균형한 레이블 데이터 분포도 확인
print('레이블 테스트 세트 크기: ', y_test.shape)
print('테스트 세트 레이블 0과 1의 분포도')
print(pd.Series(y_test).value_counts())

#MyFakeClassifier로 학습/예측/정확도 평가
fakeclf = MyFakeClassifier()
fakeclf.fit(X_train, y_train)
fakepred = fakeclf.predict(X_test)
print('모든 예측을 0으로 해도 정확도는: {0:.3f}'.format(accuracy_score(y_test, fakepred)))
```

![image](https://user-images.githubusercontent.com/76269316/124428479-bc198c80-dda7-11eb-98b9-de19689ea67e.png)



모두 0으로 예측했음에도 불구하고 예측 정확도가 90%라는 높은 결과가 나왔습니다. 

이처럼 정확도 평가 지표는 불균형한 레이블 데이터 세트에서는 성능 수치로 사용돼서는 안 됩니다.

이러한 정확도의 한계점을 극복하기 위해서는 여러 가지 분류 지표와 함께 사용돼야 합니다.



### 2. 오차 행렬 (Confusion Matrix)

오차 행렬은 이진 분류의 예측 오류가 얼마인지와 더불어 어떤 유형의 예측 오류가 발생하고 있는지를 함께 나타내는 지표입니다.

다음과 같이 4분면 행렬에서 실제 레이블 클래스 값과 예측 레이블 클래스 값이 어떤 유형을 갖고 매핑되는지를 나타냅니다.

<img src="https://user-images.githubusercontent.com/76269316/124429422-d43ddb80-dda8-11eb-94e7-9862bd0cc5d8.png" alt="image" style="zoom: 67%;" />



앞 문자는 True/False로 예측값과 실제값이 같은지 틀린지를 나타내고, 뒤에 문자는 Negative/Positive로 예측 결과값이 부정(0), 긍정(1)을 의미합니다.



- TN : 예측값을 Negative(0)으로 예측했고 실제값 역시 Negative(0)
- FP : 예측값을 Positive(1)로 예측했는데 실제값은 Negative(0)
- FN : 예측값을 Negative(0)로 예측했는데 실제값은 Positive(1)
- TP : 예측값을 Positive(1)로 예측했고, 실제값 역시 Positive(1)



사이킷런은 오차 행렬을 구하기 위해 confusion_matrix() API를 제공합니다.

```python
from sklearn.metrics import confusion_matrix

confusion_matrix(y_test, fakepred)
```

![image](https://user-images.githubusercontent.com/76269316/124429914-7231a600-dda9-11eb-9d14-5b684ac94f60.png)



array[0, 0], array[0, 1], array[1,0], array[1,1]은 차례대로 TN, FP, FN, TP를 의미합니다.

위 결과에 따르면 TN은 405 (전체 450건 데이터 중 negative로 예측해서 true가 된 결과 405건), FN은 45 (전체 450건 데이터 중 negative로 예측해서 false가 된 결과 45건) 입니다.

전부 negative로 예측했기 때문에 FP, TP가 0인 것을 확인할 수 있습니다.



이 값을 조합해 Classifier 성능을 측정할 수 있는 주요 지표인 정확도 (Accuracy), 정밀도(Precision), 재현율(Recall) 값을 알 수 있습니다.



먼저, 정확도는 예측 결과와 실제 값이 동일한 건수 / 전체 데이터 수였으므로, 다음과 같이 재정의될 수 있습니다.

<img src="https://user-images.githubusercontent.com/76269316/124430538-42cf6900-ddaa-11eb-809f-b24c9098981e.png" alt="image" style="zoom:50%;" />



일반적으로 불균형한 레이블 클래스를 갖는 이진 분류 모델에서는 많은 데이터 중에서 중점적으로 찾아야 하는 적은 수의 결괏값에 positive를 설정해 1 값을 부여하고, 그렇지 않은 값에 negative로 0을 부여합니다.



예를 들어 사기 행위 예측 모델에서는 사기 행위를 postive로 정상 행위를 negative 값으로 할당하고, 암 검진 예측 모델에서는 양성일 경우 positive, 음성일 경우 negative로 할당합니다.



이런 불균형한 이진 분류 데이터 세트에서는 positive 건수가 매우 작으므로 데이터에 기반한 ML 알고리즘은 negative로 예측 정확도가 높아지는 경향(negative로 예측하려는 경향이 강해짐)이 발생합니다.

따라서 TN은 매우 커지고, TP는 매우 작아집니다. 또, negative로 예측할 때 정확도가 높기 때문에 FN 또한 작게되고, positive로 예측하는 경우도 적기 때문에 FP도 작아집니다.

<img src="https://user-images.githubusercontent.com/76269316/124431991-0bfa5280-ddac-11eb-80f1-87a26dfbcf16.png" alt="image" style="zoom: 67%;" />

*빨간색으로 표시한건 증가, 파란색으로 표시한건 감소*



결과적으로 positive에 대한 예측 정확도를 판단하지 못한 상태에서 negative에 대한 예측 정확도만 가지고 높은 정확도가 나타나는 수치적인 판단 오류가 발생하게 됩니다.



### 3. 정밀도와 재현율 (Precision, Recall)

정밀도와 재현율은 postivie 데이터 세트의 예측 성능에 좀 더 초점을 맞춘 평가 지표입니다.

바로 위 MyFakeClassifier는 positive로 예측한 값이 하나도 없으므로 정밀도와 재현율 값이 모두 0입니다.



<img src="https://user-images.githubusercontent.com/76269316/124432235-5e3b7380-ddac-11eb-8d50-af9b7e3d2527.png" alt="image" style="zoom:67%;" />

**정밀도**는 예측을 positive로 한 대상 중 예측과 실제 값이 positive로 일치한 데이터의 비율을 의미합니다.

분모는 예측을 positive로 한 모든 데이터 건수이며, 분자는 예측과 실제 값이 positive로 일치한 데이터 건수입니다.

positive 예측 성능을 더 정밀하게 측정하기 위한 평가 지표로 양성 예측도라고도 불립니다.



**재현율**은 실제 값이 positive인 대상 중에 에측과 실제 값이 positive로 일치한 데이터의 비율을 의미합니다.

분모는 실제 값이 positive인 모든 데이터 건수이고, 분자는 예측과 실제 값이 positive로 일치한 데이터 건수입니다.

민감도(Sensitivity) 또는 TPR(True Positive Rate)이라고도 불립니다.



정밀도와 재현율 중 이진 분류 모델 업무 특성에 따라 특정 지표가 더 중요한 지표로 간주될 수 있습니다.



재현율이 중요 지표인 경우는 실제 positive 데이터를 negative로 잘못 판단하게 되면 업무상 큰 영향이 발생하는 경우입니다.

예를 들어 암 판단 모델의 경우 실제 양성(positive)인 암 환자를 음성(negative)으로 잘못 판단할 경우 환자가 목숨을 잃을 수 있기 때문에 재현율이 중요합니다.

+음성인 환자를 양성으로 예측(양성이라고 예측했는데 음성이였음 - FP)해도 재검사를 해야하는 금전적 추가 비용이 따르지만 생명에는 지장이 없으므로 상관이 없는데, 양성인 환자를 음성으로 예측(음성으로 예측했는데 양성이였음 - FN)하면 늦장 대응으로 생명에 지장이 갈 수도 있음

→ FN이 중요 → 재현율 중요



정밀도가 중요 지표인 경우는 실제 negative 데이터를 positive로 잘못 판단하게 되면 업무상 큰 영향이 발생하는 경우입니다.

스팸 메일 여부를 판단하는 모델의 경우 실제 스팸 메일(positive)을 일반 메일(negative)로 분류해도 사용자가 불편함을 느낄 뿐이지만, 

일반 메일(negative)을 스팸 메일(positive)로 분류할 경우 만약 업무 관련 메일이였을 경우 업무에 차질이 생기게 됩니다. 

+스팸 메일을 일반 메일로 분류(일반메일이라고 예측했는데 스팸 메일이였음 - FN)해도 상관없지만 일반 메일을 스팸 메일로 분류(스팸 메일이라고 예측했는데 일반 메일이였음 - FP)하면 문제가 생김

→ FP가 중요 → 정밀도 중요



따라서 스팸 메일 여부 판단 모델의 경우에는 정밀도가 중요합니다.



타이타닉 생존자 예측 모델에서의 오차 행렬, 정확도, 정밀도, 재현율을 구해보겠습니다.



**transform_features()**

데이터 전처리를 위한 메소드

```python
from sklearn.preprocessing import LabelEncoder

#Null 처리 함수
def fillna(df):
    df['Age'].fillna(titanic_df['Age'].mean(), inplace=True)
    df['Cabin'].fillna('N', inplace=True)
    df['Embarked'].fillna('N', inplace=True)
    return df

#머신러닝 알고리즘에 불필요한 속성 제거
def drop_features(df):
    df.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)
    return df

#레이블 인코딩 수행
def format_features(df):
    df['Cabin'] = df['Cabin'].str[:1]
    features = ['Cabin', 'Sex', 'Embarked']
    for feature in features:
        le = LabelEncoder()
        le = le.fit(df[feature])
        df[feature] = le.transform(df[feature])
    return df

def transform_features(df):
    df = fillna(df)
    df = drop_features(df)
    df = format_features(df)
    return df
```



**get_clf_eval()**

오차 행렬, 정확도, 정밀도, 재현율을 한 번에 계산하기 위한 메소드

```python
import sklearn
from sklearn.metrics import accuracy_score, precision_score,recall_score, confusion_matrix

def get_clf_eval(y_test, pred):
    confusion = confusion_matrix(y_test, pred)
    accuracy = accuracy_score(y_test, pred)
    precision = precision_score(y_test, pred)
    recall = recall_score(y_test, pred)
    print('오차 행렬')
    print(confusion)
    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}'.format(accuracy, precision, recall))
```

```python
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression

#원본 데이터를 재로딩, 데이터 가공, 학습 데이터/테스트 데이터 분할
titanic_df = pd.read_csv('./titanic_train.csv')
y_titanic_df = titanic_df['Survived']
X_titanic_df = titanic_df.drop('Survived', axis=1)
X_titanic_df = transform_features(X_titanic_df)

X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, test_size=0.2, random_state=11)  #712개의 학습 데이터, 179개의 테스트 데이터

lr_clf = LogisticRegression()

lr_clf.fit(X_train, y_train)
pred = lr_clf.predict(X_test)
get_clf_eval(y_test, pred)
```

![image](https://user-images.githubusercontent.com/76269316/124438544-474c4f80-ddb3-11eb-9698-25b208b813f9.png)



다음과 같이 정밀도가 재현율에 비해 낮게 나왔습니다. 정밀도(또는 재현율)를 강화하는 방법에 대해 알아보도록 하겠습니다.



##### 정밀도/재현율 트레이드오프

정밀도 또는 재현율을 높이기 위해 분류의 결정 임계값(threshold)을 조정해 정밀도 또는 재현율의 수치를 높일 수 있습니다.

하지만, 정밀도와 재현율은 상호 보완적인 평가 지표이기 때문에 어느 한쪽을 강제로 높이면 다른 하나의  수치는 떨어지게 됩니다.

이를 정밀도/재현율의 트레이드오프(Trade-off)라고 부릅니다.



사이킷런의 분류 알고리즘은 예측 데이터가 특정 레이블(결정 클래스 값)에 속하는지를 계산하기 위해 개별 레이블별로 결정 확률을 구합니다.

그런 다음, 예측 확률이 분류 결정 임계값보다 큰 레이블값으로 예측하게 됩니다.

predict_proba 메소드를 사용하면 테스트 피처 레코드의 개별 클래스 예측 확률을 반환합니다.



타이타닉 생존자 예측 모델의 예측 확률과 그에 따른 예측 결과를 확인해보겠습니다.

**transform_features()**

```python
from sklearn.preprocessing import LabelEncoder

#Null 처리 함수
def fillna(df):
    df['Age'].fillna(titanic_df['Age'].mean(), inplace=True)
    df['Cabin'].fillna('N', inplace=True)
    df['Embarked'].fillna('N', inplace=True)
    return df

#머신러닝 알고리즘에 불필요한 속성 제거
def drop_features(df):
    df.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)
    return df

#레이블 인코딩 수행
def format_features(df):
    df['Cabin'] = df['Cabin'].str[:1]
    features = ['Cabin', 'Sex', 'Embarked']
    for feature in features:
        le = LabelEncoder()
        le = le.fit(df[feature])
        df[feature] = le.transform(df[feature])
    return df

def transform_features(df):
    df = fillna(df)
    df = drop_features(df)
    df = format_features(df)
    return df
```

```python
import numpy as np
import pandas as pd
import sklearn
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression

#원본 데이터를 재로딩, 데이터 가공, 학습 데이터/테스트 데이터 분할
titanic_df = pd.read_csv('./titanic_train.csv')
y_titanic_df = titanic_df['Survived']
X_titanic_df = titanic_df.drop('Survived', axis=1)
X_titanic_df = transform_features(X_titanic_df)

X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, test_size=0.2, random_state=11)  #712개의 학습 데이터, 179개의 테스트 데이터

lr_clf = LogisticRegression()

lr_clf.fit(X_train, y_train)
pred = lr_clf.predict(X_test)
```

```python
pred = lr_clf.predict(X_test)
print('pred_proba() 결과 Shape: {0}'.format(pred_proba.shape))
print('pred_proba array에서 위의 3개만 샘플 추출\n', pred_proba[:3])

#예측 확률 array와 예측 결과값 array를 병합해 예측 확률과 결과값 확인
pred_proba_result = np.concatenate([pred_proba, pred.reshape(-1, 1)], axis=1)
print('두 개의 class 중에서 더 큰 확률을 클래스 값으로 예측\n', pred_proba_result[:3])
```

![image](https://user-images.githubusercontent.com/76269316/124441107-52ed4580-ddb6-11eb-8faa-90c360490c3a.png)



맨 밑에 있는 실행 결과를 보면 첫 번째 column이 0에 대한 확률, 두 번째 column이 1에 대한 확률입니다.

세 번째 column에는 최종 예측한 결과가 있습니다.



첫 번째 row를 보면 1이 될 확률이 약 53.83%이고, 0이 될 확률운 약 46.16%인데 이 두 확률 중 임계값인 50%보다 큰 확률인 1로 최종 예측하였고, 따라서 label 값이 1로 예측된 것을 확인할 수 있습니다.



이러한 구현을 사이킷런 Binarizer 클래스를 사용하여 해보도록 하겠습니다.

```python
from sklearn.preprocessing import Binarizer

X = [[1, -1, 2],
     [2, 0, 0],
     [0, 1.1, 1.2]]

#X의 개별 원소들이 threshold 값보다 작거나 같으면 0을, 크면 1 리턴
binarizer = Binarizer(threshold=1.1)
print(binarizer.fit_transform(X))
```

![image](https://user-images.githubusercontent.com/76269316/124442095-58975b00-ddb7-11eb-8f5c-0f102174c2fb.png)



다음과 같이 임계값(1.1) 보다 큰 값인 2, 2, 1.2만 1로 반환된 것을 볼 수 있습니다.



위 타이타닉 생존자 예측 모델에서 predict() 메소드를 적용한 것은 실은, predict_proba() 메소드로 구한 각 클래스별 예측 확률값인 pred_proba 객체 변수에 분류 결정 임계값(threshold)을 0.5로 지정한 다음, 최종 예측값을 구하는 식으로 동작합니다.

이를 Binarizer 클래스를 사용해 사이킷런 predict()의 의사(pseudo) 코드로 만들어보겠습니다.

**get_clf_eval()**

```python
import sklearn
from sklearn.metrics import accuracy_score, precision_score,recall_score, confusion_matrix

def get_clf_eval(y_test, pred):
    confusion = confusion_matrix(y_test, pred)
    accuracy = accuracy_score(y_test, pred)
    precision = precision_score(y_test, pred)
    recall = recall_score(y_test, pred)
    print('오차 행렬')
    print(confusion)
    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}'.format(accuracy, precision, recall))
```



```python
from sklearn.preprocessing import Binarizer

#Binarizer의 분류 결정 임계값
custom_threshold = 0.5

#predict_proba() 반환값의 두 번째 column(Positive 클래스 column)만 추출해서 Binarizer 적용
pred_proba_1 = pred_proba[:, 1].reshape(-1, 1)

binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_1)
custom_predict = binarizer.transform(pred_proba_1)

get_clf_eval(y_test, custom_predict)
```

![image](https://user-images.githubusercontent.com/76269316/124443399-9b0d6780-ddb8-11eb-9b6c-df368598b8ab.png)

이 코드로 계산된 값과 앞에서 logistic regression classifier 객체에서 호출된 predict()로 계산된 지표값과 정확하게 동일한 것을 볼 수 있습니다.

predict()는 predict_proba()에 기반하여 생성된 API이기 때문입니다.



이 분류 결정 임계값을 0.4로 낮춰보겠습니다.

```python
from sklearn.preprocessing import Binarizer

#Binarizer의 분류 결정 임계값
custom_threshold = 0.4

#predict_proba() 반환값의 두 번째 column(Positive 클래스 column)만 추출해서 Binarizer 적용
pred_proba_1 = pred_proba[:, 1].reshape(-1, 1)

binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_1)
custom_predict = binarizer.transform(pred_proba_1)

get_clf_eval(y_test, custom_predict)
```

![image](https://user-images.githubusercontent.com/76269316/124444484-9dbc8c80-ddb9-11eb-8cf3-f3cbb69bafe3.png)



실행 결과, 정밀도가 떨어지고 재현율이 올라갔습니다.



![image](https://user-images.githubusercontent.com/76269316/124445451-87630080-ddba-11eb-8a42-899cea80c606.png)



분류 결정 임계값은 positive 예측값을 결정하는 확률의 기준이 됩니다. 분류 결정 임계값이 0.4로 내려가면 positive로 예측을 더 너그럽게 하기 때문에 true 값이 많아지게 됩니다.



임계값이 낮아지면서 TP가 48에서 51로 늘었고, FN이 13에서 10으로 줄었습니다. 따라서 재현율이 0.8361로 좋아졌고,

FP는 14에서 19로 늘면서 정밀도가 0.7286으로 나빠졌습니다.

![image](https://user-images.githubusercontent.com/76269316/124446314-46b7b700-ddbb-11eb-88ee-1a98a0b02246.png)



임계값을 0.4에서 0.6까지 0.05씩 증가시키면서 평가 지표를 조사하겠습니다.



**get_clf_eval**

오차 행렬, 정확도, 정밀도, 재현율을 한 번에 계산하기 위한 메소드

```python
import sklearn
from sklearn.metrics import accuracy_score, precision_score,recall_score, confusion_matrix

def get_clf_eval(y_test, pred):
    confusion = confusion_matrix(y_test, pred)
    accuracy = accuracy_score(y_test, pred)
    precision = precision_score(y_test, pred)
    recall = recall_score(y_test, pred)
    print('오차 행렬')
    print(confusion)
    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}'.format(accuracy, precision, recall))
```



**get_eval_by_threshold()**

임계값에 따라 get_clf_eval 메소드를 호출

```python
#테스트를 수행할 모든 임계값을 리스트 객체로 저장
thresholds = [0.4, 0.45, 0.50, 0.55, 0.60]

def get_eval_by_threshold(y_test, pred_proba_c1, thresholds):
    #thresholds list 객체 내의 값을 차례로 iteration하면서 evaluation 수행
    for custom_threshold in thresholds:
        binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_c1)
        custom_predict = binarizer.transform(pred_proba_c1)
        print('임계값: ', custom_threshold)
        get_clf_eval(y_test, custom_predict)
```

```python
import numpy as np
import pandas as pd
import sklearn
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression

#원본 데이터를 재로딩, 데이터 가공, 학습 데이터/테스트 데이터 분할
titanic_df = pd.read_csv('./titanic_train.csv')
y_titanic_df = titanic_df['Survived']
X_titanic_df = titanic_df.drop('Survived', axis=1)
X_titanic_df = transform_features(X_titanic_df)

X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, test_size=0.2, random_state=11)  #712개의 학습 데이터, 179개의 테스트 데이터

lr_clf = LogisticRegression()

lr_clf.fit(X_train, y_train)
pred_proba = lr_clf.predict_proba(X_test)
get_eval_by_threshold(y_test, pred_proba[:, 1].reshape(-1, 1), thresholds)
```

![image](https://user-images.githubusercontent.com/76269316/124451420-52f24300-ddc0-11eb-9e9d-ed19279fad87.png)



실행 결과 임계값이 0.45일 때 디폴트 0.5인 경우와 비교해서 정확도는 동일하고, 정밀도는 약간 떨어졌으나 재현율이 향상 됐습니다.



위에서는 get_eval_by_threshold 사용자 정의 함수를 사용했는데, 사이킷런에서는 precision_recall_curve() API를 제공합니다.

**precision_recall_curve()**

|                        입력 파라미터                         |                           반환 값                            |
| :----------------------------------------------------------: | :----------------------------------------------------------: |
| y_true : 실제 클래스값 배열 (배열 크기 = [데이터 건수])<br />probas_pred : positive column의 예측 확률 배열 (배열 크기 = [데이터 건수]) | 정밀도 : 임계값별 정밀도 값을 배열로 반환<br />재현율 : 임계값별 재현율 값을 배열로 반환 |

precision_recall_curve()를 이용해 타이타닉 예측 모델의 임계값별 정밀도와 재현율을 구해보겠습니다.



**transform_features()**

데이터 전처리를 위한 메소드

```python
from sklearn.preprocessing import LabelEncoder

#Null 처리 함수
def fillna(df):
    df['Age'].fillna(titanic_df['Age'].mean(), inplace=True)
    df['Cabin'].fillna('N', inplace=True)
    df['Embarked'].fillna('N', inplace=True)
    return df

#머신러닝 알고리즘에 불필요한 속성 제거
def drop_features(df):
    df.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)
    return df

#레이블 인코딩 수행
def format_features(df):
    df['Cabin'] = df['Cabin'].str[:1]
    features = ['Cabin', 'Sex', 'Embarked']
    for feature in features:
        le = LabelEncoder()
        le = le.fit(df[feature])
        df[feature] = le.transform(df[feature])
    return df

def transform_features(df):
    df = fillna(df)
    df = drop_features(df)
    df = format_features(df)
    return df
```

```python
import numpy as np
import pandas as pd
import sklearn
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression

#원본 데이터를 재로딩, 데이터 가공, 학습 데이터/테스트 데이터 분할
titanic_df = pd.read_csv('./titanic_train.csv')
y_titanic_df = titanic_df['Survived']
X_titanic_df = titanic_df.drop('Survived', axis=1)
X_titanic_df = transform_features(X_titanic_df)

X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, test_size=0.2, random_state=11)  #712개의 학습 데이터, 179개의 테스트 데이터

lr_clf = LogisticRegression()

lr_clf.fit(X_train, y_train)
```

```python
from sklearn.metrics import precision_recall_curve

#레이블 값이 1일 때의 예측 확률 추출
pred_proba_class1 = lr_clf.predict_proba(X_test)[:, 1]

#실제값 데이터 세트와 레이블 값이 1일 때의 예측 확률을 precision_recall_curve 인자로 입력
precisions, recalls, thresholds = precision_recall_curve(y_test, pred_proba_class1)
print('반환된 분류 결정 임계값 배열의 shape: ', thresholds.shape)

#반환된 임계값 배열 row가 143건이므로 샘플로 10건만 추출, 임계값을 15 step으로 추출
thr_index = np.arange(0, thresholds.shape[0], 15)
print('샘플 추출을 위한 임계값 배열의 index 10개: ',thr_index)
print('샘플용 10개의 임계값: ', np.round(thresholds[thr_index], 2))

#15 step 단위로 추출된 임계값에 따른 정밀도와 재현율 값
print('샘플 임계값별 정밀도: ', np.round(precisions[thr_index], 3))
print('샘플 임계값별 재현율: ', np.round(recalls[thr_index], 3))
```

![image](https://user-images.githubusercontent.com/76269316/124453460-5981ba00-ddc2-11eb-9d94-b86df8f70d63.png)



추출된 샘플 10개에 해당하는 정밀도와 재현율을 보면, 임계값이 증가할수록 정밀도도 증가하나, 재현율 값이 낮아지는 것을 볼 수 있습니다.

precision_recall_curve() API는 정밀도와 재현율의 임계값에 따른 값 변화를 곡선 형태의 그래프로 시각화할 수 있습니다.



**transform_features()**

데이터 전처리를 위한 메소드

```python
from sklearn.preprocessing import LabelEncoder

#Null 처리 함수
def fillna(df):
    df['Age'].fillna(titanic_df['Age'].mean(), inplace=True)
    df['Cabin'].fillna('N', inplace=True)
    df['Embarked'].fillna('N', inplace=True)
    return df

#머신러닝 알고리즘에 불필요한 속성 제거
def drop_features(df):
    df.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)
    return df

#레이블 인코딩 수행
def format_features(df):
    df['Cabin'] = df['Cabin'].str[:1]
    features = ['Cabin', 'Sex', 'Embarked']
    for feature in features:
        le = LabelEncoder()
        le = le.fit(df[feature])
        df[feature] = le.transform(df[feature])
    return df

def transform_features(df):
    df = fillna(df)
    df = drop_features(df)
    df = format_features(df)
    return df
```



```python
import numpy as np
import pandas as pd
import sklearn
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression

#원본 데이터를 재로딩, 데이터 가공, 학습 데이터/테스트 데이터 분할
titanic_df = pd.read_csv('./titanic_train.csv')
y_titanic_df = titanic_df['Survived']
X_titanic_df = titanic_df.drop('Survived', axis=1)
X_titanic_df = transform_features(X_titanic_df)

X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, test_size=0.2, random_state=11)  #712개의 학습 데이터, 179개의 테스트 데이터

lr_clf = LogisticRegression()

lr_clf.fit(X_train, y_train)
```



**precision_recall_curve_plot()**

정밀도와 재현율을 시각화해주는 메소드

```python
from sklearn.metrics import precision_recall_curve
import matplotlib.pyplot as plt
import matplotlib.ticker as ticker
%matplotlib inline

def precision_recall_curve_plot(y_test, pred_proba_c1):
    #threshold ndarray와 threshold에 따른 정밀도, 재현율 ndarray 추출
    precisions, recalls, thresholds = precision_recall_curve(y_test, pred_proba_c1)
    
    #X축을 threshold 값으로, Y축은 정밀도, 재현율 값으로 각각 plot 실행. (정밀도는 점선으로 표시_
    plt.figure(figsize=(8, 6))
    threshold_boundary = thresholds.shape[0]
    plt.plot(thresholds, precisions[0:threshold_boundary], linestyle='--', label='precision')
    plt.plot(thresholds, recalls[0:threshold_boundary], label='recall')
    
    #threshold 값 X축의 scale을 0.1 단위로 변경
    start, end = plt.xlim()  #X축 범위 반환
    plt.xticks(np.round(np.arange(start, end, 0.1), 2))  #X축에 눈금 표시
    
    #X축, Y축 label과 legend, grid 설정
    plt.xlabel('Threshold value'); plt.ylabel('Precision and Recall value')
    plt.legend(); plt.grid()  #범례, 격자 표시
    plt.show()
    
precision_recall_curve_plot(y_test, lr_clf.predict_proba(X_test)[:, 1])
```

<img src="https://user-images.githubusercontent.com/76269316/124455824-f6455700-ddc4-11eb-9605-bd517636e37e.png" alt="image" style="zoom:67%;" />



임계값을 변경함에 따라 정밀도와 재현율의 수치가 변합니다.

이런 변경은 두 개의 수치를 상호 보완할 수 있는 수준에서 적용돼야 하며, 단순히 하나의 성능 지표를 높이기 위한 수단으로 사용돼서는 안됩니다.



##### 정밀도가 100%가 되는 방법

확실한 기준이 되는 경우만 positive로 예측하고 나머지는 모두 negative로 예측합니다.

![image](https://user-images.githubusercontent.com/76269316/124456282-79ff4380-ddc5-11eb-8694-65fe3658095b.png)

예를 들어,  전체 환자 1000명 중 확실한 positive 징후만 가진 환자가 단 한명이라고 하면 이 한 명만 positive로 예측하고 나머지는 모두 negative로 예측하더라도 FP = 0, TP = 1이 되므로 1/(1+0)이 되서 100%가 되게 됩니다.



##### 재현율이 100%가 되는 방법

모든 환자를 positive로 예측합니다.

![image](https://user-images.githubusercontent.com/76269316/124456490-b763d100-ddc5-11eb-8522-bf79791d4cf7.png)

전체 환자 1000명을 다 positive로 예측하면 이 중 실제 양성인 사람이 30명이여도 TN이 수치에 포함되지 않고, FN은 아예 0이므로 30/(30+0)으로 100%가 됩니다.



다시 한 번 강조하지만 극단적으로 정밀도와 재현율 중 한 쪽만을 강조하는 상황이 돼서는 안됩니다.



### 4. F1 스코어 (F1 Score)

F1 스코어는 정밀도와 재현율을 결합한 지표입니다.

F1 스코어는 정밀도와 재현율이 어느 한 쪽으로  치우치지 않는 수치를 나타낼 때 상대적으로 높은 값을 갖습니다.

![image](https://user-images.githubusercontent.com/76269316/124457217-8506a380-ddc6-11eb-8396-7f14c9eca630.png)



사이킷런은 F1 스코어를 구하기 위해 f1_score()라는 API를 제공합니다.

이를 이용해 정밀도와  재현율 예제에서 학습/예측한 로지스틱 회귀 기반 타이타닉 생존자 모델의 F1 스코어를 구해보겠습니다.

**transform_features()**

데이터 전처리를 위한 메소드

```python
from sklearn.preprocessing import LabelEncoder

#Null 처리 함수
def fillna(df):
    df['Age'].fillna(titanic_df['Age'].mean(), inplace=True)
    df['Cabin'].fillna('N', inplace=True)
    df['Embarked'].fillna('N', inplace=True)
    return df

#머신러닝 알고리즘에 불필요한 속성 제거
def drop_features(df):
    df.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)
    return df

#레이블 인코딩 수행
def format_features(df):
    df['Cabin'] = df['Cabin'].str[:1]
    features = ['Cabin', 'Sex', 'Embarked']
    for feature in features:
        le = LabelEncoder()
        le = le.fit(df[feature])
        df[feature] = le.transform(df[feature])
    return df

def transform_features(df):
    df = fillna(df)
    df = drop_features(df)
    df = format_features(df)
    return df
```

```python
import numpy as np
import pandas as pd
import sklearn
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression

#원본 데이터를 재로딩, 데이터 가공, 학습 데이터/테스트 데이터 분할
titanic_df = pd.read_csv('./titanic_train.csv')
y_titanic_df = titanic_df['Survived']
X_titanic_df = titanic_df.drop('Survived', axis=1)
X_titanic_df = transform_features(X_titanic_df)

X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, test_size=0.2, random_state=11)  #712개의 학습 데이터, 179개의 테스트 데이터

lr_clf = LogisticRegression()

lr_clf.fit(X_train, y_train)
pred = lr_clf.predict(X_test)
```

```python
from sklearn.metrics import f1_score
f1 = f1_score(y_test, pred)
print('F1 스코어: {0:.4f}'.format(f1))
```

![image](https://user-images.githubusercontent.com/76269316/124458067-86849b80-ddc7-11eb-9fa3-6d9ca96b73b6.png)



임계값을 변화시키면서 F1 스코어를 포함한 평가 지표를 구해보겠습니다.

위에서 사용한 get_clf_eval()에 F1 스코어를 구하는 로직을 추가하겠습니다.

**transfor_features()**

데이터 전처리를 위한 메소드

```python
from sklearn.preprocessing import LabelEncoder

#Null 처리 함수
def fillna(df):
    df['Age'].fillna(titanic_df['Age'].mean(), inplace=True)
    df['Cabin'].fillna('N', inplace=True)
    df['Embarked'].fillna('N', inplace=True)
    return df

#머신러닝 알고리즘에 불필요한 속성 제거
def drop_features(df):
    df.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)
    return df

#레이블 인코딩 수행
def format_features(df):
    df['Cabin'] = df['Cabin'].str[:1]
    features = ['Cabin', 'Sex', 'Embarked']
    for feature in features:
        le = LabelEncoder()
        le = le.fit(df[feature])
        df[feature] = le.transform(df[feature])
    return df

def transform_features(df):
    df = fillna(df)
    df = drop_features(df)
    df = format_features(df)
    return df
```



**get_clf_eval**

오차 행렬, 정확도, 정밀도, 재현율, F1 score를 한 번에 계산하기 위한 메소드

```python
import sklearn
from sklearn.metrics import accuracy_score, precision_score,recall_score, confusion_matrix, f1_score

def get_clf_eval(y_test, pred):
    confusion = confusion_matrix(y_test, pred)
    accuracy = accuracy_score(y_test, pred)
    precision = precision_score(y_test, pred)
    recall = recall_score(y_test, pred)
    #F1 스코어 추가
    f1 = f1_score(y_test, pred)
    print('오차 행렬')
    print(confusion)
    #F1 스코어 print 추가
    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}, F1: {3:.4f}'.format(accuracy, precision, recall, f1))
```



**get_eval_by_threshold()**

임계값에 따라 get_clf_eval 메소드를 호출

```python
from sklearn.preprocessing import Binarizer

def get_eval_by_threshold(y_test, pred_proba_c1, thresholds):
    #thresholds list 객체 내의 값을 차례로 iteration하면서 evaluation 수행
    for custom_threshold in thresholds:
        binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_c1)
        custom_predict = binarizer.transform(pred_proba_c1)
        print('임계값: ', custom_threshold)
        get_clf_eval(y_test, custom_predict)
```



```python
import numpy as np
import pandas as pd
import sklearn
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression

#원본 데이터를 재로딩, 데이터 가공, 학습 데이터/테스트 데이터 분할
titanic_df = pd.read_csv('./titanic_train.csv')
y_titanic_df = titanic_df['Survived']
X_titanic_df = titanic_df.drop('Survived', axis=1)
X_titanic_df = transform_features(X_titanic_df)

X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, test_size=0.2, random_state=11)  #712개의 학습 데이터, 179개의 테스트 데이터

lr_clf = LogisticRegression()

lr_clf.fit(X_train, y_train)

thresholds = [0.4, 0.45, 0.50, 0.55, 0.60]
pred_proba = lr_clf.predict_proba(X_test)
get_eval_by_threshold(y_test, pred_proba[:, 1].reshape(-1, 1), thresholds)
```

![image](https://user-images.githubusercontent.com/76269316/124458983-9f418100-ddc8-11eb-9e27-8428891b704a.png)



임계값이 0.6일 때 F1 스코어가 가장 좋으나, 재현율이 크게 떨어졌습니다.



### 5. ROC 곡선과 AUC

ROC 곡선 (Receiver Operation Characteristic Curve)은 우리 말로 수신자 판단 곡선입니다. 

원래 2차 세계대전 때 통신 장비 성능 평가를 위해 고안된 수치인데, 일반적으로 의학 분야에서 많이 사용되지만 머신러닝의 이진 분류 모델의 예측 성능을 평가하는 중요한 지표로도 사용됩니다.



ROC 곡선은 FPR(False Positive Rate)이 변할 때, TPR(True Positive Rate)이 어떻게 변하는 지를 나타내는 곡선입니다. (FPR을 X축으로, TPR을 Y축으로 두고 그린 그래프)



TPR은 재현율을 나타냅니다. TPR에 대응하는 지표로 TNR(True Negative Rate)이라고 불리는 특이성(Specificity)이 있습니다.

- 민감도(TPR) : 실제값 positive가 정확히 예측돼야 하는 수준을 나타냄. (질병이 있는 사람은 질병이 있는 것으로 양성 판정)
- 특이성(TNR) : 실제값 negative가 정확히 예측돼야 하는 수준을 나타냄. (질병이 없는 건강한 사람은 질병이 없는 것으로 음성 판정)

![image](https://user-images.githubusercontent.com/76269316/124475751-09fcb780-dddd-11eb-836d-7210da1f8a9a.png)



FPR은 FP / (FP + TN)이므로 1 - TNR로 표현할 수 있습니다.

![image](https://user-images.githubusercontent.com/76269316/124476621-0289de00-ddde-11eb-89e3-0144aba6fac2.png)





![image](https://user-images.githubusercontent.com/76269316/124476999-762beb00-ddde-11eb-8dd1-5ab8e6585307.png)

다음은 ROC 곡선의 예입니다. 가운데 직선은 ROC 곡선의 최저 값으로, 동전을 무작위로 던져 앞/뒤를 맞추는 랜덤 수준의 이진 분류 ROC 직선입니다.

ROC 곡선이 가운데 직선에 가까울수록 성능이 떨어지는 것이며, 멀어질수록 성능이 뛰어난 것입니다.



ROC 곡선은 FPR을 0부터 1까지 변경하면서 TPR의 변화값을 구합니다.

FPR은 분류 결정 임계값을 변경함으로써 변경할 수 있습니다.

분류 결정 임계값은 positive 예측값을 결정하는 확률의 기준이기 때문에 FPR을 0으로 만들려면 임계값을 1로 지정하면 됩니다.

1로 지정하면 positive 예측 기준이 매우 높아 분류기(Classifier)가 임계값보다 높은 확률을 가진 데이터를 positive로 예측할 수 없게되어 FPR = FP / (FP+TN) 중 FP가 0이되어 FPR이 0이되게 됩니다.

FPR을 1로 만들기 위해서는 분류 결정 임계값을 0으로 만들면 됩니다. 그러면 분류기(Classifier)의 확률 기준이 너무 낮아 모두 positive로 예측하게 되고, negative 예측이 없어 TN이 0이 되게되어 FPR이 1이 됩니다.



사이킷런은 ROC 곡선을 구하기 위해 roc_curve() API를 제공합니다.

**roc_curve()**

|                        입력 파라미터                         |                           반환 값                            |
| :----------------------------------------------------------: | :----------------------------------------------------------: |
| y_true : 실제 클래스 값 array (array shape = [데이터 건수])<br />y_score : predict_proba()의 반환 값 array에서 positive column 예측 확률 (array shape = [n_samples]) | fpr : fpr 값을 array로 반환<br />tpr : tpr 값을 array로 반환<br />thresholds : threshold 값 array |



roc_curve()를 사용해 타이타닉 생존자 예측 모델의 FPR, TPR, 임계값을 구해보겠습니다.

**transform_features()**

데이터 전처리를 위한 메소드

```python
from sklearn.preprocessing import LabelEncoder

#Null 처리 함수
def fillna(df):
    df['Age'].fillna(titanic_df['Age'].mean(), inplace=True)
    df['Cabin'].fillna('N', inplace=True)
    df['Embarked'].fillna('N', inplace=True)
    return df

#머신러닝 알고리즘에 불필요한 속성 제거
def drop_features(df):
    df.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)
    return df

#레이블 인코딩 수행
def format_features(df):
    df['Cabin'] = df['Cabin'].str[:1]
    features = ['Cabin', 'Sex', 'Embarked']
    for feature in features:
        le = LabelEncoder()
        le = le.fit(df[feature])
        df[feature] = le.transform(df[feature])
    return df

def transform_features(df):
    df = fillna(df)
    df = drop_features(df)
    df = format_features(df)
    return df
```

```python
import numpy as np
import pandas as pd
import sklearn
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression

#원본 데이터를 재로딩, 데이터 가공, 학습 데이터/테스트 데이터 분할
titanic_df = pd.read_csv('./titanic_train.csv')
y_titanic_df = titanic_df['Survived']
X_titanic_df = titanic_df.drop('Survived', axis=1)
X_titanic_df = transform_features(X_titanic_df)

X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, test_size=0.2, random_state=11)  #712개의 학습 데이터, 179개의 테스트 데이터

lr_clf = LogisticRegression()

lr_clf.fit(X_train, y_train)
```

```python
from sklearn.metrics import roc_curve

#레이블 값이 1일 때의 예측 확률 추출
pred_proba_class1 = lr_clf.predict_proba(X_test)[:, 1]

fprs, tprs, thresholds = roc_curve(y_test, pred_proba_class1)

#반환된 임계값 배열에서 샘플로 데이터를 추출하되, 5 step 추출
#thresholds[0]은 max(예측확률) + 1로 임의 설정됨. 이를 제외하기 위해 np.arange는 1부터 시작
print('thresholds[0] : {0}'.format(thresholds[0]))
thr_index = np.arange(1, thresholds. shape[0], 5)
print('샘플 추출을 위한 임계값 배열의 index: ', thr_index)
print('샘플 index로 추출한 임계값: ', np.round(thresholds[thr_index], 2))

#5 step 단위로 추출된 임게값에 따른 FPR, TPR 값
print('샘플 임계값별 FPR: ', np.round(fprs[thr_index], 3))
print('샘플 임계값별 TPR: ', np.round(tprs[thr_index], 3))
```

![image](https://user-images.githubusercontent.com/76269316/124480337-1d5e5180-dde2-11eb-81b2-65b86af407c0.png)

 

thresholds[0]을 보면 1.9650··· 값이 나오므로 제외해주었고, 임계값이 1에 가까워질수록 FPR은 조금씩 커지고, TPR은 가파르게 커지는 것을 볼 수 있습니다.



ROC 곡선으로 시각화해보겠습니다.

```python
from sklearn.metrics import roc_curve
import matplotlib.pyplot as plt
import matplotlib.ticker as ticker
%matplotlib inline

def roc_curve_plot(y_test, pred_proba_c1):
    #임계값에 따른 FPR, TPR 값을 반환받음
    fprs, tprs, thresholds = roc_curve(y_test, pred_proba_c1)
    #ROC 곡선을 그래프 곡선으로 그림
    plt.plot(fprs, tprs, label='ROC')
    #가운데 대각선 직선을 그림
    plt.plot([0,1], [0,1], 'k--', label='Random')
    
    #FPR X축의 scale을 0.1 단위로 변경, X축, Y축 범위 지정
    start, end = plt.xlim()
    #X축에 눈금 표시
    plt.xticks(np.round(np.arange(start, end, 0.1), 2))
    plt.xlim(0, 1); plt.ylim(0, 1)
    plt.xlabel('FPR(1 - Sensitivity)'); plt.ylabel('TPR(Recall)')
    #범례 표시
    plt.legend()
    
roc_curve_plot(y_test, pred_proba[:, 1])
```

![image](https://user-images.githubusercontent.com/76269316/124481252-0b30e300-dde3-11eb-804a-19c149f5f8bc.png)



일반적으로 ROC 곡선 자체는 FPR과 TPR의 변화 값을 보는데 사용하며, 분류의 성능 지표로 사용되는 것은 AUC입니다.

AUC(Area Under Curve) 값은 ROC 곡선 밑의 면적을 구한 것으로서 일반적으로 1에 가까울수록 좋은 수치입니다.

AUC 수치가 커지려면 FPR이 작은 상태에서 얼마나 큰 TPR을 얻을 수 있느냐가 관건입니다. 

가운데 직선에서 멀어지고 왼쪽 상단 모서리 쪽으로 가파르게 곡선이 이동할수록 직사각형에 가까운 곡선이 되어 면적이 1에 가까워지게 됩니다.

가운데 대각선 직선은 랜덤 수준(동전 던지기 수준) 이진 분류 AUC 값으로 0.5입니다. 따라서 보통의 분류는 0.5 이상의 AUC 값을 갖습니다.



AUC도 마찬가지로 사이킷런에서 제공하는 roc_auc_score() API를 이용하여 구할 수 있습니다.

```python
from sklearn.metrics import roc_auc_score

pred_proba = lr_clf.predict_proba(X_test)[:, 1]
roc_score = roc_auc_score(y_test, pred_proba)
print('ROC AUC 값: {0:.4f}'.format(roc_score))
```

![image](https://user-images.githubusercontent.com/76269316/124481898-bd68aa80-dde3-11eb-91f3-487c6e17ca40.png)



위에서 계속 사용했던 get_clf_eval() 메소드에 ROC, AUC 값을 측정하는 로직을 추가합시다.

ROC, AUC는 예측 확률값을 기반으로 계산되므로 이를 get_clf_eval() 메소드의 인자로 받을 수 있도록 함수형을 변경해주고, roc_auc_score() 메소드를 추가해줍니다.

```python
import sklearn
from sklearn.metrics import accuracy_score, precision_score,recall_score, confusion_matrix, f1_score

def get_clf_eval(y_test, pred=None, pred_proba=None):
    confusion = confusion_matrix(y_test, pred)
    accuracy = accuracy_score(y_test, pred)
    precision = precision_score(y_test, pred)
    recall = recall_score(y_test, pred)
    f1 = f1_score(y_test, pred)
    #ROC-AUC 추가
    roc_auc = roc_auc_score(y_test, pred_proba)
    print('오차 행렬')
    print(confusion)
    #ROC-AUC print 추가
    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}, F1: {3:.4f}, AUC: {4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))
```



### 피마 인디언 당뇨병 예측

피마 인디언 당뇨병 (Pima Indian Diabetes) 데이터 세트를 이용해 당뇨병 여부를 판단하는 머신러닝 예측 모델을 수립하고 지금까지 설명한 평가 지표를 적용해보겠습니다.

데이터 세트는 [Pima Indians Diabetes Database](https://www.kaggle.com/uciml/pima-indians-diabetes-database)에서 받을 수 있습니다.



피마 인디언 당뇨병 데이터 세트는 다음 피처로 구성돼 있습니다.

- Pregnancies : 임신 횟수
- Glucose : 포도당 부하 검사 수치
- BloodPressure : 혈압(mm Hg)
- SkinThickness : 팔 삼두근 뒤쪽의 피하지방 측정값(mm)
- Insulin : 혈청 인슐린 (mu U/ml)
- BMI : 체질량 지수 (체중(kg)/(키(m))^2)
- DiabetesPedigreeFunction : 당뇨 내력 가중치 값
- Age : 나이
- Outcome : 클래스 결정 값 (0 또는 1)



내려받은 diabetes.csv 파일을 로딩 후에 Outcome 클래스 결정값의 분포와 데이터를 개략적으로 보겠습니다.

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
%matplotlib inline

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score
from sklearn.metrics import f1_score, confusion_matrix, precision_recall_curve, roc_curve
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression

diabetes_data = pd.read_csv('diabetes.csv')
print(diabetes_data['Outcome'].value_counts())
diabetes_data
```

![image](https://user-images.githubusercontent.com/76269316/124484272-3406a780-dde6-11eb-9ae9-afce7ac8c34f.png)

전체 768개 데이터 중에서 negative 값 0이 500개, positive 값 1이 268개로 negative가 상대적으로 많습니다.



feature 타입과 null 개수도 보도록 하겠습니다.

```python
diabetes_data.info()
```

![image](https://user-images.githubusercontent.com/76269316/124484527-78924300-dde6-11eb-81dd-8bae557edeea.png)

Null 값은 없고 feature 타입은 모두 숫자형입니다. 임신 횟수, 나이, 당뇨 검사 수치 피처로 구성된 특징으로 볼 때 별도의 피처 인코딩은 필요 없을 것 같습니다.



로지스틱 회귀를 이용해 예측 모델을 생성해보겠습니다.

**get_clf_eval**

오차 행렬, 정확도, 정밀도, 재현율, F1 score, AUC를 한 번에 계산하기 위한 메소드

```python
import sklearn
from sklearn.metrics import accuracy_score, precision_score,recall_score, confusion_matrix, roc_auc_score, f1_score

def get_clf_eval(y_test, pred=None, pred_proba=None):
    confusion = confusion_matrix(y_test, pred)
    accuracy = accuracy_score(y_test, pred)
    precision = precision_score(y_test, pred)
    recall = recall_score(y_test, pred)
    f1 = f1_score(y_test, pred)
    #ROC-AUC 추가
    roc_auc = roc_auc_score(y_test, pred_proba)
    print('오차 행렬')
    print(confusion)
    #ROC-AUC print 추가
    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}, F1: {3:.4f}, AUC: {4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))
```

```python
#피처 데이터 세트 X, 레이블 데이터 세트 y 추출
#맨 끝이 Outcome column으로 레이블 값임 (-1 인덱스를 이용해 추출)
X = diabetes_data.iloc[:, :-1]
y = diabetes_data.iloc[:, -1]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=156, stratify=y)  #stratify로 전달된 값의 비율과 같도록 분할

#로지스틱 회귀로 학습, 예측 및 평가 수행
lr_clf = LogisticRegression()
lr_clf.fit(X_train, y_train)
pred = lr_clf.predict(X_test)
pred_proba = lr_clf.predict_proba(X_test)[:, 1]

get_clf_eval(y_test, pred, pred_proba)
```

![image](https://user-images.githubusercontent.com/76269316/124485250-5a791280-dde7-11eb-857d-e782f16f3940.png)



예측 정확도가 77.27%가 재현율이 57.41%가 나왔습니다. 전체 데이터의 65%가 negative이므로 재현율 성능에 조금 더 초점을 맞춰보겠습니다.

이를 위해 precision_recall_curve_plot()을 사용해 정확도와 재현율 값을 그래프로 나타내보겠습니다.



**precision_recall_curve_plot()**

정밀도와 재현율을 시각화해주는 메소드

```python
from sklearn.metrics import precision_recall_curve
import matplotlib.pyplot as plt
import matplotlib.ticker as ticker
%matplotlib inline

def precision_recall_curve_plot(y_test, pred_proba_c1):
    #threshold ndarray와 threshold에 따른 정밀도, 재현율 ndarray 추출
    precisions, recalls, thresholds = precision_recall_curve(y_test, pred_proba_c1)
    
    #X축을 threshold 값으로, Y축은 정밀도, 재현율 값으로 각각 plot 실행. (정밀도는 점선으로 표시_
    plt.figure(figsize=(8, 6))
    threshold_boundary = thresholds.shape[0]
    plt.plot(thresholds, precisions[0:threshold_boundary], linestyle='--', label='precision')
    plt.plot(thresholds, recalls[0:threshold_boundary], label='recall')
    
    #threshold 값 X축의 scale을 0.1 단위로 변경
    start, end = plt.xlim()  #X축 범위 반환
    plt.xticks(np.round(np.arange(start, end, 0.1), 2))  #X축에 눈금 표시
    
    #X축, Y축 label과 legend, grid 설정
    plt.xlabel('Threshold value'); plt.ylabel('Precision and Recall value')
    plt.legend(); plt.grid()  #범례, 격자 표시
    plt.show()
    
precision_recall_curve_plot(y_test, lr_clf.predict_proba(X_test)[:, 1])
```

![image](https://user-images.githubusercontent.com/76269316/124485495-93b18280-dde7-11eb-9375-713313454f70.png)

임계값을 0.42 정도로 낮추면 정밀도와 재현율이 어느 정도 균형을 맞을 것 같긴한데, 두 지표 모두 0.7이 안되는 수치로 보입니다.

임계값을 조작하기 전에 다시 데이터 값을 점검하겠습니다.



```python
diabetes_data.describe()
```

![image](https://user-images.githubusercontent.com/76269316/124485878-facf3700-dde7-11eb-8d17-2df510a97f21.png)



min 값이 0으로 돼 있는 피처가 상당히 많은 것을 볼 수  있습니다.

Glucose 피처는 포도당 수치인데 min 값이 0인 것은 이상합니다. 

```python
plt.hist(diabetes_data['Glucose'], bins=10)  #bins 가로축 구간 개수 지정
```

![image](https://user-images.githubusercontent.com/76269316/124486083-34a03d80-dde8-11eb-9c43-bd4416ac8546.png)



##### 0 값 처리

min 값이 0으로 돼 있는 피처들('Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI')에 대해 0값의 건수 및 전체 데이터 건수 대비 몇 퍼센트 비율로 존재하는지 확인해 보겠습니다.

```python
#0값을 검사할 피처명 리스트
zero_features = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']

#전체 데이터 건수
total_count = diabetes_data['Glucose'].count()

#피처별로 반복하면서 데이터 값이 0인 데이터 건수를 추출하고, 퍼센트 계산
for feature in zero_features:
    zero_count = diabetes_data[diabetes_data[feature] == 0][feature].count()
    print('{0} 0 건수는 {1}, 퍼센트는 {2:.2f}%'.format(feature, zero_count, 100*zero_count/total_count))
```

![image](https://user-images.githubusercontent.com/76269316/124486946-1424b300-dde9-11eb-90ac-276191838ede.png)



SkinThickness, Insulin의 경우 전체의 29.56%, 48.7%로 0 값이 많습니다. 전체 데이터 건수가 많지 않기 때문에 삭제하지 않고 평균값으로 대체하겠습니다.

```python
#zero_features 리스트 내부에 저장된 개별 피처들에 대해 0 값을 평균 값으로 대체
mean_zero_features = diabetes_data[zero_features].mean()
diabetes_data[zero_features] = diabetes_data[zero_features].replace(0, mean_zero_features)

#0값을 검사할 피처명 리스트
zero_features = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']

#피처별로 반복하면서 데이터 값이 0인 데이터 건수를 추출하고, 퍼센트 계산
for feature in zero_features:
    zero_count = diabetes_data[diabetes_data[feature] == 0][feature].count()
    print('{0} 0 건수는 {1}'.format(feature, zero_count))
```

![image](https://user-images.githubusercontent.com/76269316/124487397-9f05ad80-dde9-11eb-8f7f-8d5c183ef80f.png)



0 값이 모두 평균 값으로 대체됐습니다.



##### 숫자 데이터 스케일링

로지스틱 회귀의 경우 일반적으로 숫자 데이터에 스케일링을 적용하는 것이 좋습니다.

```python
X = diabetes_data.iloc[:, :-1]
y = diabetes_data.iloc[:, -1]

#StandardScaler 클래스를 이용해 피처 데이터 세트에 일괄적으로 스케일링 적용
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
```



스케일링을 적용한 데이터 세트를 가지고 다시 로지스틱 회귀를 적용해 성능 평가 지표를 확인해보겠습니다.

```python
X = diabetes_data.iloc[:, :-1]
y = diabetes_data.iloc[:, -1]

#StandardScaler 클래스를 이용해 피처 데이터 세트에 일괄적으로 스케일링 적용
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=156, stratify=y)  #stratify로 전달된 값의 비율과 같도록 분할

#로지스틱 회귀로 학습, 예측 및 평가 수행
lr_clf = LogisticRegression()
lr_clf.fit(X_train, y_train)
pred = lr_clf.predict(X_test)
pred_proba = lr_clf.predict_proba(X_test)[:, 1]

get_clf_eval(y_test, pred, pred_proba)
```

![image](https://user-images.githubusercontent.com/76269316/124487796-163b4180-ddea-11eb-9ac4-474878e9763f.png)



아까보다는 개선이 됐으나, 재현율의 경우 아직도 66.67%로 낮습니다.

분류 결정 임계값을 변화시키면서 재현율 값의 성능 수치를 개선해보겠습니다.

**get_eval_by_threshold()**

임계값에 따라 get_clf_eval 메소드를 호출

```python
from sklearn.preprocessing import Binarizer

def get_eval_by_threshold(y_test, pred_proba_c1, thresholds):
    #thresholds list 객체 내의 값을 차례로 iteration하면서 evaluation 수행
    for custom_threshold in thresholds:
        binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_c1)
        custom_predict = binarizer.transform(pred_proba_c1)
        print('임계값: ', custom_threshold)
        get_clf_eval(y_test, custom_predict, pred_proba_c1)
```

```python
thresholds = [0.3, 0.33, 0.36, 0.39, 0.42, 0.45, 0.48, 0.50]
pred_proba = lr_clf.predict_proba(X_test)
get_eval_by_threshold(y_test, pred_proba[:, 1].reshape(-1, 1), thresholds)
```

![image](https://user-images.githubusercontent.com/76269316/124488596-ffe1b580-ddea-11eb-863b-3708b2fae34f.png)



정리하면 다음과 같습니다.

<img src="https://user-images.githubusercontent.com/76269316/124489358-d5dcc300-ddeb-11eb-84e7-9e810fe61314.png" alt="image" style="zoom:80%;" />

전체적인 성능 평가 지표를 유지하면서 재현율을 약간 향상시키는 좋은 임계값으로 0.5가 적당할 것 같습니다.



임계값을 0.48로 낮추고 실제로 저런 평가 지표가 나오는지 확인해보겠습니다.

predict() 메소드는 임계값을 마음대로 변환할 수 없으므로 앞에서 사용한 Binarizer 클래스를 이용해 predict_proba()로 추출한 예측 결과 확률값을 변환해 변경된 임계값에 따른 예측 클래스 값을 구해보겠습니다.



```python
from sklearn.preprocessing import Binarizer

#임계값을 0.48로 설정한 Binarizer 생성
binarizer = Binarizer(threshold=0.48)

#lr_clf의 predict_proba() 예측 확률 array에서 1에 해당하는 column 값을 Binarizer 변환
pred_th_048 = binarizer.fit_transform(pred_proba[:, 1].reshape(-1, 1))

get_clf_eval(y_test, pred_th_048, pred_proba[:, 1])
```

![image](https://user-images.githubusercontent.com/76269316/124490202-cad66280-ddec-11eb-9a68-6e709314ec5c.png)

