---
title: "7.Clustering"
excerpt: "군집화"
toc: true
toc_label: "Clustering"
toc_sticky: true

categories:
  - Machine Learning
tags:
  - 군집화 
  - 파이썬 머신러닝 완벽 가이드
last_modified_at: 2021-08-19
---

>![파이썬 머신러닝 완벽 가이드](https://user-images.githubusercontent.com/76269316/122906446-1fa9c000-d38d-11eb-9cab-1eb7e347a1e6.png)
>
>파이썬 머신러닝 완벽 가이드를 읽고 공부한 내용을 정리한 포스팅입니다.



군집화(Clustering)란 **비지도 학습**의 대표적인 기술로 피처에 대한 레이블이 지정되어 있지 않은 데이터를 그룹핑 하는 분석 알고리즘입니다.

<br>

### K-평균 알고리즘 이해

K-평균은 군집화에서 가장 일반적으로 사용되는 알고리즘으로, 군집 중심점(centroid)을 선택해 해당 중심에서 가장 가까운 포인트들을 선택하는 군집화 기법입니다.

<br>

아래는 K-평균이 어떻게 동작하는지를 시각적으로 표현한 그림입니다.

![image](https://user-images.githubusercontent.com/76269316/130090558-aff2b98e-3be6-4e2c-a94b-e6285af29694.png)

1. 먼저 군집화의 기준이 되는 중심을 구성하려는 군집화 개수만큼 적합한 위치에 갖다 놓습니다. (전체 데이터를 2개로 군집화하려면 2개의 중심을 임의의 위치에 갖다 놓습니다.)
2. 각 데이터는 가장 가까운 곳에 위치한 중심점에 소속됩니다.
   위 그림에서는 A, B 데이터가 같은 중심점에 소속되며 C, E, F 데이터가 같은 중심점에 소속됩니다.
3. 소속이 결정되면 군집 중심점을 소속된 데이터의 평균 중심으로 이동시킵니다.
   위 그림에서는 A, B 데이터 포인트의 평군 위치로 중심점이 이동했고 다른 중심점 역시 C, E, F 데이터의 평균 위치로 이동했습니다.
4. 중심점이 이동했기 때문에 각 데이터는 기존에 속한 중심점보다 더 가까운 중심점이 있다면 해당 중심점으로 소속을 변경합니다.
   위 그림에서는 C 데이터가 기존의 중심점보다 가까운 중심점으로 변경됐습니다.
5. 다시 중심을 소속된 데이터의 평균 중심으로 이동합니다.
   위 그림에서는 C가 중심 소속이 변경되면서 두 개의 중심이 모두 이동합니다.
6. 중심점을 이동했는데 데이터의 중심점 소속 변경이 없으면 군집화를 종료합니다.
   그렇지 않을 경우 4-5번 과정을 반복합니다.



K-평균 알고리즘의 장단점

|                             장점                             |                             단점                             |
| :----------------------------------------------------------: | :----------------------------------------------------------: |
| 일반적인 군집화에서 가장 많이 활용되는 알고리즘이고, 쉽고 간결함 | 거리 기반 알고리즘으로 속성 개수가 매우 많을 경우 군집화 정확도가 떨어짐 (따라서 PCA로 차원 감소를 적용해야 할 수도 있음)<br />반복을 수행하는데, 반복 횟수가 많을 경우 수행 시간이 매우 느려짐<br />몇 개의 군집(cluster)을 선택해야 할지 가이드하기 어려움 |

<br><br>

##### 사이킷런 KMeans 클래스 소개

사이킷런 패키지는 K-평균을 구현하기 위해 KMeans 클래스를 제공합니다.

 KMeans 클래스는 다음과 같은 초기화 파라미터를 갖고 있습니다.

```python
class sklearn.cluster.KMeans(n_clusters=8, init='k-means++', n_init=10, max_iter=300, tol=0.0001, precompute_distances='auto', verbose=0, random_state=None, copy_x=True, n_jobs=1, algorithm='auto')
```

 이 중 중요한 파라미터 다음과 같습니다.

- n_clusters : 군집 개수, 즉 군집 중심점의 개수를 의미합니다.
- init : 군십 중심점의 좌표 설정 방식, 보통 임의로 설정하지 않고 k-means++ 방식으로 설정합니다.
- max_iter : 최대 반복 횟수, 이 횟수 이전에 모든 데이터의 중심점 이동이 없으면 종료합니다.

<br>

사이킷런 KMeans 클래스는 fit, fit_transform 메소드를 이용해 군집화를 수행하면 됩니다.

군집화 수행이 완료되면 군집화와 관련된 주요 속성을 알 수 있습니다. 다음은 이 주요 속성 정보입니다.

- labels_ : 각 데이터 포인트가 속한 군집 중심점 레이블
- cluster_centers_ : 각 군집 중심점 좌표(Shape는 [군집 개수, 피처 개수])로 이를 이용하면 군집 중심점 좌표가 어딘지 시각화 할 수 있습니다.

<br><br>

##### K-평균을 이용한 붓꽃 데이터 세트 군집화

붓꽃 데이터(붓꽃의 꽃받침(sepal)과 꽃잎(petal) 길이와 너비에 따라 품종을 분류하는 데이터 세트)를 이용해 K-평균 군집화를 수행해 보겠습니다.

3개 그룹으로 군집화해 보고, 분류 값과 비교해 보겠습니다.

```python
from sklearn.preprocessing import scale
from sklearn.datasets import load_iris
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
%matplotlib inline

iris = load_iris()
#더 편리한 데이터 핸들링을 위해 DataFrame으로 변환
irisDF = pd.DataFrame(data=iris.data, columns=['sepal_length', 'sepal_width', 'petal_length', 'petal_width'])
irisDF['target'] = iris.target  #붓꽃 데이터 세트 target 값을 target으로 저장

#3개의 군집으로 군집화, 초기 중심 설정 방식은 k-means++, 최대 반복 횟수 300회
kmeans = KMeans(n_clusters=3, init='k-means++', max_iter=300, random_state=0)
kmeans.fit(irisDF)

#각 데이터 포인트가 속한 군집 중심점 레이블 출력
print(kmeans.labels_)
```

![image](https://user-images.githubusercontent.com/76269316/130238520-b43844bd-6dfd-4c5c-ac86-90a96dae457c.png)

labels_ 값이 0, 1, 2로 돼 있는데 이는 각 레코드가 첫 번째 군집, 두 번째 군집, 세 번째 군집에 속함을 의미합니다.

실제 붓꽃 품종 분류 값과 비교해보면서 군집화가 효과적으로 됐는지 확인해 보겠습니다.

<br>

```python
irisDF['cluster'] = kmeans.labels_  #군집화 분류값을 cluster로 저장
iris_result = irisDF.groupby(['target', 'cluster'])['sepal_length'].count()
print(iris_result)
```

![image](https://user-images.githubusercontent.com/76269316/130238944-ff522fec-19b3-4f2f-bfb2-bb8e60ea7f2e.png)

분류 target이 0 값인 데이터와 1인 데이터는 각각 1번 군집, 0번 군집으로 잘 그룹핑 됐습니다.

target이 2인 데이터의 경우 0번 군집 1개, 2번 군집 49개로 크게 분산되지 않고 잘 군집화 됐습니다.

<br>

붓꽃 데이터 세트 군집화를 시각화해 보겠습니다.

붓꽃 데이터 세트는 속성이 4개 이므로 2차원 평면에 적합하지 않습니다.

따라서 PCA를 이용해 4개의 속성을 2개로 차원 축소한 다음 X 좌표, Y 좌표로 개별 데이터를 표현 했습니다.

```python
from sklearn.decomposition import PCA

pca = PCA(n_components=2)
pca_transformed = pca.fit_transform(iris.data)

irisDF['pca_x'] = pca_transformed[:, 0]
irisDF['pca_y'] = pca_transformed[:, 1]

#군집 값 0, 1, 2 인덱스 추출
marker0_ind = irisDF[irisDF['cluster'] == 0].index
marker1_ind = irisDF[irisDF['cluster'] == 1].index
marker2_ind = irisDF[irisDF['cluster'] == 2].index

#군집 값 0, 1, 2에 해당하는 인덱스로 각 군집 레벨의 pca_x, pca_y 값 추출 (o, s, ^로 마커 표시)
plt.scatter(x=irisDF.loc[marker0_ind, 'pca_x'], y=irisDF.loc[marker0_ind, 'pca_y'], marker='o')
plt.scatter(x=irisDF.loc[marker1_ind, 'pca_x'], y=irisDF.loc[marker1_ind, 'pca_y'], marker='s')
plt.scatter(x=irisDF.loc[marker2_ind, 'pca_x'], y=irisDF.loc[marker2_ind, 'pca_y'], marker='^')

plt.xlabel('PCA 1')
plt.ylabel('PCA 2')
plt.title('3 Clusters Visualization by 2 PCA Components')
plt.show()
```

![image](https://user-images.githubusercontent.com/76269316/130240244-3f6c5ba1-c21b-4ae1-b764-4f552941fde3.png)

Cluster 1을 나타내는 네모('s')는 명확히 다른 군집과 잘 분리돼 있습니다.

Cluster 0을 나타내는 동그라미('o')와 Cluster 2를 나타내는 세모('^')는 상당 수준 분리돼 있지만, 네모만큼 명확하게 분리돼 있지는 않는 것을 확인할 수 있습니다.

<br><br>

##### 군집화 알고리즘 테스트를 위한 데이터 생성

사이킷런은 다양한 유형의 군집화 알고리즘을 테스트해 보기 위한 간단한 데이터 생성기를 제공합니다.

대표적인 군집화용 데이터 생성기로 make_blobs(), make_classification() API가 있습니다.

두 API는 여러 개의 클래스에 해당하는 데이터 세트를 만드는데, 하나의 클래스에 여러 개의 군집이 분포될 수 있게 데이터를 생성할 수 있습니다.

둘 중 어떤 것을 사용해도 큰 차이는 없지만, make_blobs()는 개별 군집의 중심점과 표준 편차 제어 기능이 있고, make_classification()은 노이즈를 포함한 데이터를 만들 수 있습니다. (둘 다 분류 용도의 데이터 세트 생성이 가능)

make_circle(), make_moon() API는 중심 기반 군집화로 해결하기 어려운 데이터 세트를 만드는 데 사용됩니다.

<br>

**make_blobs()**

make_blobs()를 호출하면 피처 데이터 세트와 타깃 데이터 세트가 튜플로 반환됩니다.

make_blobs() 호출 파라미터는 다음과 같습니다.

- n_samples : 생성할 총 데이터 개수 (default=100)
- n_features : 데이터 피처 개수, 시각화를 목표로 할 경우 2개로 설정해 첫 번째 피처 - x 좌표, 두 번째 피처 - y 좌표로 표현합니다.
- centers : int 값으로 설정시 군집의 개수를 의미, ndarray로 설정시 개별 군집 중심점의 좌표를 의미
- cluster_std : float 값으로 설정시 생성될 군집 데이터의 표준 편차를 의미, [0.8, 1.2, 0.6]과 같은 형태로 표현시 3개의 군집에서 첫 번째 군집내 데이터의 표준 편차 0.8, 두 번째 군집내 데이터의 표준 편차 1.2, 세 번째 군집내 데이터 표준 편차 0.6을 의미 (군집별로 다른 표준 편차를 가진 데이터 세트를 만들 때 사용)

<br>

![image](https://user-images.githubusercontent.com/76269316/130246535-68b8c4cf-917e-4303-9d21-21d55ab2d649.png)

![image](https://user-images.githubusercontent.com/76269316/130246610-b608dfd1-ece9-4fd3-aae2-d1cfa54a6595.png)

![image](https://user-images.githubusercontent.com/76269316/130246647-02f0369b-e4c7-44e0-a8e6-34704ad04b6a.png)

![image](https://user-images.githubusercontent.com/76269316/130246694-26030a1c-7987-45ad-b317-c348513893c0.png)

make_blobs()의 cluster_std 파라미터를 0.4, 0.8, 1.2 ,1.6으로 했을 때의 데이터를 시각화한 것입니다.

cluster_std가 작을수록 군집 중심에 데이터가 모여 있고, 클수록 데이터가 퍼져 있는 것을 확인할 수 있습니다.

<br>

X, y = make_blobs(n_samples=200, n_features=2, centers=3, cluster_std=0.8, random_state=0)를 호출하면

총 200개의 레코드와 2개의 피처가 3개의 군집화 기반 분포도를 갖는 피처 데이터 세트 X와 3개의 군집화 값을 갖는 타깃 데이터 세트 y가 반환됩니다.

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.datasets import make_blobs
%matplotlib inline

X, y = make_blobs(n_samples=200, n_features=2, centers=3, cluster_std=0.8, random_state=0)
print(X.shape, y.shape)

#y target 값 분포 확인
unique, counts = np.unique(y, return_counts=True)  #return_counts=True : 고유한 원소별 개수 구하기
print(unique, counts)
```

![image](https://user-images.githubusercontent.com/76269316/130241888-7b4d4bb3-0d24-4d96-9a39-93ce049771bf.png)

피처 데이터 세트 X는 200개 레코드와 2개의 피처를 가지므로 (200, 2), 군집 타깃 데이터 세트 y는 (200, ), 3개의 cluster값은 [0, 1, 2]이고 각각 67, 67, 66개로 균일하게 구성돼 있습니다.



데이터 가공을 편하게 하기 위해 DataFrame으로 변환한 뒤, 어떠한 군집화 분포를 가졌는지 확인해 보기 위해 마커를 다르게 해서 산점도를 그려보겠습니다.

```python
import pandas as pd

#더 편리한 데이터 핸들링을 위해 DataFrame으로 변환
clusterDF = pd.DataFrame(data=X, columns=['ftr1', 'ftr2'])
clusterDF['target'] = y

#3개의 군집 영역으로 구분한 데이터 세트를 생성했으므로 target_list는 [0, 1, 2]
target_list = np.unique(y)
#각 타깃별 산점도 마커 값
markers = ['o', 's', '^', 'P', 'D', 'H', 'x']

for target in target_list:
    target_cluster = clusterDF[clusterDF['target'] == target]
    plt.scatter(x=target_cluster['ftr1'], y=target_cluster['ftr2'], edgecolor='k', marker=markers[target])

plt.show()
```

![image](https://user-images.githubusercontent.com/76269316/130243117-f2e80901-52f5-4a88-9aab-c38292b5e6c9.png)

<br>

이렇게 만들어진 데이터 세트에 KMeans 군집화를 수행한 뒤 군집별로 시각화해 보겠습니다.

KMeans 객체에 fit_predict를 수행해 make_blobs() 피처 데이터 세트인 X 데이터를 군집화합니다.

이를 clusterDF 'kmeans_label' 컬럼으로 저장하고, KMeans 객체 cluster_centers_ 속성으로 개별 군집의 중심 위치 좌표를 표시하겠습니다.

```python
#KMeans 객체를 이용해 X 데이터를 K-Means 클러스터링 수행
kmeans = KMeans(n_clusters=3, init='k-means++', max_iter=200, random_state=0)
cluster_labels = kmeans.fit_predict(X)
clusterDF['kmeans_label'] = cluster_labels  #clusterDF에 kmeans_label 컬럼으로 저장

#개별 클러스터의 중심 위치 좌표 시각화를 위해 cluster_centers_ 추출
centers = kmeans.cluster_centers_

unique_labels = np.unique(cluster_labels)
markers = ['o', 's', '^', 'P', 'D', 'H', 'x']

#군집된 label 유형별로 iteration 하면서 marker별 scatter plot 수행
for label in unique_labels:
    label_cluster = clusterDF[clusterDF['kmeans_label'] == label]  #군집별 인덱스 추출
    center_x_y = centers[label]  #군집별 중심 좌표 추출
    plt.scatter(x=label_cluster['ftr1'], y=label_cluster['ftr2'], edgecolor='k', marker=markers[label])
    
    #군집별 중심 위치 좌표 시각화
    plt.scatter(x=center_x_y[0], y=center_x_y[1], s=200, color='white', alpha=0.9, edgecolor='k', marker=markers[label])
    plt.scatter(x=center_x_y[0], y=center_x_y[1], s=70, color='k', edgecolor='k', marker='$%d$' % label)
    
plt.show()
```

![image](https://user-images.githubusercontent.com/76269316/130245218-e33906b0-3456-4c59-8e2c-bcff21b5f623.png)

```python
print(clusterDF.groupby('target')['kmeans_label'].value_counts())
```

![image](https://user-images.githubusercontent.com/76269316/130245336-76fe885c-bb33-42b1-8667-d22008695910.png)

kmeans_label은 군집 번호를 의미하므로 make_blobs() 타깃과 다른 값으로 매핑될 수 있습니다. (그래서 산점도의 마커가 다름)

Target 0이 cluster label 0으로, target 1이 cluster label2로, target 2가 cluster label 1로 거의 대부분 잘 매핑된 것을 확인할 수 있습니다.

<br><br><br>

### 군집 평가(Cluster Evaluation)

위에서 다룬 붓꽃 데이터 세트의 경우 결괏값에 품종을 뜻하는 타깃 레이블이 있었기 때문에 군집화 결과를 레이블과 비교해 군집화가 효율적으로 됐는지 짐작할 수 있었습니다.

하지만 대부분의 군집화 데이터 세트는 이렇게 비교할 만한 타깃 레이블을 갖고 있지 않기 때문에 타깃 레이블과 비교하는 방식으로는 성능을 평가하기 어렵습니다.

군집화의 성능을 평가하는 대표적인 방법인 실루엣 분석에 대해 설명하겠습니다.

<br>

##### 실루엣 분석의 개요

실루엣 분석(silhouette analysis)은 간 군집 간의 거리가 얼마나 효율적으로 분리돼 있는지를 나타냅니다.

효율적으로 잘 분리돼다는 것은 다른 군집과의 거리는 떨어져 있고 동일 군집끼리의 데이터는 서로 가깝게 잘 뭉쳐 있다는 의미입니다.

실루엣 분석은 실루엣 계수(silhouette coefficient)를 기반으로 하는데, 실루엣 계수는 해당 데이터가 같은 군집 내의 데이터와 얼마나 가깝게 군집화돼 있고, 다른 군집에 있는 데이터와는 얼마나 멀리 분리돼 있는지를 나타내는 지표입니다.

![image](https://user-images.githubusercontent.com/76269316/130302511-132aedf9-777c-4de7-828e-8cb0211d44eb.png)

- a(i) : 해당 데이터 포인트와 같은 군집 내에 있는 다른 데이터 포인트와의 거리를 평균한 값
- b(i) : 해당 데이터 포인트가 속하지 않은 가장 가까운 군집과의 평균 거리

두 군집간의 거리가 얼마나 떨어져 있는지 나타내는 값은 b(i) - a(i)이고 이 값을 정규화하기 위해 MAX(a(i), b(i)) 값으로 나누는데 이것이 실루엣 계수의 정의입니다.



**i번째 데이터 포인트의 실루엣 계수 s(i)**

![image](https://user-images.githubusercontent.com/76269316/130302905-973466ac-9e91-4b47-a2ce-fb3f8a521215.png)

실루엣 계수는 -1에서 1 사이의 값을 가지며, 1로 가까워질수록 근처의 군집과 더 멀리 떨어져 있다는 것이고 0에 가까울수록 근처 군집과 가깝다는 의미입니다.

\- 값은 아예 다른 군집에 데이터 포인트가 할당됐음을 의미합니다.

<br>

사이킷런은 실루엣 분석을 위해 다음과 같은 메소드를 제공합니다.

- sklearn.metrics.silhouette_samples(X, labels, metric='euclidean', \**kwds): 인자로 X feature 데이터 세트와 각 피처 데이터 세트가 속한 군집 레이블 값인 labels 데이터를 입력하면 각 데이터 포인트의 실루엣 계수를 계산해 반환합니다.
- sklearn.metrics.silhouette_score(X, labels, metric='euclidean', sample_size=None, \**kwds):  인자로 X feature 데이터 세트와 각 피처 데이터 세트가 속한 군집 레이블 값인 labels 데이터를 입력해주면 전체 데이터의 실루엣 계수 값을 평균해 반환합니다. (즉 np.mean(silhouette_samples())입니다)
  일반적으로 이 값이 높을수록 군집화가 어느정도 잘 됐다고 판단할 수 있지만, 무조건 이 값이 높다고 군집화가 잘 됐다고 판단할 수는 없습니다.

<br>

좋은 군집화가 되려면 다음 조건을 만족해야 합니다.

1. 전체 실루엣 계수의 평균값(silhouette_score())이 0 ~ 1 사이의 값을 가지며, 1에 가까울수록 좋습니다.
2. 전체 실루엣 계수의 평균값과 더불어 개별 군집의 평균값의 편차가 크지 않아야 합니다. (개별 군집의 실루엣 계수값이 전체 실루엣 계수의 평균값에서 크게 벗어나지 않는 것이 중요)
   만약 전체 실루엣 계수 평균값은 높지만 특정 군집의 실루엣 계수값만 유난히 높고 다른 군집의 실루엣 계수값은 낮으면 좋은 군집화가 아닙니다.

<br><br>

##### 붓꽃 데이터 세트를 이용한 평가

붓꽃 데이터 세트 군집화 결과를 실루엣 분석으로 평가해 보겠습니다.

```python
from sklearn.preprocessing import scale
from sklearn.datasets import load_iris
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_samples, silhouette_score  #실루엣 분석 평가 지표 값을 구하기 위한 API 추가
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
%matplotlib inline

iris = load_iris()
feature_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']
irisDF = pd.DataFrame(data=iris.data, columns=feature_names)
kmeans = KMeans(n_clusters=3, init='k-means++', max_iter=300, random_state=0).fit(irisDF)
irisDF['cluster'] = kmeans.labels_

#iris 데이터 세트의 모든 개별 데이터 실루엣 계수 값을 구함
score_samples = silhouette_samples(iris.data, irisDF['cluster'])
print('silhouette_samples() return 값의 shape: ', score_samples.shape)

#irisDF에 실루엣 계수 컬럼 추가
irisDF['silhouette_coeff'] = score_samples

#모든 데이터의 평균 실루엣 계수 값을 구함
average_score = silhouette_score(iris.data, irisDF['cluster'])
print('붓꽃 데이터 세트 Silhouette Analysis Score: {0:.3f}'.format(average_score))
irisDF.head(3)
```

![image](https://user-images.githubusercontent.com/76269316/130303988-c12455d0-4f3d-4fdf-8ec6-6987d1b16b45.png)

head로 출력한 1번 군집의 실루엣 계수 값은 모두 0.8 이상으로 높은데 평균이 0.553인 것은 다른 군집의 실루엣 계수 값이 평균보다 낮기 때문일 것입니다.

<br>

군집별로 group by하여 군집별 실루엣 계수 평균값을 구해보겠습니다.

```python
irisDF.groupby('cluster')['silhouette_coeff'].mean()
```

![image](https://user-images.githubusercontent.com/76269316/130304040-ee7a5fc7-b2e1-4fc4-baf2-5352ddabb54f.png)

1번 군집은 실루엣 계수 평균 값이 0.79인데 반해, 0번은 0.41, 2번은 0.45로 상대적으로 평균값이 낮습니다.
