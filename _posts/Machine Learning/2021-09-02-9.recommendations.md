---
title: "9.Recommendations"
excerpt: "추천 시스템"
toc: true
toc_label: "Recommendations"
toc_sticky: true

categories:
  - Machine Learning
tags:
  - 추천 시스템
  - 파이썬 머신러닝 완벽 가이드
last_modified_at: 2021-09-03
---

>![파이썬 머신러닝 완벽 가이드](https://user-images.githubusercontent.com/76269316/122906446-1fa9c000-d38d-11eb-9cab-1eb7e347a1e6.png)
>
>파이썬 머신러닝 완벽 가이드를 읽고 공부한 내용을 정리한 포스팅입니다.

### 추천 시스템의 개요와 배경

##### 추천 시스템의 개요

하나의 콘텐츠를 선택했을 때 선택된 콘텐츠와 연관된 추천 콘텐츠가 얼마나 사용자의 관심을 끌고 개인에게 맞춤 콘텐츠를 추천했는지는 그 사이트의 평판을 좌우하는 매우 중요한 요소입니다.

추천 시스템의 진정한 묘미는 사용자 자신도 좋아하는지 몰랐던 취향을 시스템이 발견하고 그에 맞는 콘텐츠를 추천해주는 것입니다.

이러한 추천 시스템을 접한 사용자는 해당 사이트를 더 강하게 신뢰하게 되어 더 많은 추천 콘텐츠를 선택하게 되고, 결국 더 많은 데이터가 축적되면서 추천 시스템이 더욱 정확해지고 다양한 결과를 얻을 수 있는 선순환 시스템을 구축할 수 있게 됩니다.

넷플릭스, 유튜브, 아마존 등 많은 기업들이 사용자의 관심을 오랫동안 지속하기 위해 추천 시스템의 고도화에 큰 비용과 투자를 아끼지 않고 있습니다.

<br><br>

##### 온라인 스토어의 필수 요소, 추천 시스템

온라인 스토어는 많은 양과 고객의 상품 관련 데이터를 갖고 있는데, 너무 많은 상품과 콘텐츠는 오히려 사용자가 어떤 상품을 골라야 할지에 대한 압박감을 느끼게 만듧니다.

이때 좋은 추천 시스템은 사용자가 무엇을 원하는지 빠르게 찾아내 사용자의 온라인 쇼핑을 도와 이러한 상황을 타개해줍니다.

온라인 스토어는 많은 양의 고객과 상품 관련 데이터를 갖고 있는데, 다음과 같은 데이터가 추천 시스템을 구성하는데 사용될 수 있습니다.

- 사용자가 어떤 상품을 구매했는가?
- 사용자가 어떤 상품을 둘러보거나 장바구니에 넣었는가?
- 사용자가 평가한 영화 평점은? 제품 평가는?
- 사용자가 스스로 작성한 자신의 취향은?
- 사용자가 무엇을 클릭했는가?

이런 데이터를 기반으로 추천 시스템은 '당신만을 위한 최신 상품', '이 상품을 선택한 다른 사람들이 좋아하는 상품들', '이 상품을 좋아하나요?' 같은 문구로 사용자가 상품을 구매하도록 유혹합니다.

<br><br>

##### 추천 시스템의 유형

추천 시스템은 콘텐츠 기반 필터링(Content based filtering) 방식과 협업 필터링(Collaborative filtering) 방식으로 나뉩니다.

협업 필터링은 다시 최근접 이웃(Nearest Neighbor) 협업 필터링과 잠재 요인(Latent Factor) 협업 필터링으로 나뉩니다.

- 콘텐츠 기반 필터링
- 협업 필터링
  - 최근접 이웃 협업 필터링
  - 잠재 요인 협업 필터링



초창기에는 콘텐츠 기반 필터링이나 최근접 이웃 협업 필터링이 주로 사용됐지만, 넷플릭스 추천 시스템 경연 대회에서 행렬 분해(Matrix Factorization) 기법을 이용한 잠재 요인 협업 필터링 방식이 우승하면서 많은 온라인 스토어에서 잠재 요인 협업 필터링 기반의 추천 시스템을 적용하고 있습니다.

하지만 서비스 아이템의 특성에 따라 콘텐츠 기반 필터링이나 최근접 이웃 기반 필터링 방식을 유지하는 사이트들도 많고, 요즘에는 개인화 특성을 강화하기 위해 하이브리드 형식으로 결합해 사용하는 경우도 늘고 있습니다.

<br><br><br>

### 콘텐츠 기반 필터링 추천 시스템

콘텐츠 기반 필터링 방식은 사용자가 특정한 아이템을 매우 선호하는 경우, 그 아이템과 비슷한 콘텐츠를 가진 다른 아이템을 추천하는 방식입니다.

예를 들어 사용자가 '엔드게임'이라는 영화에 8점(10점 만점), '인피니티 워'에 9점이라는 높은 점수를 줬을 때,

'엔드게임'과 '인피니티 워'의 장르, 감독, 출연 배우, 키워드 등의 콘텐츠를 감안해 이와 유사한 영화를 추천합니다.

'엔드게임'의 경우 장르가 액션, 모험, 슈퍼히어로 영화이고, '인피니티 워'는 액션, 슈퍼히어로 영화, SF로 분류됩니다.

영화 감독의 경우 앤서니 루소, 조 루소입니다.

콘텐츠 기반 필터링 추천 시스템은 사용자가 높게 평가한 이러한 영화의 콘텐츠를 감안해 이와 적절하게 매칭되는 영화를 추천해줍니다.

'시빌 워'의 경우 사용자가 선호하는 감독, 장르 등의 콘텐츠를 다양하게 포함하고 있으므로 콘텐츠 기반 필터링 추천 시스템에 의해 추천되게 됩니다.

<img src="https://user-images.githubusercontent.com/76269316/131944660-f15b9b72-41f6-4e15-a4ca-02daacd590c2.png" alt="image"  />

<br><br><br>

### 최근접 이웃 협업 필터링

하지만 좋아하는 배우/감독만을 보고 영화를 선택했다가 실망한 경험이 있을겁니다.

그래서 우리는 대부분 영화를 본 가까운 친구들(취향이 비슷한)에게 영화가 어땠는지를 물어보고 영화를 보러 갈지 말지를 결정합니다.

이렇게 친구들에게 물어보는 것과 유사한 방식으로, 사용자가 아이템에 매긴 평점 정보나 상품 구매 이력과 같은 사용자 행동 양식(User Behavior)만을 기반으로 추천을 수행하는 것이 협업 필터링(Collaborative Filtering) 방식입니다.

<br>

협업 필터링의 주요 목표는 사용자-아이템 평점 행렬과 같은 축적된 사용자 행동 데이터를 기반으로 사용자가 아직 평가하지 않은 아이템을 예측 평가(Predicted Rating) 하는 것입니다.



<img src="https://user-images.githubusercontent.com/76269316/131945428-2ccd963c-db1f-4c34-aaf7-b730ba2e3e9e.png" alt="image" style="zoom:67%;" />

위 그림에서 User1은 Item 4에 대해 아직 평가하지 않았습니다.

협업 필터링은 사용자가 평가한 다른 아이템을 기반으로 사용자가 평가하지 않은 아이템의 예측 평가를 도출하는 방식입니다.



협업 필터링 기반 추천 시스템은 **최근접 이웃 방식**과 **잠재 요인 방식**으로 나뉘며, 두 방식 모두 사용자-아이템 평점 행렬 데이터에 의존해 추천을 수행합니다.

사용자-아이템 평점 행렬에서 행은 개별 사용자, 열은 개별 아이템으로 구성되며, 사용자 아이디 행, 아이템 아이디 열 위치에 해당하는 값이 평점을 나타내는 형태입니다.

<br>

만약 다음 그림 왼쪽과 같이 사용자-아이템 평점 데이터라면 판다스 pivot_table()과 같은 함수를 사용해 오른쪽과 같은 형태인 사용자-아이템 평점 행렬로 변경해야 합니다.

<img src="https://user-images.githubusercontent.com/76269316/131949621-e2eccbd7-dd81-49c7-ab0b-ac7ef00e78a5.png" alt="image" style="zoom: 67%;" />

일반적으로 이런 사용자-아이템 평점 행렬은 많은 아이템을 열로 갖는 다차원 행렬이며, 사용자가 아이템에 대한 평점을 매기는 경우가 많지 않기 때문에 희소 행렬(Sparse Matrix) 특성을 갖고 있습니다.

<br>

최근접 이웃 협업 필터링은 다시 사용자 기반과 아이템 기반으로 나뉠 수 있습니다.

사용자 기반(User-User) 최근접 이웃 방식은 특정 사용자와 타 사용자 간의 유사도(Similarity)를 측정한 뒤 가장 유사도가 높은 TOP-N 사용자를 추출해 그들이 선호하는 아이템을 추천하는 것입니다.



사용자 A의 주요 영화의 평점 정보는 사용자 C보다 사용자 B와 유사합니다.

만약 사용자 A에게 아직 보지 못한 두 개의 영화 중 하나를 추천한다면 사용자 B가 재미있게 본 '프로메테우스'를 추천하는 것이 사용자 기반 최근접 이웃 협업 필터링입니다.

<img src="https://user-images.githubusercontent.com/76269316/131950285-e080c309-aeff-46cd-916e-e8ed71226901.png" alt="image" style="zoom:67%;" />

<br>

아이템 기반 최근접 이웃 방식은 사용자들이 그 아이템을 좋아하는지/싫어하는지의 평가 척도가 유사한 아이템을 추천하는 알고리즘입니다.

아이템 '다크 나이트'는 '스타워즈-라스트 제다이'보다 '프로메테우스'와 사용자들의 평점 분포가 비슷합니다.

따라서 '다크 나이트'를 매우 좋아하는 사용자 D에게 아이템 기반 협업 필터링은 '프로메테우스'와 '스타워즈-라스트 제다이' 중 '프로메테우스'를 추천합니다.

<img src="https://user-images.githubusercontent.com/76269316/131950455-42c31d3f-7362-45a8-a43b-ebbf35b543f9.png" alt="image" style="zoom:67%;" />

<br>

일반적으로 비슷한 영화를 좋아한다고 사람들의 취향이 비슷하다고 판단하기는 어려운 경우가 많고, 사용자들이 평점을 매긴 영화(또는 상품)의 개수가 많지 않은 경우가 일반적이기 때문에 최근접 이웃 협업 필터링은 사용자 기반보다 아이템 기반 협업 필터링을 적용합니다.

<br><br><br>

### 잠재 요인 협업 필터링

잠재 요인 협업 필터링은 사용자-아이템 평점 행렬 속에 숨어 있는 잠재 요인을 추출해 추천 예측을 할 수 있게 하는 기법입니다.

대규모 다차원 행렬을 SVD와 같은 차원 감소 기법으로 분해하는 과정에서 잠재 요인을 추출하는데 이러한 기법을 행렬 분해(Matrix Factorization)라고 합니다.

다차원 희소 행렬인 사용자-아이템 행렬 데이터를 저차원 밀집 행렬의 **사용자-잠재 요인 행렬**과 **잠재 요인-아이템 행렬**(아이템-잠재 요인 행렬의 전치행렬)로 분해한 뒤, 두 행렬의 내적을 통해 새로운 예측 사용자-아이템 평점 행렬 데이터를 만들어서 사용자가 아직 평점을 부여하지 않은 아이템에 대한 예측 평점을 생성합니다.

![image](https://user-images.githubusercontent.com/76269316/131954931-702b42cf-613e-4fe1-bfbd-faac853171f8.png)

행렬 분해에 의해 추출되는 '잠재 요인'이 어떤 것인지 명확히 정의할 수는 없지만 가령 영화 평점 기반의 사용자-아이템 평점 행렬 데이터라면 영화가 갖는 장르별 특성 선호도로 가정할 수 있습니다.

따라서 사용자-잠재 요인 행렬은 사용자의 영화 장르에 대한 선호도, 아이템-잠재 요인 행렬은 영화의 장르별 특성값으로 정의할 수 있습니다.

<br>

사용자-아이템 평점 행렬 R에서 사용자(User)의 아이템(Item)에 대한 평점은 R(u, i)입니다. (u는 사용자 아이디, i는 아이템 아이디)

사용자-잠재 요인 행렬(사용자의 영화 장르별 선호도) P의 factor 1을 액션 선호도, factor 2를 로맨스 선호도로 가정하겠습니다. (설명상 편의를 위해 장르 2개만 사용했습니다)

아이템-잠재 요인 행렬(영화의 장르별 특성값) Q의 factor 1은 액션 요소 값, factor 2는 로맨스 요소 값으로 설정했습니다.

<img src="https://user-images.githubusercontent.com/76269316/131956840-cfd6bdf3-4349-412f-8cb8-b7e8deba941d.png" alt="image" style="zoom:67%;" />

평점이란 사용자의 특정 영화 장르에 대한 선호도와 개별 영화의 장르적 특성값을 반영해 결정됩니다.

예를 들어 사용자가 액션 영화를 매우 좋아하고, 특정 영화가 액션 영화의 특성이 매우 크다면 사용자가 해당 영화에 높은 평점을 줄 것입니다.

따라서 평점은 사용자의 장르별 선호도와 벡터와 영화의 장르별 특성 벡터를 곱해 만들 수 있습니다.

User 1의 item 1 평점인 R(1, 1)은 P 행렬의 User 1 벡터와 Q.T 행렬의 Item 1 벡터를 곱한 값입니다. (Q는 P와의 내적 계산을 통해 예측 평점을 계산하기 위해 행과 열 위치를 교환합니다)

<br>

마찬가지 방법으로 아직 User 1이 평점을 매기지 못한 Item 2에 대해 예측 평점을 수행할 수 있습니다.

<img src="https://user-images.githubusercontent.com/76269316/131959226-8f8436d5-3d43-4108-b3cf-1c6969d55af1.png" alt="image" style="zoom:67%;" />

R(1, 2)는 행렬 분해된 P 행렬의 User 1 벡터와 Q.T 행렬의 Item 2 벡터의 내적 결괏값인 2.56으로 예측할 수 있습니다.

이처럼 잠재 요인 협업 필터링은 숨겨져 있는 잠재 요인을 기반으로 분해된 행렬을 이용해 사용자가 아직 평가하지 않은 아이템에 대한 예측 평가를 수행하는 것입니다.

<br><br>

##### 행렬 분해의 이해

M개의 사용자(User) 행과 N개의 아이템(Item) 열을 갖는 평점 행렬 R은 M X N 차원으로 구성되며, 행렬 분해를 통해 사용자-잠재 요인 행렬 P(M X K 차원), 잠재 요인-아이템 행렬 Q.T(K X N 차원)으로 분해될 수 있습니다.

<img src="https://user-images.githubusercontent.com/76269316/131965286-1c26a006-90b4-4d86-b4c0-542d067cddea.png" alt="image" style="zoom:67%;" />

<br>

R 행렬의 u행 사용자와 i 열 아이템 위치에 있는 평점 데이터를 r(u, i)라고 하면 다음과 같이 계산할 수 있습니다.

![image](https://user-images.githubusercontent.com/76269316/131965756-1fe6856e-d17d-4d3b-95d2-e15b84ff1ae9.png)

아직 사용자가 평가하지 않은 아이템에 대한 평점도 잠재 요인으로 분해된 P 행렬과 Q 행렬을 이용해 예측할 수 있습니다.

따라서 사용자-아이템 평점 행렬의 미정 값을 포함한 모든 평점 값은 행렬 분해를 통해 얻어진 P 행렬과 Q.T 행렬의 내적을 통해 예측 평점으로 다시 계산할 수 있습니다.

![image](https://user-images.githubusercontent.com/76269316/131975692-c148066c-97b7-4a2b-9708-223d44a34b8e.png)

<br>

이렇게 행렬 분해는 다차원의 매트릭스를 저차원 매트릭스로 분해하는 기법으로서 대표적으로 SVD(Singular Vector Decomposition), NMF(Non-Negative Matrix Factorization) 등이 있는데,

SVD의 경우 널(NaN) 값이 없는 행렬에만 적용할 수 있기 때문에 평점이 없는 R 행렬에는 SVD 방식으로 분해할 수 없습니다.

이러한 경우에는 확률적 경사 하강법(SGD, Stochastic Gradient Descent)이나 ALS(Alternating Least Squares) 방식을 사용합니다.

<br><br>

##### 확률적 경사 하강법을 이용한 행렬 분해

확률적 경사 하강법을 이용한 행렬 분해는 P와 Q 행렬로 계산된 **예측 R 행렬 값**이 **실제 R 행렬 값**과 가장 최소의 오류를 가질 수 있도록 반복적인 비용 함수 최적화를 통해 P와 Q를 유추해냅니다.

<br>

**확률적 경사 하강법을 이용한 행렬 분해 절차**

1. P와 Q를 임의의 값을 가진 행렬로 설정합니다.
2. P와 Q.T 값을 곱해 예측 R 행렬을 계산하고 오류 값을 계산합니다.
3. 이 오류 값을 최소화할 수 있도록 P와 Q 행렬을 각각 업데이트 합니다.
4. 만족할만한 오류 값을 가질 때까지 2, 3번 작업을 반복하면서 P와 Q 값을 업데이트합니다.

<br>

실제 값과 예측값의 오류 최소화와 L2 규제를 고려한 비용 함수식은 다음과 같습니다.

![image](https://user-images.githubusercontent.com/76269316/131980741-ae6a8807-d5b9-4dd1-8129-f453e4a38dd8.png)

위 비용 함수를 최소화하기 위해 업데이트 되는<img src="https://user-images.githubusercontent.com/76269316/131980850-27a90463-6bbe-4891-80ab-75810260e9ca.png" alt="image" style="zoom:80%;" />와 <img src="https://user-images.githubusercontent.com/76269316/131980894-609324f6-0aef-4052-9274-9b2d0c97b94d.png" alt="image" style="zoom:80%;" />는 다음과 같이 계산할 수 있습니다.

![image](https://user-images.githubusercontent.com/76269316/131980961-3eb8e4de-1d7f-42b9-9fdf-14386ddde329.png)

각각의 기호가 의미하는 바는 다음과 같습니다.

- <img src="https://user-images.githubusercontent.com/76269316/131981022-ee6606c9-7f9d-49a6-938c-e159e7561354.png" alt="image" style="zoom:80%;" />: P 행렬의 사용자 U행 벡터
- <img src="https://user-images.githubusercontent.com/76269316/131981160-e61167c0-f489-4e45-8f6b-c64fa85655c9.png" alt="image" style="zoom:80%;" />: Q 행렬의 아이템 i행의 전치 벡터
- <img src="https://user-images.githubusercontent.com/76269316/131981353-ee03aae0-b955-41b7-a376-d811e71186ad.png" alt="image" style="zoom:80%;" />: 실제 R 행렬의 u행, i열에 위치한 값
- <img src="https://user-images.githubusercontent.com/76269316/131981550-ff792752-8d05-4e51-8222-903a1ce966d6.png" alt="image" style="zoom:80%;" />: 예측 행렬 <img src="https://user-images.githubusercontent.com/76269316/131981655-262f6658-a664-4422-9dc9-e7bda7090f07.png" alt="image" style="zoom:80%;" />의 u행, i열에 위치한 값
- <img src="https://user-images.githubusercontent.com/76269316/131981757-5a89c579-c5e6-444a-9067-b06ac534813f.png" alt="image" style="zoom:80%;" />: u행, i열에 위치한 실제 행렬 값과 예측 행렬 값의 차이 오류 (<img src="https://user-images.githubusercontent.com/76269316/131982186-b68f074f-b559-4952-a2ee-a29c86c6d7e8.png" alt="image" style="zoom:80%;" />)
- <img src="https://user-images.githubusercontent.com/76269316/131982234-55197372-1c78-4d7f-9a95-793ef726ed95.png" alt="image" style="zoom:80%;" />: SGD 학습률
- <img src="https://user-images.githubusercontent.com/76269316/131982318-7ef01e0a-64f3-4507-a903-9be2c0037400.png" alt="image" style="zoom:80%;" />: L2 규제 계수
