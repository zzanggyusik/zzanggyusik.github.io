---
title:  "2.scikit-learn Machine Learning in Python"
excerpt: "사이킷런으로 시작하는 머신러닝"
toc: true
toc_label: "scikit-learn Machine Learning in Python"
toc_sticky: true

categories:
  - Machine Learning
tags:
  - Machine Learning
last_modified_at: 2021-06-25


---





>![파이썬 머신러닝 완벽 가이드](https://user-images.githubusercontent.com/76269316/122906446-1fa9c000-d38d-11eb-9cab-1eb7e347a1e6.png)
>
>파이썬 머신러닝 완벽 가이드를 읽고 공부한 내용을 정리한 포스팅입니다.



사이킷런(scikit-learn)은 파이썬 머신러닝 라이브러리 중 가장 많이 사용되는 라이브러리입니다.

사이킷런의 특징은 다음과 같습니다.

- 쉽고 가장 파이썬스러운 API를 제공
- 머신러닝을 위한 매우 다양한 알고리즘과 편리한 프레임워크, API를 제공
- 오랜 기간 실전 환경에서 검증되어 많은 환경에서 사용되는 성숙한 라이브러리임



Anaconda를 설치하면 기본으로 사이킷런까지 설치가 완료되기 때문에 별도로 설치할 필요가 없습니다.

+재설치 해야하는 경우 (conda 명령어로 설치하는 것을 권장)

```python
conda install scikit-learn  #Anaconda의 conda 명령어로 설치할 경우 사이킷런 구동에 필요한 다양한 라이브러리를 동시에 설치해줌
pip install scikit-learn
```



### 붓꽃 품종 예측하기

사이킷런에는 예제로 활용할 수 있는 간단한 데이터 세트가 내장돼 있습니다. 

이 중 하나인 붓꽃 데이터 세트를 이용해서 붓꽃 품종 예측 머신러닝 모델을 만들어보겠습니다.



붓꽃 품종 예측 머신러닝 모델이라는 것은 붓꽃 데이터 세트의 꽃잎의 길이와 너비, 꽃받침의 길이와 너비 feature를 기반으로 꽃의 품종을 분류(Classfication)한다는 것입니다.

분류(Classfication)는 대표적인 [지도학습](https://seominseok4834.github.io/1.machine-learning-term-and-concept/#supervised-learning) 방법 중 하나인데,

![image](https://user-images.githubusercontent.com/76269316/123435462-1dc64380-d5bd-11eb-940a-fdad9059c48f.png)

지도학습은 학습을 위한 다양한 feature와 분류 결정값인 label 데이터로 모델을 학습한 뒤, 별도의 테스트 데이터 세트에서 미지의 label을 예측합니다. (명확한 정답이 주어진 데이터를 먼저 학습한 뒤 미지의 정답을 예측하는 방식)

이 때, 학습을 위해 주어진 데이터 세트를 **학습 데이터 세트**, 머신러닝 모델의 예측 성능을 평가하기 위해 별도로 주어진 데이터 세트를 **테스트 데이터 세트**라고 합니다.



feature와 label이 뭔지 감이 안 오실텐데, feature는 단어 그대로 특징을 의미합니다. 

붓꽃 데이터 세트에서 feature는 꽃잎의 길이와 너비, 꽃받침의 길이와 너비를 의미합니다.

label도 마찬가지로 우리가 상표나 품명을 인쇄해서 붙여놓는 종잇조각인 라벨처럼, 각각의 데이터들이 무엇인지를 결정해주는 값입니다. 붓꽃 데이터 세트에서는 붓꽃의 품종(setosa, vesicolor, virginica)을 의미합니다.



즉, 학습 데이터 세트를 통해서 학습을 시킬 때는 각각의 feature들이 어떤 품종인지를 나타내는 label 값을 주고 학습을 시킨 다음, 실제로 학습시킨 머신 러닝 모델의 예측 성능을 평가할 때는 이 label값을 주지 않고 feature 값만 줌으로써 (이 때 주어지는 feature는 학습시킬 때의 feature와는 다른 값입니다.) label을 얼마나 잘 예측했는지를 평가합니다.



사이킷런의 여러 모듈들을 사용해서 실제로 붓꽃 품종 예측 머신러닝 모델을 만들어보겠습니다.

```python
import pandas as pd
import sklearn

from sklearn.datasets import load_iris  #sklearn.datasets : 사이킷런에서 자체적으로 제공하는 데이터 세트를 생성하는데 사용되는 모듈
from sklearn.tree import DecisionTreeClassifier  #sklearn.tree : 트리 기반 ML 알고리즘을 구현한 클래스의 모임
from sklearn.model_selection import train_test_split  #sklearn.model_selection : 학습 데이터와 검증데이터, 예측 데이터로 데이터를 분리하거나 최적의 하이퍼 파라미터로 평가하기 위한 모듈
from sklearn.metrics import accuracy_score  #정확도 측정을 위한 accuracy_score() 함수 사용

#붓꽃 데이터 세트 로딩
iris = load_iris()

#iris.data는 데이터 세트에서 feature만으로 된 데이터를 numpy ndarray로 갖고 있음
iris_data = iris.data

#iris.target은 붓꽃 데이터 세트에서 label만으로 된 데이터를 numpy ndarray로 갖고 있음
iris_label = iris.target

#붓꽃 데이터 세트를 자세히 보기위해 DataFrame으로 변환
iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names)
iris_df['label'] = iris.target  #label column 추가
iris_df  #붓꽃 데이터 세트를 DataFrame으로 변환한 걸 출력

#학습용 데이터와 테스트용 데이터로 분리
X_train, X_test, y_train, y_test = train_test_split(iris_data, iris_label, test_size=0.2, random_state=11)

#의사 결정 트리를 이용해 학습과 예측 수행
dt_clf = DecisionTreeClassifier(random_state=11)  #DecisionTreeClassifier 객체 생성

#학습 수행
dt_clf.fit(X_train, y_train)

#학습이 완료된 DecisionTreeClassifier 객체에서 테스트 데이터 세트로 예측 수행
pred = dt_clf.predict(X_test)
                      
#정확도 측정
print('예측 정확도: {0:.4f}'.format(accuracy_score(y_test, pred)))
```

![image](https://user-images.githubusercontent.com/76269316/123438220-73294180-d60b-11eb-8f78-19524a19fd18.png)



한 줄 한 줄 살펴보면

```python
iris_data
print('iris_data type:', type(iris_data))
```

![image](https://user-images.githubusercontent.com/76269316/123496805-db584180-d664-11eb-9eb1-efc839ee0c7a.png)



다음과 같이, iris_data는 feature 값(꽃잎의 길이와 너비, 꽃받침의 길이와 너비)을 저장한 numpy의 ndarray type이라는 것을 알 수 있습니다.



```python
iris_label
print('iris_label type:',type(iris_label))
print('iris target명:', iris.target_names)
```

![image](https://user-images.githubusercontent.com/76269316/123442355-c30a0780-d60f-11eb-8455-cf21b4902470.png)



iris_label 값을 보면 0, 1, 2로만 이루어진 것을 알 수 있는데, 이는 각각 setosa, versicolor, virginica 품종을 의미합니다.



```python
iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names)
iris_df
```

![image](https://user-images.githubusercontent.com/76269316/123442659-13816500-d610-11eb-826b-6d6f152f2202.png)



label 값을 추가하지 않고 dataframe으로 변환시 해당 feature가 어떤 품종인지 알 수 없습니다.



따라서 다음과 같이 label column을 추가해줌으로써 해당 feature가 어떤 품종인지 보여줍니다.

```python
iris_df['label'] = iris.target
iris_df
```

![image](https://user-images.githubusercontent.com/76269316/123442915-59d6c400-d610-11eb-8b65-c89cfbb47d36.png)

이 작업은 그냥 feature와 label이 어떤 관계인지를 보여주기 위해 label column을 추가해서 dataframe으로 나타낸 것이고, 

실제로 학습용 데이터와 테스트용 데이터로 분리할 때는 이렇게 feature와 label을 합치지 않고 분리합니다.



이제 각각의 feature들이 어떤 품종인지에 대한 데이터가 있으니까 이를 학습용 데이터와 테스트용 데이터로 분리해 보겠습니다.

```python
X_train, X_test, y_train, y_test = train_test_split(iris_data, iris_label, test_size=0.2, random_state=11)
```

train_test_split의 첫 번째 파라미터인 iris_data는 feature 데이터 세트입니다.

두 번째 파라미터인 iris_label은 label 데이터 세트입니다.

세 번째 파라미터인 test_size는 전체 데이터 세트 중 테스트 데이터 세트의 비율입니다.

마지막 random_state는 train_test_split() 호출 시 무작위로 데이터를 분리하므로 random_state를 지정해서 수행할 때마다 동일한 데이터 세트로 분리하기 위해 임의의 숫자(11)를 부여했습니다.

위 코드를 실행하면 다음과 같은 값들이 반환됩니다.

- X_train : 학습용 feature 데이터 세트
- X_test : 테스트용 feature 데이터 세트
- y_train : 학습용 label 데이터 세트
- y_test : 테스트용 label 데이터 세트



이제 이 데이터를 기반으로 머신러닝 분류 알고리즘 중 하나인 의사 결정 트리 (Decision Tree)를 이용해 학습과 예측을 수행하겠습니다.

아직 의사 결정 트리 같은 주요 머신러닝 알고리즘에 대해 설명하지 않았지만 일단은 데이터를 학습하고 예측하는 머신러닝 기법을 구현한 주요 알고리즘 정도로 이해하면 될 것 같습니다.



```python
dt_clf = DecisionTreeClassifier(random_state=11)
```

사이킷런의 의사 결정 트리인 DecisionTreeClassfier를 객체로 생성합니다. (마찬가지로, 위 예시 코드를 수행할 때마다 동일한 학습/예측 결과를 출력하기 위해 random_state를 임의의 숫자값으로 지정해줬습니다.)



```python
dt_clf.fit(X_train, y_train)
```

DecisionTreeClassifier 객체의 fit() 메소드에 학습용 feature 데이터와 label 데이터를 입력해 호출하면 학습을 수행합니다.

즉, 학습시킬 때는 해당 feature 값에 해당하는 품종이 무엇인지를 알려주고 학습을 시키는 것입니다.



```python
pred = dt_clf.predict(X_test)
```

학습된 DecisionTreeClassfier 객체를 이용해 predict() 메소드를 사용해서 예측을 수행합니다.

이 때 파라미터에 X_test만 주었는데, 예측할 때는 해당 feature가 어떤 label일지를 예측해야하므로 label 데이터는 주지 않습니다.



```python
print('예측 정확도: {0:.4f}'.format(accuracy_score(y_test, pred)))
```

예측 결과를 기반으로 의사 결정 트리 기반의 DecisionTreeClassifier의 예측 성능을 평가하겠습니다. 

일반적으로 머신러닝 모델 성능 평가 방법은 여러가지가 있으나, 저희는 정확도를 측정해 평가하겠습니다.

정확도는 예측 결과가 실제 label 값과 얼마나 정확하게 맞는지를 평가하는 것입니다.

accuracy_score() 메소드의 파라미터로 테스트용 label 데이터 세트 (실제 결과값 : y_test)과 예측 레이블 데이터 세트(pred)를 입력합니다.



![image](https://user-images.githubusercontent.com/76269316/123496686-46554880-d664-11eb-9e1b-a356009da809.png)

실행 결과는 다음과 같습니다. 예측 정확도가 약 0.9333(93.33%)로 측정됐습니다.



붓꽃 데이터 세트로 분류를 예측하는 과정을 정리하면 다음과 같습니다.

1. 데이터 세트 분리 : 데이터를 학습 데이터와 테스트 데이터로 분리합니다.
2. 모델 학습 : 학습 데이터를 기반으로 ML 알고리즘을 적용해 모델을 학습시킵니다.
3. 예측 수행 : 학습된 ML 모델을 이용해 테스트 데이터의 분류(붓꽃 종류)를 예측합니다.
4. 평가 : 예측된 결괏값과 테스트 데이터의 실제 결괏값을 비교해 ML 모델 성능을 평가합니다.



### 사이킷런의 기반 프레임워크 익히기

사이킷런은 API 일관성과 개발 편의성을 제공하기 위한 노력이 돋보이는 패키지입니다. 

ML 모델 학습을 위해 fit(), 학습된 모델을 예측하기 위해 predict() 메소드를 제공하는데,

사이킷런에서 지도학습의 분류 알고리즘을 구현한 Classifier와 회귀 알고리즘을 구현한 Regressor 클래스에서도 fit과 predict를 사용해 간단하게 학습과 예측 결과를 확인할 수 있습니다.

이들 Classifier아 Regressor를 합쳐서 Estimator 클래스라고 부르는데, Estimator 클래스에서도 마찬가지로 fit과 predict를 제공합니다.

![Estimator](https://user-images.githubusercontent.com/76269316/123498747-caabc980-d66c-11eb-8d84-c7d0864e25e8.png)



또한 비지도학습인 차원 축소, 클러스터링, 피처 추출(Feature Extraction) 등을 구현한 클래스에서도 fit()과 transform()을 적용합니다.

비지도학습과 피처추출에서 fit은 지도학습에서의 fit과 같이 학습을 의미하는 것이 아니라, 입력 데이터의 형태에 맞춰 데이터를 변환하기 위한 사전 구조를 맞추는 작업입니다.

fit으로 변환을 위한 사전 구조를 맞추면 이후 입력 데이터의 차원 변환, 클러스터링, 피처 추출등의 작업은 transform으로 수행합니다.

fit과 transform을 합친 fit_transform() 메소드도 있는데, 사용에 약간의 차이가 있습니다. 비지도학습 포스팅에서 설명하도록 하겠습니다.



### 사이킷런의 주요 모듈

![scikit-learn module](https://user-images.githubusercontent.com/76269316/123499526-70156c00-d672-11eb-8f0d-86fb928bfe37.png)

지금은 개괄적으로만 이해해도 충분합니다. 이후 포스팅에서 상세하게 다루도록 하겠습니다.



### 내장된 예제 데이터 세트

사이킷런에는 예제로 활용할 수 있는 간단하면서 좋은 데이터 세트가 내장돼 있습니다. 저희가 위에서 사용한 붓꽃 데이터 세트도 그 중 하나입니다.

다음과 같이 5개의 데이터 세트가 내장되어 있습니다.

| API명                         | 설명                                                         |
| ----------------------------- | ------------------------------------------------------------ |
| datasets.load_boston()        | 회귀 용도이며, 미국 보스턴의 집 피처들과 가격에 대한 데이터 세트 |
| datasets.load_breast_cancer() | 분류 용도이며, 위스콘신 유방암 피처들과 악성/음성 레이블 데이터 세트 |
| datasets.load_diabetes()      | 회귀 용도이며, 당뇨 데이터 세트                              |
| datasets.load_digits()        | 분류 용도이며, 0에서 9까지 숫자의 이미지 픽셀 데이터 세트    |
| datasets.load_iris()          | 분류 용도이며, 붓꽃에 대한 피처를 가진 데이터 세트           |



fetch 계열 명령은 데이터 크기가 커서 패키지에 저장돼 있지 않고, 인터넷에서 다운받아 홈 디렉토리 아래 scikit_learn_data라는 서브 디렉토리에 저장한 후 추후 불러들여야 합니다.

- fetch_covtype() : 회귀 분석용 토지 조사 자료
- fetch_20newsgroups() : 뉴스 그룹 텍스트 자료
- fetch_olivetti_faces() : 얼굴 이미지 자료
- fetch_lfw_people() : 얼굴 이미지 자료
- fetch_lfw_pairs() : 얼굴 이미지 자료
- fetch_rcv1() : 로이터 뉴스 말뭉치
- fetch_mldata() : ML 웹사이트에서 다운로드



분류와 클러스터링을 위한 표본 데이터 생성기

| API명                           | 설명                                                         |
| ------------------------------- | ------------------------------------------------------------ |
| datasets.make_classifications() | 분류를 위한 데이터 세트를 생성.<br />높은 상관도, 불필요한 속성 등의 노이즈 효과를 위한 데이터를 무작위로 생성. |
| datasets.make_blobs()           | 클러스터링을 위한 데이터 세트를 무작위로 생성.<br />군집 지정 개수에 따라 여러가지 클러스터링을 위한 데이터 세트를 쉽게 만들어줌. |

이외에도 표본 데이터 생성기가 있지만, 위 두 개로도 충분하기 때문에 위 두 개만 소개하겠습니다.



연습용 예제 데이터가 어떻게 구성돼 있는지 보도록 하겠습니다.

사이킷런에 내장된 데이터 세트는 dictionary 형태로 있습니다.

key는 data, target, target_names, feature_names, DESCR로 구성돼 있습니다.

- data : feature의 데이터 세트 (numpy ndarray)
- target : 분류 시 label값, 회귀일 때는 숫자 결괏값 데이터 세트 (numpy ndarray)
- target_names : 개별 label의 이름 (numpy ndarray 또는 python list) 
- feature_names : feature의 이름 (numpy ndarray 또는 python list) 
- DESCR : 데이터 세트에 대한 설명과 각 feature의 설명 (python string)



먼저 붓꽃 데이터를 생성한 다음, type을 확인해보면 

```python
import sklearnfrom sklearn.datasets import load_irisiris_data = load_iris()print(type(iris_data))
```

![image](https://user-images.githubusercontent.com/76269316/123499816-40fffa00-d674-11eb-98ef-5edafaeb391c.png)

sklearn.utils.Bunch 클래스라고 나옵니다. 

Bunch 클래스는 파이썬 dictionary 자료형과 유사합니다. dictionary 형태이므로 key값을 확인해보면 

```python
keys = iris_data.keys()print('붓꽃 데이터 세트의 key:', keys)
```

![image](https://user-images.githubusercontent.com/76269316/123499877-c1bef600-d674-11eb-92ad-b946970eb1a3.png)

다음과 같이 'data', 'target', 'target_names', 'DESCR', 'feature_names'가 key값인 것을 확인할 수 있습니다.



![image](https://user-images.githubusercontent.com/76269316/123500045-157e0f00-d676-11eb-9452-fe6af8b7592f.png)

data는 feature들의 데이터 값을 가리킵니다. 데이터 세트가 dictionary 형태이기 때문에 feature 데이터 값을 추출하기 위해서는 데이터 세트.data (또는 데이터 세트['data'])를 이용하면 됩니다.

```python
iris_data.data  #iris_data['data']도 같음
```



![image](https://user-images.githubusercontent.com/76269316/123500157-ef0ca380-d676-11eb-9233-7a629bf621b0.png)



target, target_names, feature_names, DESCR 모두 동일하게 출력할 수 있습니다.

![image](https://user-images.githubusercontent.com/76269316/123500203-490d6900-d677-11eb-89d8-c70821b451d3.png)



### Model Selection 모듈 소개

[붓꽃 품종 예측하기](https://seominseok4834.github.io/machine%20learning/2.scikit-learn-machine-learning-in-python/#%EB%B6%93%EA%BD%83-%ED%92%88%EC%A2%85-%EC%98%88%EC%B8%A1%ED%95%98%EA%B8%B0)에서 학습 데이터와 테스트 데이터 세트로 분리해서 예측을 진행했는데, 학습 데이터 세트로만 학습하고, 예측할 때 발생하는 문제를 살펴보겠습니다.

```python
from sklearn.datasets import load_irisfrom sklearn.tree import DecisionTreeClassifierfrom sklearn.metrics import accuracy_scoreiris = load_iris()dt_clf = DecisionTreeClassifier()train_data = iris.datatrain_label = iris.targetdt_clf.fit(train_data, train_label)  #학습 데이터 세트로 학습#학습 데이터 세트로 예측pred = dt_clf.predict(train_data)print('예측 정확도:', accuracy_score(train_label, pred))
```

![image](https://user-images.githubusercontent.com/76269316/123500390-b241ac00-d678-11eb-9516-f983226bceae.png)

정확도가 100%가 나왔습니다.

예측 결과가 100% 정확한 이유는 이미 학습한 학습 데이터를 기반으로 예측했기 때문입니다. 

모의고사를 한 번 보고 모의고사 답을 다 외운 상태인데, 모의고사 문제와 똑같은 문제가 시험에 나와서 다 맞은 상황인 것입니다.



따라서 예측을 수행하는 데이터 세트는 학습을 수행한 학습용 데이터 세트가 아닌 테스트 전용 데이터 세트여야 합니다.

그래서 train_test_split()을 사용해 원본 데이터 세트에서 학습 및 테스트 데이터 세트로 분리한 것입니다.



train_test_split() 파라미터를 보면

```python
import sklearn
from sklearn.datasets import load_iris
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

#붓꽃 데이터 세트 로딩
iris = load_iris()

#iris.data는 데이터 세트에서 feature만으로 된 데이터를 numpy로 갖고 있음
iris_data = iris.data

#iris.target은 붓꽃 데이터 세트에서 label만으로 된 데이터를 numpy로 갖고 있음
iris_label = iris.target

#의사 결정 트리를 이용해 학습과 예측 수행
dt_clf = DecisionTreeClassifier(random_state=11)  #DecisionTreeClassifier 객체 생성

#학습용 데이터와 테스트용 데이터로 분리
X_train, X_test, y_train, y_test = train_test_split(iris_data, iris_label, test_size=0.3, random_state=121)

#학습 데이터 세트로 학습
dt_clf.fit(X_train, y_train)

#테스트 데이터 세트로 예측
pred = dt_clf.predict(X_test)
print('예측 정확도:{0:.4f}'.format(accuracy_score(y_test, pred)))
```

첫 번째 파라미터로는 feature 데이터 세트, 두 번째 파라미터로 label 데이터 세트를 입력 받습니다.

그리고 선택적으로 다음과 같은 파라미터들을 입력받습니다.

- test_size : 전체 데이터에서 테스트 데이터 세트 크기를 얼마로 샘플링 할 것인가를 결정 (default : 0.25 (25%))
- train_size : 전체 데이터에서 학습용 데이터 세트 크기를 얼마로 샘플링 할 것인가를 결정 (train_size를 사용하는게 일반적이라 잘 사용 안함)
- shuffle : 데이터를 분리하기 전 미리 섞을지를 결정 (default : True), 데이터를 분산시켜서 효율적인 학습 및 데이터 세트를 만드는데 사용됨.
- random_state : 호출할 때마다 동일한 학습/테스트용 데이터 세트를 생성하기 위해 주는 난수 값. random_state를 지정하지 않으면 수행할 때마다 다른 학습/테스트용 데이터를 생성함.



위 코드를 실행하면 다음과 같이 예측 정확도가 95.56%가 나옵니다. (붓꽃 데이터는 150개 데이터로 데이터 양이 크지 않아 테스트 데이터가 전체의 30% (45개) 밖에 되지 않아 알고리즘 성능을 판단하기에는 적절하지 않지는 않습니다.)

![image](https://user-images.githubusercontent.com/76269316/123500611-5415c880-d67a-11eb-9fb0-c41a503b55f2.png)





##### 교차 검증

위에서 알고리즘을 학습시키는 학습 데이터와 예측 성능을 평가하기 위한 별도의 테스트 데이터가 필요하다고 했는데,

만약 모델이 학습 데이터에만 과도하게 최적화 되어 실제 예측을 수행할 경우 예측 성능이 과도하게 떨어지는 과적합(Overfitting) 문제가 발생할 수도 있습니다.

