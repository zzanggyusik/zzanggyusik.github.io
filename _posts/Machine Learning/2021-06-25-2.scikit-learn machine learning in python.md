---
title:  "2.scikit-learn Machine Learning in Python"
excerpt: "사이킷런으로 시작하는 머신러닝"
toc: true
toc_label: "scikit-learn Machine Learning in Python"
toc_sticky: true

categories:
  - Machine Learning
tags:
  - Machine Learning
last_modified_at: 2021-06-25


---





>![파이썬 머신러닝 완벽 가이드](https://user-images.githubusercontent.com/76269316/122906446-1fa9c000-d38d-11eb-9cab-1eb7e347a1e6.png)
>
>파이썬 머신러닝 완벽 가이드를 읽고 공부한 내용을 정리한 포스팅입니다.



사이킷런(scikit-learn)은 파이썬 머신러닝 라이브러리 중 가장 많이 사용되는 라이브러리입니다.

사이킷런의 특징은 다음과 같습니다.

- 쉽고 가장 파이썬스러운 API를 제공
- 머신러닝을 위한 매우 다양한 알고리즘과 편리한 프레임워크, API를 제공
- 오랜 기간 실전 환경에서 검증되어 많은 환경에서 사용되는 성숙한 라이브러리임



Anaconda를 설치하면 기본으로 사이킷런까지 설치가 완료되기 때문에 별도로 설치할 필요가 없습니다.

+재설치 해야하는 경우 (conda 명령어로 설치하는 것을 권장)

```python
conda install scikit-learn  #Anaconda의 conda 명령어로 설치할 경우 사이킷런 구동에 필요한 다양한 라이브러리를 동시에 설치해줌
pip install scikit-learn
```



### 붓꽃 품종 예측하기

사이킷런에는 예제로 활용할 수 있는 간단한 데이터 세트가 내장돼 있습니다. 

이 중 하나인 붓꽃 데이터 세트를 이용해서 붓꽃 품종 예측 머신러닝 모델을 만들어보겠습니다.



붓꽃 품종 예측 머신러닝 모델이라는 것은 붓꽃 데이터 세트의 꽃잎의 길이와 너비, 꽃받침의 길이와 너비 feature를 기반으로 꽃의 품종을 분류(Classfication)한다는 것입니다.

분류(Classfication)는 대표적인 [지도학습](https://seominseok4834.github.io/1.machine-learning-term-and-concept/#supervised-learning) 방법 중 하나인데,

![image](https://user-images.githubusercontent.com/76269316/123435462-1dc64380-d5bd-11eb-940a-fdad9059c48f.png)

지도학습은 학습을 위한 다양한 feature와 분류 결정값인 label 데이터로 모델을 학습한 뒤, 별도의 테스트 데이터 세트에서 미지의 label을 예측합니다. (명확한 정답이 주어진 데이터를 먼저 학습한 뒤 미지의 정답을 예측하는 방식)

이 때, 학습을 위해 주어진 데이터 세트를 **학습 데이터 세트**, 머신러닝 모델의 예측 성능을 평가하기 위해 별도로 주어진 데이터 세트를 **테스트 데이터 세트**라고 합니다.



feature와 label이 뭔지 감이 안 오실텐데, feature는 단어 그대로 특징을 의미합니다. 

붓꽃 데이터 세트에서 feature는 꽃잎의 길이와 너비, 꽃받침의 길이와 너비를 의미합니다.

label도 마찬가지로 우리가 상표나 품명을 인쇄해서 붙여놓는 종잇조각인 라벨처럼, 각각의 데이터들이 무엇인지를 결정해주는 값입니다. 붓꽃 데이터 세트에서는 붓꽃의 품종(setosa, vesicolor, virginica)을 의미합니다.



즉, 학습 데이터 세트를 통해서 학습을 시킬 때는 각각의 feature들이 어떤 품종인지를 나타내는 label 값을 주고 학습을 시킨 다음, 실제로 학습시킨 머신 러닝 모델의 예측 성능을 평가할 때는 이 label값을 주지 않고 feature 값만 줌으로써 (이 때 주어지는 feature는 학습시킬 때의 feature와는 다른 값입니다.) label을 얼마나 잘 예측했는지를 평가합니다.



사이킷런의 여러 모듈들을 사용해서 실제로 붓꽃 품종 예측 머신러닝 모델을 만들어보겠습니다.

```python
import pandas as pd
import sklearn

from sklearn.datasets import load_iris  #sklearn.datasets : 사이킷런에서 자체적으로 제공하는 데이터 세트를 생성하는데 사용되는 모듈
from sklearn.tree import DecisionTreeClassifier  #sklearn.tree : 트리 기반 ML 알고리즘을 구현한 클래스의 모임
from sklearn.model_selection import train_test_split  #sklearn.model_selection : 학습 데이터와 검증데이터, 예측 데이터로 데이터를 분리하거나 최적의 하이퍼 파라미터로 평가하기 위한 모듈
from sklearn.metrics import accuracy_score  #정확도 측정을 위한 accuracy_score() 함수 사용

#붓꽃 데이터 세트 로딩
iris = load_iris()

#iris.data는 데이터 세트에서 feature만으로 된 데이터를 numpy ndarray로 갖고 있음
iris_data = iris.data

#iris.target은 붓꽃 데이터 세트에서 label만으로 된 데이터를 numpy ndarray로 갖고 있음
iris_label = iris.target

#붓꽃 데이터 세트를 자세히 보기위해 DataFrame으로 변환
iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names)
iris_df['label'] = iris.target  #label column 추가
iris_df  #붓꽃 데이터 세트를 DataFrame으로 변환한 걸 출력

#학습용 데이터와 테스트용 데이터로 분리
X_train, X_test, y_train, y_test = train_test_split(iris_data, iris_label, test_size=0.2, random_state=11)

#의사 결정 트리를 이용해 학습과 예측 수행
dt_clf = DecisionTreeClassifier(random_state=11)  #DecisionTreeClassifier 객체 생성

#학습 수행
dt_clf.fit(X_train, y_train)

#학습이 완료된 DecisionTreeClassifier 객체에서 테스트 데이터 세트로 예측 수행
pred = dt_clf.predict(X_test)
                      
#정확도 측정
print('예측 정확도: {0:.4f}'.format(accuracy_score(y_test, pred)))
```

![image](https://user-images.githubusercontent.com/76269316/123438220-73294180-d60b-11eb-8f78-19524a19fd18.png)



한 줄 한 줄 살펴보면

```python
iris_data
print('iris_data type:', type(iris_data))
```

![image](https://user-images.githubusercontent.com/76269316/123496805-db584180-d664-11eb-9eb1-efc839ee0c7a.png)



다음과 같이, iris_data는 feature 값(꽃잎의 길이와 너비, 꽃받침의 길이와 너비)을 저장한 numpy의 ndarray type이라는 것을 알 수 있습니다.



```python
iris_label
print('iris_label type:',type(iris_label))
print('iris target명:', iris.target_names)
```

![image](https://user-images.githubusercontent.com/76269316/123442355-c30a0780-d60f-11eb-8455-cf21b4902470.png)



iris_label 값을 보면 0, 1, 2로만 이루어진 것을 알 수 있는데, 이는 각각 setosa, versicolor, virginica 품종을 의미합니다.



```python
iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names)
iris_df
```

![image](https://user-images.githubusercontent.com/76269316/123442659-13816500-d610-11eb-826b-6d6f152f2202.png)



label 값을 추가하지 않고 dataframe으로 변환시 해당 feature가 어떤 품종인지 알 수 없습니다.



따라서 다음과 같이 label column을 추가해줌으로써 해당 feature가 어떤 품종인지 보여줍니다.

```python
iris_df['label'] = iris.target
iris_df
```

![image](https://user-images.githubusercontent.com/76269316/123442915-59d6c400-d610-11eb-8b65-c89cfbb47d36.png)

이 작업은 그냥 feature와 label이 어떤 관계인지를 보여주기 위해 label column을 추가해서 dataframe으로 나타낸 것이고, 

실제로 학습용 데이터와 테스트용 데이터로 분리할 때는 이렇게 feature와 label을 합치지 않고 분리합니다.



이제 각각의 feature들이 어떤 품종인지에 대한 데이터가 있으니까 이를 학습용 데이터와 테스트용 데이터로 분리해 보겠습니다.

```python
X_train, X_test, y_train, y_test = train_test_split(iris_data, iris_label, test_size=0.2, random_state=11)
```

train_test_split의 첫 번째 파라미터인 iris_data는 feature 데이터 세트입니다.

두 번째 파라미터인 iris_label은 label 데이터 세트입니다.

세 번째 파라미터인 test_size는 전체 데이터 세트 중 테스트 데이터 세트의 비율입니다.

마지막 random_state는 train_test_split() 호출 시 무작위로 데이터를 분리하므로 random_state를 지정해서 수행할 때마다 동일한 데이터 세트로 분리하기 위해 임의의 숫자(11)를 부여했습니다.

위 코드를 실행하면 다음과 같은 값들이 반환됩니다.

- X_train : 학습용 feature 데이터 세트
- X_test : 테스트용 feature 데이터 세트
- y_train : 학습용 label 데이터 세트
- y_test : 테스트용 label 데이터 세트



이제 이 데이터를 기반으로 머신러닝 분류 알고리즘 중 하나인 의사 결정 트리 (Decision Tree)를 이용해 학습과 예측을 수행하겠습니다.

아직 의사 결정 트리 같은 주요 머신러닝 알고리즘에 대해 설명하지 않았지만 일단은 데이터를 학습하고 예측하는 머신러닝 기법을 구현한 주요 알고리즘 정도로 이해하면 될 것 같습니다.



```python
dt_clf = DecisionTreeClassifier(random_state=11)
```

사이킷런의 의사 결정 트리인 DecisionTreeClassfier를 객체로 생성합니다. (마찬가지로, 위 예시 코드를 수행할 때마다 동일한 학습/예측 결과를 출력하기 위해 random_state를 임의의 숫자값으로 지정해줬습니다.)



```python
dt_clf.fit(X_train, y_train)
```

DecisionTreeClassifier 객체의 fit() 메소드에 학습용 feature 데이터와 label 데이터를 입력해 호출하면 학습을 수행합니다.

즉, 학습시킬 때는 해당 feature 값에 해당하는 품종이 무엇인지를 알려주고 학습을 시키는 것입니다.



```python
pred = dt_clf.predict(X_test)
```

학습된 DecisionTreeClassfier 객체를 이용해 predict() 메소드를 사용해서 예측을 수행합니다.

이 때 파라미터에 X_test만 주었는데, 예측할 때는 해당 feature가 어떤 label일지를 예측해야하므로 label 데이터는 주지 않습니다.



```python
print('예측 정확도: {0:.4f}'.format(accuracy_score(y_test, pred)))
```

예측 결과를 기반으로 의사 결정 트리 기반의 DecisionTreeClassifier의 예측 성능을 평가하겠습니다. 

일반적으로 머신러닝 모델 성능 평가 방법은 여러가지가 있으나, 저희는 정확도를 측정해 평가하겠습니다.

정확도는 예측 결과가 실제 label 값과 얼마나 정확하게 맞는지를 평가하는 것입니다.

accuracy_score() 메소드의 파라미터로 테스트용 label 데이터 세트 (실제 결과값 : y_test)과 예측 레이블 데이터 세트(pred)를 입력합니다.



![image](https://user-images.githubusercontent.com/76269316/123496686-46554880-d664-11eb-9e1b-a356009da809.png)

실행 결과는 다음과 같습니다. 예측 정확도가 약 0.9333(93.33%)로 측정됐습니다.



붓꽃 데이터 세트로 분류를 예측하는 과정을 정리하면 다음과 같습니다.

1. 데이터 세트 분리 : 데이터를 학습 데이터와 테스트 데이터로 분리합니다.
2. 모델 학습 : 학습 데이터를 기반으로 ML 알고리즘을 적용해 모델을 학습시킵니다.
3. 예측 수행 : 학습된 ML 모델을 이용해 테스트 데이터의 분류(붓꽃 종류)를 예측합니다.
4. 평가 : 예측된 결괏값과 테스트 데이터의 실제 결괏값을 비교해 ML 모델 성능을 평가합니다.



### 사이킷런의 기반 프레임워크 익히기

사이킷런은 API 일관성과 개발 편의성을 제공하기 위한 노력이 돋보이는 패키지입니다. 

ML 모델 학습을 위해 fit(), 학습된 모델을 예측하기 위해 predict() 메소드를 제공하는데,

사이킷런에서 지도학습의 분류 알고리즘을 구현한 Classifier와 회귀 알고리즘을 구현한 Regressor 클래스에서도 fit과 predict를 사용해 간단하게 학습과 예측 결과를 확인할 수 있습니다.

이들 Classifier아 Regressor를 합쳐서 Estimator 클래스라고 부르는데, Estimator 클래스에서도 마찬가지로 fit과 predict를 제공합니다.

![Estimator](https://user-images.githubusercontent.com/76269316/123498747-caabc980-d66c-11eb-8d84-c7d0864e25e8.png)



또한 비지도학습인 차원 축소, 클러스터링, 피처 추출(Feature Extraction) 등을 구현한 클래스에서도 fit()과 transform()을 적용합니다.

비지도학습과 피처추출에서 fit은 지도학습에서의 fit과 같이 학습을 의미하는 것이 아니라, 입력 데이터의 형태에 맞춰 데이터를 변환하기 위한 사전 구조를 맞추는 작업입니다.

fit으로 변환을 위한 사전 구조를 맞추면 이후 입력 데이터의 차원 변환, 클러스터링, 피처 추출등의 작업은 transform으로 수행합니다.

fit과 transform을 합친 fit_transform() 메소드도 있는데, 사용에 약간의 차이가 있습니다. 비지도학습 포스팅에서 설명하도록 하겠습니다.



### 사이킷런의 주요 모듈

![scikit-learn module](https://user-images.githubusercontent.com/76269316/123499526-70156c00-d672-11eb-8f0d-86fb928bfe37.png)

지금은 개괄적으로만 이해해도 충분합니다. 이후 포스팅에서 상세하게 다루도록 하겠습니다.



### 내장된 예제 데이터 세트

사이킷런에는 예제로 활용할 수 있는 간단하면서 좋은 데이터 세트가 내장돼 있습니다. 저희가 위에서 사용한 붓꽃 데이터 세트도 그 중 하나입니다.

다음과 같이 5개의 데이터 세트가 내장되어 있습니다.

| API명                         | 설명                                                         |
| ----------------------------- | ------------------------------------------------------------ |
| datasets.load_boston()        | 회귀 용도이며, 미국 보스턴의 집 피처들과 가격에 대한 데이터 세트 |
| datasets.load_breast_cancer() | 분류 용도이며, 위스콘신 유방암 피처들과 악성/음성 레이블 데이터 세트 |
| datasets.load_diabetes()      | 회귀 용도이며, 당뇨 데이터 세트                              |
| datasets.load_digits()        | 분류 용도이며, 0에서 9까지 숫자의 이미지 픽셀 데이터 세트    |
| datasets.load_iris()          | 분류 용도이며, 붓꽃에 대한 피처를 가진 데이터 세트           |



fetch 계열 명령은 데이터 크기가 커서 패키지에 저장돼 있지 않고, 인터넷에서 다운받아 홈 디렉토리 아래 scikit_learn_data라는 서브 디렉토리에 저장한 후 추후 불러들여야 합니다.

- fetch_covtype() : 회귀 분석용 토지 조사 자료
- fetch_20newsgroups() : 뉴스 그룹 텍스트 자료
- fetch_olivetti_faces() : 얼굴 이미지 자료
- fetch_lfw_people() : 얼굴 이미지 자료
- fetch_lfw_pairs() : 얼굴 이미지 자료
- fetch_rcv1() : 로이터 뉴스 말뭉치
- fetch_mldata() : ML 웹사이트에서 다운로드



분류와 클러스터링을 위한 표본 데이터 생성기

| API명                           | 설명                                                         |
| ------------------------------- | ------------------------------------------------------------ |
| datasets.make_classifications() | 분류를 위한 데이터 세트를 생성.<br />높은 상관도, 불필요한 속성 등의 노이즈 효과를 위한 데이터를 무작위로 생성. |
| datasets.make_blobs()           | 클러스터링을 위한 데이터 세트를 무작위로 생성.<br />군집 지정 개수에 따라 여러가지 클러스터링을 위한 데이터 세트를 쉽게 만들어줌. |

이외에도 표본 데이터 생성기가 있지만, 위 두 개로도 충분하기 때문에 위 두 개만 소개하겠습니다.



연습용 예제 데이터가 어떻게 구성돼 있는지 보도록 하겠습니다.

사이킷런에 내장된 데이터 세트는 dictionary 형태로 있습니다.

key는 data, target, target_names, feature_names, DESCR로 구성돼 있습니다.

- data : feature의 데이터 세트 (numpy ndarray)
- target : 분류 시 label값, 회귀일 때는 숫자 결괏값 데이터 세트 (numpy ndarray)
- target_names : 개별 label의 이름 (numpy ndarray 또는 python list) 
- feature_names : feature의 이름 (numpy ndarray 또는 python list) 
- DESCR : 데이터 세트에 대한 설명과 각 feature의 설명 (python string)



먼저 붓꽃 데이터를 생성한 다음, type을 확인해보면 

```python
import sklearnfrom sklearn.datasets import load_irisiris_data = load_iris()print(type(iris_data))
```

![image](https://user-images.githubusercontent.com/76269316/123499816-40fffa00-d674-11eb-98ef-5edafaeb391c.png)

sklearn.utils.Bunch 클래스라고 나옵니다. 

Bunch 클래스는 파이썬 dictionary 자료형과 유사합니다. dictionary 형태이므로 key값을 확인해보면 

```python
keys = iris_data.keys()
print('붓꽃 데이터 세트의 key:', keys)
```

![image](https://user-images.githubusercontent.com/76269316/123499877-c1bef600-d674-11eb-92ad-b946970eb1a3.png)

다음과 같이 'data', 'target', 'target_names', 'DESCR', 'feature_names'가 key값인 것을 확인할 수 있습니다.



![image](https://user-images.githubusercontent.com/76269316/123500045-157e0f00-d676-11eb-9452-fe6af8b7592f.png)

data는 feature들의 데이터 값을 가리킵니다. 데이터 세트가 dictionary 형태이기 때문에 feature 데이터 값을 추출하기 위해서는 데이터 세트.data (또는 데이터 세트['data'])를 이용하면 됩니다.

```python
iris_data.data  #iris_data['data']도 같음
```



![image](https://user-images.githubusercontent.com/76269316/123500157-ef0ca380-d676-11eb-9233-7a629bf621b0.png)



target, target_names, feature_names, DESCR 모두 동일하게 출력할 수 있습니다.

![image](https://user-images.githubusercontent.com/76269316/123500203-490d6900-d677-11eb-89d8-c70821b451d3.png)



### Model Selection 모듈 소개

[붓꽃 품종 예측하기](https://seominseok4834.github.io/machine%20learning/2.scikit-learn-machine-learning-in-python/#%EB%B6%93%EA%BD%83-%ED%92%88%EC%A2%85-%EC%98%88%EC%B8%A1%ED%95%98%EA%B8%B0)에서 학습 데이터와 테스트 데이터 세트로 분리해서 예측을 진행했는데, 학습 데이터 세트로만 학습하고, 예측할 때 발생하는 문제를 살펴보겠습니다.

```python
from sklearn.datasets import load_irisfrom sklearn.tree import DecisionTreeClassifierfrom sklearn.metrics import accuracy_scoreiris = load_iris()dt_clf = DecisionTreeClassifier()train_data = iris.datatrain_label = iris.targetdt_clf.fit(train_data, train_label)  #학습 데이터 세트로 학습#학습 데이터 세트로 예측pred = dt_clf.predict(train_data)print('예측 정확도:', accuracy_score(train_label, pred))
```

![image](https://user-images.githubusercontent.com/76269316/123500390-b241ac00-d678-11eb-9516-f983226bceae.png)

정확도가 100%가 나왔습니다.

예측 결과가 100% 정확한 이유는 이미 학습한 학습 데이터를 기반으로 예측했기 때문입니다. 

모의고사를 한 번 보고 모의고사 답을 다 외운 상태인데, 모의고사 문제와 똑같은 문제가 시험에 나와서 다 맞은 상황인 것입니다.



따라서 예측을 수행하는 데이터 세트는 학습을 수행한 학습용 데이터 세트가 아닌 테스트 전용 데이터 세트여야 합니다.

그래서 train_test_split()을 사용해 원본 데이터 세트에서 학습 및 테스트 데이터 세트로 분리한 것입니다.



train_test_split() 파라미터를 보면

```python
import sklearn
from sklearn.datasets import load_iris
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

#붓꽃 데이터 세트 로딩
iris = load_iris()

#iris.data는 데이터 세트에서 feature만으로 된 데이터를 numpy로 갖고 있음
iris_data = iris.data

#iris.target은 붓꽃 데이터 세트에서 label만으로 된 데이터를 numpy로 갖고 있음
iris_label = iris.target

#의사 결정 트리를 이용해 학습과 예측 수행
dt_clf = DecisionTreeClassifier(random_state=11)  #DecisionTreeClassifier 객체 생성

#학습용 데이터와 테스트용 데이터로 분리
X_train, X_test, y_train, y_test = train_test_split(iris_data, iris_label, test_size=0.3, random_state=121)

#학습 데이터 세트로 학습
dt_clf.fit(X_train, y_train)

#테스트 데이터 세트로 예측
pred = dt_clf.predict(X_test)
print('예측 정확도:{0:.4f}'.format(accuracy_score(y_test, pred)))
```

첫 번째 파라미터로는 feature 데이터 세트, 두 번째 파라미터로 label 데이터 세트를 입력 받습니다.

그리고 선택적으로 다음과 같은 파라미터들을 입력받습니다.

- test_size : 전체 데이터에서 테스트 데이터 세트 크기를 얼마로 샘플링 할 것인가를 결정 (default : 0.25 (25%))
- train_size : 전체 데이터에서 학습용 데이터 세트 크기를 얼마로 샘플링 할 것인가를 결정 (train_size를 사용하는게 일반적이라 잘 사용 안함)
- shuffle : 데이터를 분리하기 전 미리 섞을지를 결정 (default : True), 데이터를 분산시켜서 효율적인 학습 및 데이터 세트를 만드는데 사용됨.
- random_state : 호출할 때마다 동일한 학습/테스트용 데이터 세트를 생성하기 위해 주는 난수 값. random_state를 지정하지 않으면 수행할 때마다 다른 학습/테스트용 데이터를 생성함.



위 코드를 실행하면 다음과 같이 예측 정확도가 95.56%가 나옵니다. (붓꽃 데이터는 150개 데이터로 데이터 양이 크지 않아 테스트 데이터가 전체의 30% (45개) 밖에 되지 않아 알고리즘 성능을 판단하기에는 적절하지 않지는 않습니다.)

![image](https://user-images.githubusercontent.com/76269316/123500611-5415c880-d67a-11eb-9fb0-c41a503b55f2.png)





##### 교차 검증

위에서 알고리즘을 학습시키는 학습 데이터와 예측 성능을 평가하기 위한 별도의 테스트 데이터가 필요하다고 했는데,

만약 모델이 학습 데이터에만 과도하게 최적화 되어 실제 예측을 다른 데이터로 수행할 경우 예측 성능이 과도하게 떨어지는 과적합(Overfitting) 문제가 발생할 수도 있습니다.

그렇다고 고정된 학습 데이터와 테스트 데이터로 평가를 하다보면 테스트 데이터에만 최적의 성능을 발휘하는 편향된 모델이 유도되게 됩니다.

이러한 문제점을 개선하기 위해 교차 검증을 사용해 다양한 학습과 평가를 수행합니다.



교차 검증은 데이터 편중을 막기 위해 여러 세트로 구성된 학습 데이터 세트와 검증 데이터 세트에서 학습과 평가를 수행합니다.

각 세트에서 수행한 평가 결과에 따라 하이퍼 파라미터 튜닝 등의 모델 최적화를 할 수 있습니다.

<img src="https://user-images.githubusercontent.com/76269316/123505741-c77c0200-d69b-11eb-83c6-ba457abcec09.png" alt="image" style="zoom: 50%;" />



##### K 폴드 교차 검증

가장 보편적으로 사용되는 교차 검증 기법으로, K개의 데이터 폴드 세트를 만들어서 K번만큼 각 폴드 세트에 검증 평가를 반복적으로 수행하는 방법입니다.

![image](https://user-images.githubusercontent.com/76269316/123506053-3148db80-d69d-11eb-9f26-e31a159977d1.png)

K=5라고 할 경우, 5개의 폴드된 데이터 세트를 학습과 검증을 위한 데이터 세트로 변경하면서 5번 평가를 수행한 뒤, 이 5개 평가를 평균한 결과를 가지고 예측 성능을 평가합니다.

이렇게 학습 데이터 세트와 검증 데이터 세트를 점진적으로 변경하면서 마지막 5번째까지 학습과 검증을 수행하는 것이 K 폴드 교차 검증입니다.



사이킷런에서는 K폴드 교차 검증 프로세스를 구현하기 위해 KFold와 StratifiedKFold 클래스를 제공합니다.

KFold 클래스를 사용해 붓꽃 데이터 세트를 교차 검증하고 예측 정확도를 알아보겠습니다.

```python
import numpy as np
import sklearn
from sklearn.datasets import load_iris
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
from sklearn.model_selection import KFold

#붓꽃 데이터 세트 로딩
iris = load_iris() 

#feature 데이터를 가져옴
features = iris.data

#label 데이터를 가져옴
label = iris.target

#DecisionTreeClassifier 객체 생성
dt_clf = DecisionTreeClassifier(random_state=156)

#5개의 폴드 세트로 분리하는 KFold 객체와 폴드 세트별 정확도를 담을 리스트 객체 생성
kfold = KFold(n_splits=5)
cv_accuracy = []
print('붓꽃 데이터 세트 크기:',features.shape[0])
```

![image](https://user-images.githubusercontent.com/76269316/123506321-8cc79900-d69e-11eb-8ea3-40f9902357ec.png)



```python
Kfold = KFold(n_splits=5)
```

KFold객체를 생성했으니 이제 생성된 KFold 객체의 split()을 호출해 전체 붓꽃 데이터를 5개의 폴드 데이터 세트로 분리합니다.

전체 붓꽃 데이터는 모두 150개이므로 학습용 데이터 세트는 이 중 4/5인 120개, 검증용 데이터 세트는 30개로 분할됩니다.



```python
n_iter = 0for train_index, test_index in kfold.split(features):    #kfold.split()으로 반환된 인덱스를 이용해 학습용, 검증용 테스트 데이터 추출    X_train, X_test = features[train_index], features[test_index]    y_train, y_test = label[train_index], label[test_index]        #학습 및 예측    dt_clf.fit(X_train, y_train)    pred = dt_clf.predict(X_test)    n_iter += 1        #반복 시 마다 정확도 측정    accuracy = np.round(accuracy_score(y_test, pred),4)  #소숫점 다섯째자리에서 반올림 (넷째자리까지 표시)    train_size = X_train.shape[0]    test_size = X_test.shape[0]    print('\n#{0} 교차 검증 정확도: {1}, 학습 데이터 크기: {2}, 검증 데이터 크기: {3}'.format(n_iter, accuracy, train_size, test_size))    print('#{0} 검증 세트 인덱스: {1}'.format(n_iter, test_index))    	#정확도를 cv_accuracy list에 넣음    cv_accuracy.append(accuracy)    #개별 iteration별 정확도를 합하여 평균 정확도 계산print('\n## 평균 검증 정확도: ', np.mean(cv_accuracy))
```

![image](https://user-images.githubusercontent.com/76269316/123513525-a7af0300-d6c8-11eb-9214-161ae2a8323d.png)



KFold 클래스의 split()을 호출하면 학습용/검증용 데이터로 분할할 수 있는 인덱스를 반환합니다. 따라서 학습용 인덱스를 train_index, 검증용 인덱스를 test_index로 받았습니다.

```python
for train_index, test_index in kfold.split(features):
```



이후 앞에서 했던 것과 마찬가지로 의사 결정 트리 DecisionTreeClassifier를 이용해 예측 성능을 평가하고 이를 cv_accuracy list에 추가해주었습니다.

5개의 예측 평가를 구한뒤 이를 평균해서 평균 정확도를 계산했습니다.

```python
print('\n## 평균 검증 정확도: ', np.mean(cv_accuracy))
```



##### Stratified K 폴드

Stratified K 폴드는 불균형한 분포도를 가진 label(결정 클래스) 데이터 집합을 위한 K 폴드 방식입니다.

불균형한 분포도를 가진 label 데이터 집합은 특정 label 값이 특이하게 많거나 매우 적어서 값의 분포가 한 쪽으로 치우치는 것을 말합니다.



예를 들어, 대출 사기 데이터를 예측한다고 할 때 이 데이터 세트는 1억건이고 수십 개의 feature와 대출 사기 여부를 뜻하는 label (대출 사기: 1, 정상 대출: 0)로 구성돼 있습니다.

1억 건중 대출 사기가 1,000건이 있다고 하면 전체의 0.0001%의 아주 작은 확률로 대출 사기 label이 존재합니다. 

이렇게 작은 비율로 1 label이 존재한다면 K 폴드로 랜덤하게 학습 및 테스트 세트의 인덱스를 고르더라도 0과 1의 비율을 제대로 반영하지 못하게 됩니다. (1이 특정 학습/테스트 데이터 세트에는 상대적으로 많이 들어있고, 다른 학습/테스트 데이터 세트에는 그렇지 못하게 됨.)

대출 사기 label이 1인 레코드는 건수는 작지만 대출 사기를 예측하기 위한 중요한 feature 값을 갖고 있기 때문에 매우 중요한 데이터 세트입니다.

**따라서 원본 데이터와 유사한 label 값의 분포를 학습/테스트 데이터 세트에도 유지하는 것이 중요합니다.**



Stratified K 폴드는 원본 데이터의 label 분포를 먼저 고려한 다음, 이 분포와 동일하게 학습과 검증 데이터 세트를 분배합니다.



먼저 K 폴드가 어떤 문제를 갖고있는지 보도록 하겠습니다.

```python
import pandas as pd
import sklearn
from sklearn.datasets import load_iris
from sklearn.model_selection import KFold

iris = load_iris()
iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)
iris_df['label'] = iris.target

#3개의 폴드 세트로 분리하는 KFold 객체 생성
kfold = KFold(n_splits=3)
n_iter = 0
for train_index, test_index in kfold.split(iris_df):
    n_iter += 1
    label_train = iris_df['label'].iloc[train_index]
    label_test = iris_df['label'].iloc[test_index]
    print('## 교차 검증: {0}'.format(n_iter))
    print('학습 레이블 데이터 분포:\n', label_train.value_counts())
    print('검증 레이블 데이터 분포:\n', label_test.value_counts())
```

![image](https://user-images.githubusercontent.com/76269316/123512853-c3180f00-d6c4-11eb-867d-d70458eb39b2.png)



교차 검증시마다 3개의 폴드 세트로 만들어지는 학습 label과 검증 label이 완전히 다른 값으로 추출되었습니다.

첫 번째 교차 검증에서는 학습 label이 1, 2값으로만 50개씩 추출되었고 검증 label에 0 값이 50개 추출되었습니다. 

학습 label이 1, 2 밖에 없으므로 0의 경우는 전혀 학습하지 못하게되고, 이 경우 예측 정확도는 0이 될 수 밖에 없습니다.



StraitifiedKFold는 이렇게 KFold로 분할된 label 데이터 세트가 전체 label 값의 분포도를 반영하지 못하는 문제를 해결해 줍니다.

이번에는 StraitifiedKFold를 사용해 학습/검증 label 데이터 분포도를 확인해보겠습니다.

```python
import pandas as pdimport sklearnfrom sklearn.datasets import load_irisfrom sklearn.model_selection import StratifiedKFoldiris = load_iris()iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)iris_df['label'] = iris.target#3개의 폴드 세트로 분리하는 StratifiedKFold 객체 생성skf = StratifiedKFold(n_splits=3)n_iter = 0#StratifiedKFold split() 호출 시에는 *label 데이터 세트 추가 입력 필요for train_index, test_index in skf.split(iris_df, iris_df['label']):    n_iter += 1    label_train = iris_df['label'].iloc[train_index]    label_test = iris_df['label'].iloc[test_index]    print('## 교차 검증:{0}'.format(n_iter))    print('학습 레이블 데이터 분포:\n', label_train.value_counts())    print('검증 레이블 데이터 분포:\n', label_test.value_counts())
```

![image](https://user-images.githubusercontent.com/76269316/123513175-97962400-d6c6-11eb-931c-a11d28a06730.png)



출력 결과를 보면 학습 label과 검증 label 데이터 값의 분포도가 동일하게 할당된 것을 볼 수 있습니다.

이렇게 분할이 되어야 label 0, 1, 2 값에 대해 모두 학습할 수 있고 이에 기반해 검증할 수 있습니다. 이제 이 데이터를 이용해 검증해보도록 하겠습니다.



```python
import numpy as np
import sklearn
from sklearn.datasets import load_iris
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
from sklearn.model_selection import StratifiedKFold

#붓꽃 데이터 세트 로딩
iris = load_iris() 

#feature 데이터를 가져옴
features = iris.data

#label 데이터를 가져옴
label = iris.target

dt_clf = DecisionTreeClassifier(random_state=156)

skfold = StratifiedKFold(n_splits=3)
n_iter = 0
cv_accuracy = []

#StratifiedKFold split() 호출 시에는 *label 데이터 세트 추가 입력 필요
for train_index, test_index in skfold.split(features, label):
    #split()으로 반환된 인덱스를 이용해 학습용, 검증용 테스트 데이터 추출
    X_train, X_test = features[train_index], features[test_index]
    y_train, y_test = label[train_index], label[test_index]
    
    #학습 및 예측
    dt_clf.fit(X_train, y_train)
    pred = dt_clf.predict(X_test)
    n_iter += 1
    
    #반복 시 마다 정확도 측정
    accuracy = np.round(accuracy_score(y_test, pred), 4)  #소숫점 다섯째자리에서 반올림 (넷째자리까지 표시)
    train_size = X_train.shape[0]
    test_size = X_test.shape[0]
    print('\n#{0} 교차 검증 정확도: {1}, 학습 데이터 크기: {2}, 검증 데이터 크기: {3}'.format(n_iter, accuracy, train_size, test_size))
    print('#{0} 검증 세트 인덱스: {1}'.format(n_iter, test_index))
    
	#정확도를 cv_accuracy list에 넣음
    cv_accuracy.append(accuracy)
    
#교차 검증별 정확도 및 평균 정확도 계산
print('\n## 교차 검증별 정확도:', np.round(cv_accuracy, 4))
print('\n## 평균 검증 정확도: ', np.round(np.mean(cv_accuracy), 4))    
```

![image](https://user-images.githubusercontent.com/76269316/123513768-e98c7900-d6c9-11eb-82af-a381a3a4d6ba.png)



3개의 Straitifed K 폴드로 교차 검증한 결과 평균 검증 정확도가 약 96.67%가 측정됐습니다.

Stratified K 폴드의 경우 원본 데이터의 label 분포도 특성을 반영한 학습 및 검증 데이터 세트를 만들 수 있으므로 왜곡된 label 데이터 세트에서는 반드시 Straitifed K 폴드를 이용해 교차 검증해야 합니다.



+분류(Classification)에서의 교차 검증은 K 폴드가 아니라 Stratified K 폴드로 분할돼야 합니다. (회귀(Regression)의 결정값(label)이 이산값 형태가 아니라 연속된 숫자값이기 때문에 Straitifed K 폴드가 지원되지 않음)



##### 교차 검증을 보다 간편하게 - cross_val_score()

이전까지는

1. 폴드 세트를 설정
2. for 루프에서 반복으로 학습 및 테스트 데이터 인덱스 추출
3. 반복적으로 학습과 예측을 수행하고 예측 성능 반환

위 3가지 과정을 거쳤습니다. 사이킷런의 cross_val_score()에서는 이런 일련의 과정을 한꺼번에 수행해주는 API를 제공합니다.



```python
cross_val_score(estimator, X, y=None, scoring=None, cv=None, n_jobs=1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs')
```

파라미터 중 estimator, X, y, scoring, cv가 주요 파라미터입니다.

- estimator : 사이킷런 분류 알고리즘 클래스(Classifier) 또는 회귀 알고리즘 클래스(Regressor)를 의미합니다.
- X : 피처 데이터 세트
- y : 레이블 데이터 세트
- scoring : 예측 성능 평가 지표
- cv : 교차 검증 폴드 수



+cross_val_score()는 classifier가 입력되면 Straitifed K 폴드 방식으로 레이블 값의 분포에 따라 학습/테스트 세트를 분할합니다. (Regressor인 경우 K 폴드 방식으로 분할)



```python
import numpy as np
import sklearn
from sklearn.datasets import load_iris
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import cross_val_score

iris_data = load_iris()
dt_clf = DecisionTreeClassifier(random_state=156)

data = iris_data.data
label = iris_data.target

#성능 지표는 정확도(accuracy), 교차 검증 세트는 3개
scores = cross_val_score(dt_clf, data, label, scoring='accuracy', cv=3)
print('교차 검증별 정확도:', np.round(scores, 4))
print('평균 검증 정확도:', np.round(np.mean(scores), 4))
```

![image](https://user-images.githubusercontent.com/76269316/123515011-d3ce8200-d6d0-11eb-95b6-f6a1dfd35cb2.png)



cross_val_score 수행 후 scoring 파라미터로 지정된 성능 평가 값을 배열 형태로 반환합니다.

일반적으로 이를 평균해 평가 수치로 사용합니다.

cross_val_score는 내부적으로 학습(fit), 예측(predict), 평가(evaluation)를 시켜주므로 간단하게 교차 검증을 수행할 수 있습니다.



또한 바로 위에서 StraitifedKFold의 수행 결과와 동일한 결과가 나온 것을 알 수 있습니다.

이는 cross_val_score가 내부적으로 StraitifedKFold를 사용하기 때문입니다.



비슷한 API로 cross_validate()가 있습니다. 

cross_val_score는 하나의 평가 지표만 가능하지만 cross_validate는 여러 개의 평가 지표를 반환할 수 있습니다. 

또한 학습 데이터에 대한 성능 평가 지표와 수행 시간도 같이 제공합니다. 아래 import문을 통해 사용할 수 있습니다.

```python
from sklearn.model_selection import cross_validate
```



##### GridSearchCV - 교차 검증과 최적 하이퍼 파라미터 튜닝을 한 번에

아직 머신러닝 알고리즘을 구성하는 하이퍼 파라미터에 대한 상세한 설명을 하지 않았기 때문에 이 부분은 그냥 한 번 읽기만 해도 될 것 같습니다.

하이퍼 파라미터는 머신러닝 알고리즘을 구성하는 주요 구성 요소로써, 값을 조정해 알고리즘의 예측 성능을 개선할 수 있습니다.



사이킷런에서는 GridSearchCV API를 통해 분류나 회귀와 같은 알고리즘에 사용되는 하이퍼 파라미터 딕셔너리를 만들고 이를 교차 검증으로 순차 적용하면서  최적의 파라미터를 찾을 수 있도록 합니다.



만약 다음과 같은 하이퍼 파라미터 딕셔너리가 있고, CV*교차 검증 폴드 수)가 3회라면

```python
gird_parameters = {'max_depth': [1, 2, 3], 'min_samples_split': [2, 3]}
```

| 순번 | max_depth | min_samples_split |
| :--: | :-------: | :---------------: |
|  1   |     1     |         2         |
|  2   |     1     |         3         |
|  3   |     2     |         2         |
|  4   |     2     |         3         |
|  5   |     3     |         2         |
|  6   |     3     |         3         |

CV 3회 X 6개 파라미터 조합 = 18회의 학습/평가가 이루어지게 됩니다.



GridSearchCV 클래스 주요 파라미터는 다음과 같습니다.

- estimator : classifier, regressor, pipeline이 사용될 수 있습니다.
- param_grid : key + 리스트 값을 갖는 딕셔너리가 주어집니다. (estimator 튜닝을 위해 파라미터명과 파라미터 값을 지정)
- scoring : 예측 성능을 측정할 평가 방법 지정 (보통 사이킷런 성능 평가 지표를 지정하는 문자열(예 - 정확도 : accuracy)로 지정하나 별도의 성능 평가 지표 함수도 지정 가능)
- cv : 교차 검증을 위해 분할되는 학습/테스트 세트 개수
- refit : True로 생성시 가장 최적의 하이퍼 파라미터를 찾은 뒤 입력된 estimator 객체를 해당 하이퍼 파라미터로 재학습시킴. (default : true)



```python
import pandas as pd
import sklearn
from sklearn.datasets import load_iris
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.model_selection import GridSearchCV

#데이터를 로딩하고 학습 데이터와 테스틑 데이터로 분리
iris_data = load_iris()
X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, test_size=0.2, random_state=121)

#DecisionTreeClassifier 객체 생성
dtree = DecisionTreeClassifier(random_state=156)

#하이퍼 파라미터를 딕셔너리 형태로 설정
parameters = {'max_depth':[1, 2, 3], 'min_samples_split':[2, 3]}

#param_grid 하이퍼 파라미터를 3개의 train, test 세트 폴드로 나누어 테스트 수행 설정
grid_dtree = GridSearchCV(dtree, param_grid=parameters, cv=3, refit=True)  #refit=True가 default (최적의 파라미터로 재학습 시킴)

#붓꽃 학습 데이터로 param_grid 하이퍼 파라미터를 순차적으로 학습/평가
grid_dtree.fit(X_train, y_train)

#GridSearchCV 결과를 추출해 DataFrame으로 변환
scores_df = pd.DataFrame(grid_dtree.cv_results_)
scores_df[['params', 'mean_test_score', 'rank_test_score', 'split0_test_score', 'split1_test_score', 'split2_test_score']]
```

![image](https://user-images.githubusercontent.com/76269316/123516229-029b2700-d6d6-11eb-8b5a-63a2e0271d36.png)



rank_test_score가 1이라는 의미는 해당 parameter를 갖고 평가한 결과 예측 성능이 1위라는 의미입니다. 

인덱스 5, 6번이 mean_test_score(split0, split1, split2 세 개의 성능 수치를 평균한 값)가 0.975로 가장 높은 것을 볼 수 있습니다.



- parmas column : 수행할 때마다 적용된 개별 하이퍼 파라미터 값
- rank_test_score : 하이퍼 파라미터별로 성능이 좋은 score 순위 (1이 가장 뛰어난 순위이며 이때의 파라미터가 최적의 하이퍼 파라미터)
- mean_test_score : 개별 하이퍼 파라미터별로 CV의 폴딩 테스트 세트에 대해 총 수행한 평가 평균값



GridSearchCV 객체의 fit을 수행하면 최고 성능을 나타낸 하이퍼 파라미터의 값과 그 떄의 평과 결과 값이 best_params\_, best_score\_ 속성에 기록됩니다. (rank_test_score가 1일 때의 값)

```python
print('GridSearchCV 최적 파라미터:', grid_dtree.best_params_)
print('GridSearchCV 최고 정확도:{0:.4f}'.format(grid_dtree.best_score_))
```

![image](https://user-images.githubusercontent.com/76269316/123516457-1dba6680-d6d7-11eb-82f7-101b8881d7e7.png)



refit=True인 경우 GridSearchCV가 최적 성능을 나타내는 하이퍼 파라미터로 estimator를 학습해 best_estimator_로 저장합니다.

best\_estimator\_를 이용해 train_test_split()으로 분리한 테스트 데이터 세트에 대해 예측하고 성능을 평가해보겠습니다.

```python
#GridSearchCV의 refit으로 이미 학습된 estimator 반환
estimator = grid_dtree.best_estimator_

#GridSearchCV의 best_estimator_는 이미 최적 학습 됐으므로 별도 학습이 필요 없음
pred = estimator.predict(X_test)
print('테스트 데이터 세트 정확도:{0:.4f}'.format(accuracy_score(y_test, pred)))
```

![image](https://user-images.githubusercontent.com/76269316/123516536-902b4680-d6d7-11eb-86e9-e657bd50a92b.png)

약 96.67%의 결과가 나왔습니다.



일반적으로 학습 데이터를 GridSearchCV를 이용해 최적 하이퍼 파라미터 튜닝을 수행하고 별도의 테스트 세트에서 이를 평가하는 것이 일반적인 머신러닝 모델 적용 방법입니다.



### 데이터 전처리

ML 알고리즘은 데이터에 기반하기 때문에 어떤 데이터를 입력으로 가지느냐에 따라 결과가 크게 달라집니다. (Garbage In, Garbage Out)

그래서  ML 알고리즘을 적용하기 전에 데이터에 대해 미리 처리해야 할 사항들이 있습니다.

- 결손값(Nan)을 허용하지 않음 → Null 값은 다른 값으로 변환되어야 함.

feature 값 중 Null 값이 얼마되지 않는다면 feautre의 평균값 등으로 대체할 수 있지만 Null값이 대부분이라면 해당 feature는 drop 하는 것이 좋습니다.

(해당 feature가 중요도가 높은 feature이고, Null 값을 단순히 평균값으로 대체할 경우 예측 왜곡이 심할 수 있는 경우 더 정밀한 대체 값을 선정해야 합니다.)

- 문자열 값을 입력 값으로 허용하지 않음 → 인코딩해서 숫자형으로 변환해야 함.

문자열 feature는 카테고리형 / 텍스트형으로 나뉘는데 텍스트형은 feature vectorization 등의 기법으로 벡터화해야하는데, 나중에 텍스트 분석 포스트에서 설명하도록 하겠습니다.

문자열 feature의 경우에도 불필요한 feature라고 판단되는 경우 삭제하는 게 좋습니다. (주민번호나 단순 문자열 아이디와 같은 경우 단순히 row를 식별하는데만 사용되고, 알고리즘을 오히려 복잡하게 만들고 예측 성능을 떨어뜨리기 때문)



#### 데이터 인코딩



##### 레이블 인코딩 (Label Encoding)

카테고리 feature를 코드형 숫자 값으로 변환하는 것입니다.

TV, 냉장고, 전자레인지, 컴퓨터, 선풍기, 믹서 값이 있다면 TV: 1, 냉장고: 2, 전자레인지: 3 ··· 같은 숫자형 값으로 변환합니다.

주의해야 할 점은 '01', '02' 같은 코드값 역시 문자열이므로 1, 2 같은 숫자형 값으로 변환돼야 합니다.

```python
import sklearn
from sklearn.preprocessing import LabelEncoder

items=['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']

#LabelEncoder를 객체로 생성한 후, fit()과 transform()으로 인코딩 
encoder = LabelEncoder()
encoder.fit(items)
labels = encoder.transform(items)
print('인코딩 변화값:', labels)
```

![image](https://user-images.githubusercontent.com/76269316/123532402-d02a1200-d747-11eb-8e06-5172521aced2.png)



TV는 0, 냉장고 1, 전자레인지 4, 컴퓨터 5, 선풍기 3, 믹서는 2로 변환됐습니다.

위 코드는 데이터가 작아서 문자열 값이 어떤 숫자 값으로 인코딩 됐는지 바로 알 수 있지만 보통은 한 번에 알아보기 힘듧니다.

```python
print('인코딩 클래스:', encoder.classes_)
```

![image](https://user-images.githubusercontent.com/76269316/123532454-1c755200-d748-11eb-8500-6e7c8c18ab30.png)



classes_ 속성은 0번부터 변환된 인코딩 값에 대한 원본 값을 갖고 있습니다.

inverse_transform()을 사용해서 인코딩된 값을 다시 디코딩 할 수 있습니다.

```python
print('디코딩 원본값:', encoder.inverse_transform([4, 5, 2, 0, 1, 1, 3, 3]))
```

![image](https://user-images.githubusercontent.com/76269316/123532478-4e86b400-d748-11eb-8ac0-6b2ed03efa0a.png)



레이블 인코딩은 간단하게 문자열 값을 숫자형 카테고리 값으로 변환합니다.

하지만 몇몇 ML 알고리즘에서 이를 적용할 경우 숫자 값의 크고 작음에 대한 특성이 작용해서 예측 성능이 떨어지는 경우가 발생할 수 있습니다.

예를 들어 냉장고가 1, 믹서가 2로 변환되면 특정 알고리즘에서 가중치가 더 부여되어 믹서를 더 중요하게 인식할 수 있다는 의미입니다.

하지만 냉장고와 믹서는 단순히 카테고리 feature이기 때문에 숫자 값에 따라 중요도로 인식되면 안됩니다.

이런 특성 때문에 레이블 인코딩은 선형 회귀와 같은 ML 알고리즘에는 적용하지 않아야합니다. (트리 계열의 ML 알고리즘은 이러한 특성을 반영하지 않으므로 적용 가능)

이런 문제점을 개선하기 위한 인코딩 방식이 원-핫 인코딩입니다.



##### 원-핫 인코딩 (One-Hot Encoding)

원-핫 인코딩은 feature 값의 유형에 따라 새로운 feature를 추가해 고유 값에 해당하는 column에만 1을 표시하고 나머지 column에는 0으로 표시하는 방식입니다.

