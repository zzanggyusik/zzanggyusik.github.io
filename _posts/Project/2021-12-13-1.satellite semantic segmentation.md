---

title:  "1.Satellite Semantic Segmentation"
excerpt: "MMSegmentationì„ ì‚¬ìš©í•´ì„œ semantic segmentation êµ¬í˜„í•˜ê¸°"
toc: true
toc_label: "Satellite Semantic Segmentation"
toc_sticky: true
published: true

categories:
  - Project
tags:
  - Semantic Segmentation
  - Satellite Image
last_modified_at: 2021-12-13


---

ì¸ê³µì§€ëŠ¥ ìˆ˜ì—…ì—ì„œ í–ˆë˜ í”„ë¡œì íŠ¸ë¥¼ ì •ë¦¬í•œ í¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.

<br>

### 0. Introduce Project

ë‹¤ìŒê³¼ ê°™ì€ ì¸ê³µìœ„ì„± ì‚¬ì§„ì—ì„œ

<img src="https://user-images.githubusercontent.com/76269316/145778196-6bfb9809-9a6b-4a2d-b2d9-1c5aad222bed.png" alt="BLD01552_PS3_K3A_NIA0373" style="zoom: 50%;" />

ì•„ë˜ì™€ ê°™ì´ ë¹Œë”©ê³¼ ë„ë¡œë¥¼ ê²€ì¶œí•˜ëŠ” í”„ë¡œì íŠ¸ì˜€ìŠµë‹ˆë‹¤.

<img src="https://user-images.githubusercontent.com/76269316/145778324-c584aa87-fe97-458b-8220-c2f43c2d7a98.png" alt="BLD01552_PS3_K3A_NIA0373 (1)" style="zoom: 50%;" />

<br>

ì‚¬ìš©í•œ ë°ì´í„°ì„¸íŠ¸ëŠ” [ì—¬ê¸°](https://aihub.or.kr/aidata/7982)ì—ì„œ ë‹¤ìš´ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ë°ì´í„°ì„¸íŠ¸ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì´ë¯¸ì§€ íŒŒì¼ê³¼ ë§ˆìŠ¤í‚¹ ì •ë³´ê°€ ë‹´ê¸´ json íŒŒì¼ í˜•íƒœë¡œ ì£¼ì–´ì¡ŒìŠµë‹ˆë‹¤.

<img width="1032" alt="ìŠ¤í¬ë¦°ìƒ· 2021-12-14 ì˜¤í›„ 2 54 50" src="https://user-images.githubusercontent.com/76269316/145941251-1d7f861a-6c89-4296-bffc-38e47213fc19.png" style="zoom:67%;" >

<img width="1032" alt="ìŠ¤í¬ë¦°ìƒ· 2021-12-14 ì˜¤í›„ 2 57 57" src="https://user-images.githubusercontent.com/76269316/145941596-29becea6-ba88-4115-94e2-442375db3b7e.png" style="zoom:67%;" >

<br>

<img width="421" alt="ìŠ¤í¬ë¦°ìƒ· 2021-12-13 ì˜¤í›„ 5 46 59" src="https://user-images.githubusercontent.com/76269316/145780258-41b2a9dc-5170-4042-a7aa-2006f27ebaf7.png">

ëª¨ë¸ êµ¬í˜„ì„ ìœ„í•´ì„œ [MMSegmentation](https://github.com/open-mmlab/mmsegmentation)ì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.

MMSegmentationì„ ì‚¬ìš©í•œ ì´ìœ ëŠ” ì»´í“¨í„° ë¹„ì „ì„ ì²˜ìŒ ì ‘í–ˆê¸° tensorflowë‚˜ kerasì²˜ëŸ¼ ë„¤íŠ¸ì›Œí¬ë¥¼ ì§ì ‘ êµ¬ì„±í•˜ëŠ”ë°ì— ë¬´ë¦¬ê°€ ìˆë‹¤ê³  íŒë‹¨ë¼, MMSegmentationì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.

MMSegmentationì€ ì¤‘êµ­ ì¹­í™” ëŒ€í•™ì—ì„œ êµ¬í˜„í•œ open source toolboxë¡œ configuration íŒŒì¼ì„ ë³€ê²½í•˜ëŠ” ê²ƒë§Œìœ¼ë¡œ mmsegmentationì—ì„œ êµ¬í˜„í•´ë†“ì€ ë‹¤ì–‘í•œ ëª¨ë¸ë“¤ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

<br>MMsegmentationì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´ì„  ground truth íŒŒì¼ì´ gray scaleë¡œ ë§ˆìŠ¤í‚¹ ë¼ ìˆì–´ì•¼í•©ë‹ˆë‹¤.

[Creating custom data for training #185](https://github.com/open-mmlab/mmsegmentation/issues/185)

<br>

ìì„¸íˆ ì„¤ëª…í•˜ë©´,

ë§ˆìŠ¤í‚¹ ì •ë³´ê°€ ë“¤ì–´ìˆëŠ” json íŒŒì¼ì„ ì‚¬ìš©í•´ì„œ ì´ë¯¸ì§€ë¥¼ ëª¨ë‘ 0ìœ¼ë¡œ ì±„ìš´(zero masking) ë‹¤ìŒ, ë¹Œë”©ê³¼ ê±´ë¬¼ì´ ìˆëŠ” ë¶€ë¶„ë§Œ ë§ˆìŠ¤í‚¹ í•´ì£¼ë©´ ë‹¤ìŒê³¼ ê°™ì´ ë§ˆìŠ¤í‚¹ ë˜ê²Œ ë©ë‹ˆë‹¤.

<img src="https://user-images.githubusercontent.com/76269316/145782389-6e487e19-3188-4761-8980-0b2db1b94399.png" alt="BLD01552_PS3_K3A_NIA0373" style="zoom: 50%;" />

í•˜ì§€ë§Œ ì´ ìƒíƒœë¡œëŠ” mmsegmentationì—ì„œ ì‚¬ìš©í•  ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤. í˜„ì¬ ë°°ê²½ì€ ëª¨ë‘ 0ì¸ ìƒíƒœì´ì§€ë§Œ ê±´ë¬¼ê³¼ ë„ë¡œëŠ” ëª¨ë‘ 0ì´ ì•„ë‹Œ ì–´ë–¤ í”½ì…€ê°’ì„ ê°–ê³  ìˆìŠµë‹ˆë‹¤.

ì´ ë•Œ ë¹Œë”©ì˜ í”½ì…€ê°’ì„ 1, ë„ë¡œì˜ í”½ì…€ê°’ì„ 2ë¡œ ë°”ê¿”ì£¼ë©´ ë‹¤ìŒê³¼ ê°™ì´ í‘ë°± ì´ë¯¸ì§€(gray scale)ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

<img src="https://user-images.githubusercontent.com/76269316/145782846-feb620c9-ddd4-404b-862e-ab96785be6df.png" alt="BLD01552_PS3_K3A_NIA0373 (1)" style="zoom:50%;" />

ì €í¬ê°€ ë³´ê¸°ì—ëŠ” ì˜¨í†µ ê²€ì€ìƒ‰ì´ì§€ë§Œ ì‹¤ì œë¡œ ì´ ì•ˆì—ëŠ” ì•„ë˜ì™€ ê°™ì´ í´ë˜ìŠ¤ ë³„ë¡œ ê±´ë¬¼ ë¶€ë¶„ì€ 1, ë„ë¡œ ë¶€ë¶„ì€ 2ë¡œ ì±„ì›Œì ¸ìˆìŠµë‹ˆë‹¤.

![image](https://user-images.githubusercontent.com/76269316/145783066-7c60e945-7781-4bb9-be33-3e2c0d8b8ea3.png)

[ì¶œì²˜: Semantic Segmentation ì²«ê±¸ìŒ!](https://medium.com/hyunjulie/1%ED%8E%B8-semantic-segmentation-%EC%B2%AB%EA%B1%B8%EC%9D%8C-4180367ec9cb)

<br>

ë”°ë¼ì„œ ì €ëŠ” ë¨¼ì € ê±´ë¬¼ì€ (128, 128, 0)ë¡œ, ë„ë¡œëŠ” (128, 64, 128)ë¡œ ë§ˆìŠ¤í‚¹ í•œ ë’¤, ì´ë¥¼ ë‹¤ì‹œ 1, 2ë¡œ mapping ì‹œì¼œì£¼ì—ˆìŠµë‹ˆë‹¤.

<br><br>

### 1. Masking (gray scale)

```json
    "features": [
      {
        "geometry": {
          "coordinates": [
            [
              31.3609468532,
              30.140372558,
              0
            ],
            [
              31.3667921448,
              30.1404454243,
              0
            ],
            [
              31.366708448,
              30.1455259019,
              0
            ],
            [
              31.3608628572,
              30.1454530208,
              0
            ]
          ],
          "type": "Polygon"
        },
        "properties": {
          "object_imcoords": "EMPTY",
          "building_imcoords": "EMPTY",
          "road_imcoords": "211.13825632612296,0,228.25757440661943,0,236.73506587440733,0,222.73960447617443,8.736311155155173,205.13056959253697,20.22717757755483,156.48327523790732,56.01530199102005,107.5950759842507,91.32161660643132,51.870298799909584,131.75963478574357,-2.8421709430404014e-14,170.75222357089405,-2.8421709430404014e-14,145.7946338998848,80.57492376553665,89.70522674180145,146.761359523997,42.5906896754829",
          "image_id": "BLD00596_PS3_K3A_NIA0277.png",
          "ingest_time": "2020-11-11T08:29:37.297611Z",
          "type_id": "3",
          "type_name": "Secondary"
        },
        "type": "Feature"
      }
```

json íŒŒì¼ì€ ë‹¤ìŒê³¼ ê°™ì´ êµ¬ì„±ë¼ ìˆìŠµë‹ˆë‹¤.

ë„ë¡œ ë§ˆìŠ¤í‚¹ ì¢Œí‘œ ì •ë³´ê°€ ë‹´ê¸´ json íŒŒì¼ì´ë¼ road_imcoords keyì—ë§Œ ì¢Œí‘œ ì •ë³´ê°€ ìˆê³  building_imcoordsëŠ” EMPTYë¡œ ë¼ ìˆëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

<br>

pandas read_jsonì„ ì‚¬ìš©í•´ì„œ ì´ë¯¸ì§€ ì´ë¦„ê³¼ ë™ì¼í•œ json íŒŒì¼ì„ ì½ì–´ë“¤ì—¬ ì¢Œí‘œ ì •ë³´ì— í•´ë‹¹í•˜ëŠ” ë¶€ë¶„ì„ fill_polyë¡œ ë§ˆìŠ¤í‚¹í•´ì¤¬ìŠµë‹ˆë‹¤.

**masking.py**

json íŒŒì¼ì„ ì½ì–´ë“¤ì—¬ ë§ˆìŠ¤í‚¹í•˜ëŠ” ì½”ë“œ

ê±´ë¬¼ë§Œ ìˆëŠ” ê²½ìš°, ê±´ë¬¼+ë„ë¡œ ê°™ì´ ìˆëŠ” ê²½ìš° ë§ˆìŠ¤í‚¹

```python
import os
import numpy as np
import pandas as pd
import cv2
import matplotlib.pyplot as plt
import pylab
%matplotlib inline

 
building_imgs_path = '/content/drive/MyDrive/LV2_dataset/LV2_validation_set/images'
building_labels_path = '/content/drive/MyDrive/LV2_dataset/LV2_validation_set/labels/building'

road_imgs_path = '/content/drive/MyDrive/LV2_dataset/LV2_validation_set/images'
road_labels_path = '/content/drive/MyDrive/LV2_dataset/LV2_validation_set/labels/road'

save_dir = '/content/drive/MyDrive/SIA/labels'  # ë§ˆìŠ¤í‚¹ ì´ë¯¸ì§€ë¥¼ ì €ì¥í•  ìœ„ì¹˜

building_label_list = os.listdir(building_labels_path)

def list_chunk(lst, n):
    return [lst[i:i+n] for i in range(0, len(lst), n)]

for building_label in building_label_list:
    # json íŒŒì¼ì¸ì§€ ì²´í¬
    if building_label.split('.')[1] != 'json':
        continue

    building_img = os.path.join(building_imgs_path, building_label.split('.')[0] + '.png')
    if os.path.isfile(building_img):  # ì´ë¯¸ì§€ íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        image_array = cv2.imread(building_img)
        zero_mask = np.zeros(image_array.shape[0:3])
        masked_image = zero_mask

        cur_build_json = pd.read_json(building_labels_path + "/" + building_label)

        for feature in cur_build_json['features']:
            building_imcoords = feature['properties']['building_imcoords']

            if len(building_imcoords) == 0:  # ì¢Œí‘œ ì •ë³´ê°€ ì—†ì„ ê²½ìš° ë‹¤ìŒ ì¢Œí‘œ ì •ë³´ í™•ì¸
                continue

            building_imcoords_list = building_imcoords.split(',')
            building_imcoords_list = list_chunk(building_imcoords_list, 2)

            polygon = np.array(building_imcoords_list)
            polygon = np.array(polygon, np.float32)
            polygon = np.array(polygon, np.int32)
            cv2.fillPoly(masked_image, np.int32([polygon]), [0, 128, 128])

        road_json = os.path.join(road_labels_path, building_label)
        if os.path.isfile(road_json):  # ë„ë¡œ json íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
            cur_road_json = pd.read_json(road_json)

            for feature in cur_road_json['features']:
                road_imcoords = feature['properties']['road_imcoords']

                if len(road_imcoords) == 0:  # ì¢Œí‘œ ì •ë³´ê°€ ì—†ì„ ê²½ìš° ë‹¤ìŒ ì¢Œí‘œ í™•ì¸
                    continue
                
                road_imcoords_list = road_imcoords.split(',')
                road_imcoords_list = list_chunk(road_imcoords_list, 2)

                polygon = np.array(road_imcoords_list)
                polygon = np.array(polygon, np.float32)
                polygon = np.array(polygon, np.int32)
                cv2.fillPoly(masked_image, np.int32([polygon]), [128, 64, 128])

        print('current file: {}'.format(building_label))
        plt.imshow(masked_image)
        plt.show()

        save_path = os.path.join(save_dir, building_label.split('.')[0] + '.png')
        result = cv2.imwrite(save_path, masked_image)

        if result == True:
            print('File saved successfully\n')
        else:
            print('{} file: Error in saving file\n'.format(save_path))
```

ë„ë¡œë§Œ ìˆëŠ” ê²½ìš° ë§ˆìŠ¤í‚¹

```python
road_label_list = os.listdir(road_labels_path)

for road_label in road_label_list:
    # json íŒŒì¼ì¸ì§€ í™•ì¸
    if road_label.split('.')[1] != 'json':
        continue

    road_img = os.path.join(road_imgs_path, road_label.split('.')[0] + '.png')
    existBuildJson = os.path.join(building_labels_path, road_label)
    if os.path.isfile(road_img) and not os.path.isfile(existBuildJson): # road ì´ë¯¸ì§€ê°€ ìˆëŠ”ì§€ í™•ì¸ & building json íŒŒì¼ì´ ì—†ëŠ”ì§€ í™•ì¸
        image_array = cv2.imread(road_img)
        zero_mask = np.zeros(image_array.shape[0:3])
        masked_image = zero_mask

        cur_road_json = pd.read_json(road_labels_path + "/" + road_label)

        for feature in cur_road_json['features']:
            road_imcoords = feature['properties']['road_imcoords']

            if len(road_imcoords) == 0:  # ì¢Œí‘œ ì •ë³´ê°€ ì—†ì„ ê²½ìš° ë‹¤ìŒ ì¢Œí‘œ ì •ë³´ í™•ì¸
                continue

            road_imcoords_list = road_imcoords.split(',')
            road_imcoords_list = list_chunk(road_imcoords_list, 2)

            polygon = np.array(road_imcoords_list)
            polygon = np.array(polygon, np.float32)
            polygon = np.array(polygon, np.int32)
            cv2.fillPoly(masked_image, np.int32([polygon]), [128, 64, 128])

        print('current file: {}'.format(road_label))
        plt.imshow(masked_image)
        plt.show()

        save_path = os.path.join(save_dir, road_label.split('.')[0] + '.png')
        result = cv2.imwrite(save_path, masked_image)

        if result == True:
            print('File saved successfully\n')
        else:
            print('{} file: Error in saving file\n'.format(save_path))
```

ì²˜ìŒ ì œê³µë°›ì€ ë°ì´í„° ì„¸íŠ¸ëŠ” ë§ˆìŠ¤í‚¹ ì •ë³´ê°€ ê±´ë¬¼ë§Œ ìˆëŠ” ê²ƒ, ë„ë¡œë§Œ ìˆëŠ” ê²ƒ, ê±´ë¬¼+ë„ë¡œë§Œ ìˆëŠ” ê²ƒ ì´ë ‡ê²Œ ì„¸ê°€ì§€ë¼

ë¨¼ì € ê±´ë¬¼ ë””ë ‰í† ë¦¬ì— ìˆëŠ” ì´ë¯¸ì§€ë¥¼ ì½ì–´ ê±´ë¬¼ json íŒŒì¼ë¡œ ë§ˆìŠ¤í‚¹ í•œ ë‹¤ìŒ, í•´ë‹¹ ì´ë¯¸ì§€ì˜ ë„ë¡œ json íŒŒì¼ë„ ìˆëŠ”ì§€ í™•ì¸í•œ ë‹¤ìŒ ìˆìœ¼ë©´ ë§ˆìŠ¤í‚¹ì„ í•´ì£¼ì—ˆìŠµë‹ˆë‹¤.

ì´ë ‡ê²Œ í•˜ë©´, json íŒŒì¼ì´ ê±´ë¬¼ë§Œ ìˆê±°ë‚˜ ê±´ë¬¼ê³¼ ë„ë¡œ ëª¨ë‘ ìˆëŠ” ê²½ìš°ëŠ” ë§ˆìŠ¤í‚¹ ë˜ë¯€ë¡œ ì•„ë˜ ì½”ë“œë¥¼ í†µí•´ ë„ë¡œ json íŒŒì¼ë§Œ ìˆëŠ” ê²½ìš°ë„ ë§ˆìŠ¤í‚¹ í•´ì£¼ì—ˆìŠµë‹ˆë‹¤.

**âœ“ fillpoly í•¨ìˆ˜ëŠ” RGBê°€ ì•„ë‹Œ BGR ìˆœì„œë¡œ ì…ë ¥ë°›ê¸° ë•Œë¬¸ì— ìƒ‰ê¹” ì§€ì •ì‹œ ìœ ì˜í•´ì•¼ í•©ë‹ˆë‹¤.**

<br>

ë³€í™˜ ì½”ë“œëŠ” [Semantic Segmentation of Aerial Images](https://www.kaggle.com/alexalex02/semantic-segmentation-of-aerial-images)ì„ ì°¸ì¡°í–ˆìŠµë‹ˆë‹¤.

ê·¸ëŸ° ë‹¤ìŒ, ë§ˆìŠ¤í‚¹ ìƒ‰ê¹”ì„ 1, 2ë¡œ ë§µí•‘ì‹œì¼œì£¼ì—ˆìŠµë‹ˆë‹¤.

**mask2class.py**

```python
clr_tab = {}
clr_tab['Clutter'] = [0, 0, 0]
clr_tab['Building'] = [128, 128, 0]
clr_tab['Road'] = [128, 64, 128]

def clr2id(clr):
    return clr[0]+clr[1]*255+clr[2]*255*255
  
id_tab = {}
for k, v in clr_tab.items():
    id_tab[k] = clr2id(v)

print(id_tab)
```

ì´ë•ŒëŠ” RGB ìˆœì„œë¡œ ì…ë ¥í•´ì£¼ë©´ ë©ë‹ˆë‹¤.

```python
masking_path = '/content/drive/MyDrive/SIA/labels'
save_path = '/content/drive/MyDrive/SIA/maskings'

mask_file_list = os.listdir(masking_path)

for mask_file in mask_file_list:
    cur_file = os.path.join(masking_path, mask_file)
    gt = np.array(Image.open(cur_file))
    trainId = transform(gt, dtype=np.uint8)

    save_file_path = os.path.join(save_path, mask_file)
    print(save_file_path)
    print(np.unique(trainId))
    print('\n')
    Image.fromarray(trainId).save(save_file_path)
```

<img width="548" alt="ìŠ¤í¬ë¦°ìƒ· 2021-12-14 ì˜¤ì „ 9 51 35" src="https://user-images.githubusercontent.com/76269316/145912620-7c0faab7-e82b-43de-94ef-fc64f92cdb7e.png">

ì´ë ‡ê²Œ í˜„ì¬ ì´ë¯¸ì§€ì— ì–´ë–¤ ê°’ë“¤ë¡œ ì±„ì›Œì ¸ ìˆëŠ”ì§€ ì¶œë ¥ë˜ë©´ì„œ ë³€í™˜ë˜ê²Œ ë©ë‹ˆë‹¤.

<br><br>

### 2. Initial Setting

[MMSegmentation Tutorial](https://colab.research.google.com/github/open-mmlab/mmsegmentation/blob/master/demo/MMSegmentation_Tutorial.ipynb), [DLCV_New/mask_rcnn](https://github.com/chulminkw/DLCV_New/tree/main/mask_rcnn)ì„ ì°¸ê³ í–ˆìŠµë‹ˆë‹¤.

**1. git clone**

ë¨¼ì € MMSegmentation githubë¥¼ git clone í•´ì¤ë‹ˆë‹¤.

```shell
!pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu111/torch1.10.0/index.html
!git clone https://github.com/open-mmlab/mmsegmentation.git
```

**âœ“ ì´ ì´í›„ë¶€í„° ë””ë ‰í† ë¦¬ë“¤ì„ ì´ë™í•˜ë©´ì„œ importí•˜ë‹ˆê¹Œ cd ëª…ë ¹ì–´ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.**

<br>

```python
import torch

print(f"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})")
```

<br>

torchë¥¼ import í•´ì¤€ë’¤ mmsegmentation ë””ë ‰í† ë¦¬ë¡œ ì´ë™í•©ë‹ˆë‹¤.

```shell
%cd mmsegmentation
```

<br>

ì´í›„ ëª¨ë‘ import í•´ì¤ë‹ˆë‹¤.

```python
from mmseg.apis import inference_segmentor, init_segmentor, show_result_pyplot
import mmcv
```

```python
import os.path as osp
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
```

<br>

[MMSegmentation github](https://github.com/open-mmlab/mmsegmentation)ì— ë“¤ì–´ê°€ë©´ ë‹¤ìŒê³¼ ê°™ì´ ì§€ì›ë˜ëŠ” ëª¨ë¸ë“¤ì´ ì •ë¦¬ë¼ ìˆìŠµë‹ˆë‹¤.

<img width="336" alt="ìŠ¤í¬ë¦°ìƒ· 2021-12-14 ì˜¤í›„ 12 01 35" src="https://user-images.githubusercontent.com/76269316/145925367-c00f8c7d-6208-400c-b017-879722637440.png">

ì´ ì¤‘ ì‚¬ìš©í•˜ê³ ì í•˜ëŠ” ëª¨ë¸ì„ í´ë¦­í•´ì„œ ë“¤ì–´ê°€ë©´ ë‹¤ìŒê³¼ ê°™ì´ pretrain ë°ì´í„° ì„¸íŠ¸ë³„ë¡œ ëª¨ë¸ê³¼ configuration íŒŒì¼ë“¤ì„ ë‹¤ìš´ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

<img width="1028" alt="ìŠ¤í¬ë¦°ìƒ· 2021-12-14 ì˜¤í›„ 12 03 43" src="https://user-images.githubusercontent.com/76269316/145925609-2054e7f4-5543-4354-b370-3d9570e400e6.png">

<br>

checkpoints ë””ë ‰í† ë¦¬ë¥¼ ë§Œë“¤ê³  í•´ë‹¹ ë””ë ‰í† ë¦¬ì— ì‚¬ìš©í•  ëª¨ë¸ íŒŒì¼ì„ ë‹¤ìš´ë°›ìŠµë‹ˆë‹¤.

<img width="296" alt="ìŠ¤í¬ë¦°ìƒ· 2021-12-14 ì˜¤í›„ 1 55 15" src="https://user-images.githubusercontent.com/76269316/145935540-c3c1b953-31e0-49e9-a054-cc7edc53fc64.png">

ì‚¬ìš©í•  ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë§í¬ëŠ” ë§ˆìš°ìŠ¤ ìš°í´ë¦­ìœ¼ë¡œ ë§í¬ ë³µì‚¬í•´ì„œ ë¶™ì—¬ë„£ìœ¼ë©´ ë©ë‹ˆë‹¤.

```shell
!mkdir checkpoints
!wget -O //content/mmsegmentation/checkpoints/fpn_r101_512x1024_80k_cityscapes_20200717_012416-c5800d4c.pth https://download.openmmlab.com/mmsegmentation/v0.5/sem_fpn/fpn_r101_512x1024_80k_cityscapes/fpn_r101_512x1024_80k_cityscapes_20200717_012416-c5800d4c.pth
```

<br>

ê·¸ëŸ° ë‹¤ìŒ configuration íŒŒì¼ê³¼ ë‹¤ìš´ë°›ì€ ëª¨ë¸ íŒŒì¼ì˜ ê²½ë¡œë¥¼ ê°ê°ì˜ ë³€ìˆ˜ì— ì§€ì •í•´ì£¼ë©´ ë©ë‹ˆë‹¤.

```python
# config íŒŒì¼ì„ ì„¤ì •í•˜ê³ , ë‹¤ìš´ë¡œë“œ ë°›ì€ pretrained ëª¨ë¸ì„ checkpointë¡œ ì„¤ì •. 
config_file = '/content/mmsegmentation/configs/sem_fpn/fpn_r101_512x1024_80k_cityscapes.py'
checkpoint_file = '/content/mmsegmentation/checkpoints/fpn_r101_512x1024_80k_cityscapes_20200717_012416-c5800d4c.pth'
```

+config íŒŒì¼ì€ mmsegmentation ë””ë ‰í† ë¦¬ì˜ configs ë””ë ‰í† ë¦¬ì—ì„œ ëª¨ë¸ì— ë§ëŠ” íŒŒì¼ì„ ì°¾ì•„ì„œ ì‚¬ìš©í•˜ë©´ ë©ë‹ˆë‹¤.

configuration íŒŒì¼ì„ ì¼ë¶€ ìˆ˜ì •í•´ì•¼í•˜ëŠ”ë° ì•„ë˜ì—ì„œ ìì„¸íˆ ì„¤ëª…í•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.

<br><br>

### 3. Data Structure

MMSegmentationì´ë‚˜ MMDetectionì„ ì´ìš©í•˜ë ¤ë©´ ì§€ì›í•˜ëŠ” ë°ì´í„° í¬ë§·ì„ ë§ì¶°ì¤˜ì•¼ í•©ë‹ˆë‹¤.

[Custom Dataset](https://mmsegmentation.readthedocs.io/en/latest/tutorials/customize_datasets.html) ê³µì‹ ë¬¸ì„œê°€ ìˆê¸´í•œë° ê·¸ë ‡ê²Œ ì¹œì ˆí•˜ì§„ ì•Šì€ ê²ƒ ê°™ìŠµë‹ˆë‹¤ ğŸ˜…

íŠœí† ë¦¬ì–¼ì´ ì½”ë“œë¡œ ë¼ ìˆì–´ì„œ ë„ì›€ì´ ë” ë§ì´ ëìŠµë‹ˆë‹¤.

<br>

ë°ì´í„° ì„¸íŠ¸ êµ¬ì¡°ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ë¼ ìˆìŠµë‹ˆë‹¤.

```
SIA
 | 
 ã…¡ã…¡ images: train/validationì—ì„œ ì‚¬ìš©í•˜ëŠ” ëª¨ë“  ì´ë¯¸ì§€
 |
 ã…¡ã…¡ labels: ground truth (ê°ê°ì˜ ì¹´í…Œê³ ë¦¬ ê°’ìœ¼ë¡œ ë§ˆìŠ¤í‚¹ëœ ì´ë¯¸ì§€) 
 |
 ã…¡ã…¡ splits
          |
          ã…¡ã…¡ train.txt: trainingì— ì‚¬ìš©í•  ì´ë¯¸ì§€ëª…
          |
          ã…¡ã…¡ val.txt: validationì— ì‚¬ìš©í•  ì´ë¯¸ì§€ëª…
```

imagesì—ëŠ” train/validationì— ì‚¬ìš©í•  ì›ë³¸ ì´ë¯¸ì§€ë“¤(png)ì´ ë“¤ì–´ê°€ ìˆê³ ,

<img src="https://user-images.githubusercontent.com/76269316/145778196-6bfb9809-9a6b-4a2d-b2d9-1c5aad222bed.png" alt="BLD01552_PS3_K3A_NIA0373" style="zoom: 50%;" />

â–²imagesì— ë“¤ì–´ìˆëŠ” ì´ë¯¸ì§€

labelsì—ì„œëŠ” train/validation ì´ë¦„ê³¼ ë™ì¼í•˜ì§€ë§Œ gray scaleë¡œ ë§ˆìŠ¤í‚¹ëœ ì´ë¯¸ì§€ë“¤(png)ì´ ë“¤ì–´ìˆìŠµë‹ˆë‹¤.

<img src="https://user-images.githubusercontent.com/76269316/145782846-feb620c9-ddd4-404b-862e-ab96785be6df.png" alt="BLD01552_PS3_K3A_NIA0373 (1)" style="zoom:50%;" />

â–²labelsì— ë“¤ì–´ìˆëŠ” ì´ë¯¸ì§€

<br>

train.txtì™€ valid.txtì—ëŠ” ë‹¤ìŒê³¼ ê°™ì´ í™•ì¥ìë¥¼ ì œì™¸í•œ ì´ë¯¸ì§€ëª…ì´ ë“¤ì–´ìˆìŠµë‹ˆë‹¤.

<img width="794" alt="ìŠ¤í¬ë¦°ìƒ· 2021-12-14 ì˜¤ì „ 10 20 08" src="https://user-images.githubusercontent.com/76269316/145915091-9bf599e1-3ae7-4144-957a-8bb892f160f9.png">

<br>

### 4. Custom Dataset

Custom Dataset í¬ë§·ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´ì„  ë‹¤ìŒê³¼ ê°™ì´ CustomDataset í´ë˜ìŠ¤ë¥¼ ìƒì†ë°›ì•„ í´ë˜ìŠ¤ë¥¼ ë§Œë“¤ì–´ì•¼ í•©ë‹ˆë‹¤.

```python
from mmseg.datasets.builder import DATASETS
from mmseg.datasets.custom import CustomDataset

classes = ('background', 'building', 'road')
palette = [[0, 0, 0], [128, 128, 0], [128, 64, 128]]

@DATASETS.register_module()
class SIADataset(CustomDataset):
  CLASSES = classes
  PALETTE = palette
  def __init__(self, split, **kwargs):
    super().__init__(img_suffix='.png', seg_map_suffix='.png', 
                     split=split, **kwargs)
    assert osp.exists(self.img_dir) and self.split is not None
```

paletteì˜ ê²½ìš° ë‚˜ì¤‘ì— predict í•  ë•Œ ëª¨ë¸ì—ì„œ ì‚¬ìš©í•  ìƒ‰ì¸ë°, ë§ˆìŠ¤í‚¹í•  ë•Œì™€ ë™ì¼í•œ RGB ê°’ì„ ì£¼ì—ˆìŠµë‹ˆë‹¤.

<br>

### 5. Configuration File

MMSegmentationì€ ëª¨ë¸ê³¼ ê·¸ ëª¨ë¸ì˜ í™˜ê²½ì„¤ì •(configuration) íŒŒì¼ì´ ì¡´ì¬í•©ë‹ˆë‹¤.

MMSegmentationì˜ ê°€ì¥ í° ì¥ì ì€ ì´ í™˜ê²½ì„¤ì • íŒŒì¼ì„ ìˆ˜ì •í•˜ëŠ” ê²ƒë§Œìœ¼ë¡œ ë°±ë³¸(Backbone) ë³€ê²½, ë°ì´í„° ì¦ëŒ€(data augmentation), ëŸ°íƒ€ì„ ì„¸íŒ…(iterationì„ ì–¼ë§ˆë‚˜ í•  ê²ƒì¸ì§€, learning rateëŠ” ëª‡ìœ¼ë¡œ í•  ê²ƒì¸ì§€ ë“±ì„ ì„¤ì •)ì„ í•  ìˆ˜ ìˆë‹¤ëŠ” ì ì…ë‹ˆë‹¤.

configuration íŒŒì¼ì˜ êµ¬ì„±ì€ ëª¨ë¸ì´ ë‹¬ë¼ì ¸ë„ ë¹„ìŠ·í•˜ê¸° ë•Œë¬¸ì— ì†ì‰½ê²Œ ë‹¤ë¥¸ ëª¨ë¸ë“¤ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (**ì´ê²Œ ì •ë§ í° ì¥ì ì…ë‹ˆë‹¤**)

<br>

ë¨¼ì € configuration íŒŒì¼ì„ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.

```python
# config íŒŒì¼ì„ ì„¤ì •í•˜ê³ , ë‹¤ìš´ë¡œë“œ ë°›ì€ pretrained ëª¨ë¸ì„ checkpointë¡œ ì„¤ì •. 
config_file = '/content/mmsegmentation/configs/sem_fpn/fpn_r101_512x1024_80k_cityscapes.py'
checkpoint_file = '/content/mmsegmentation/checkpoints/fpn_r101_512x1024_80k_cityscapes_20200717_012416-c5800d4c.pth'

from mmcv import Config

cfg = Config.fromfile(config_file)
print(cfg.pretty_text)
```

<br>

```python
norm_cfg = dict(type='SyncBN', requires_grad=True)
model = dict(
    type='EncoderDecoder',
    pretrained='open-mmlab://resnet101_v1c',
    backbone=dict(
        type='ResNetV1c',
        depth=101,
        num_stages=4,
        out_indices=(0, 1, 2, 3),
        dilations=(1, 1, 1, 1),
        strides=(1, 2, 2, 2),
        norm_cfg=dict(type='SyncBN', requires_grad=True),
        norm_eval=False,
        style='pytorch',
        contract_dilation=True),
    neck=dict(
        type='FPN',
        in_channels=[256, 512, 1024, 2048],
        out_channels=256,
        num_outs=4),
    decode_head=dict(
        type='FPNHead',
        in_channels=[256, 256, 256, 256],
        in_index=[0, 1, 2, 3],
        feature_strides=[4, 8, 16, 32],
        channels=128,
        dropout_ratio=0.1,
        num_classes=19,
        norm_cfg=dict(type='SyncBN', requires_grad=True),
        align_corners=False,
        loss_decode=dict(
            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),
    train_cfg=dict(),
    test_cfg=dict(mode='whole'))
dataset_type = 'CityscapesDataset'
data_root = 'data/cityscapes/'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
crop_size = (512, 1024)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(type='Resize', img_scale=(2048, 1024), ratio_range=(0.5, 2.0)),
    dict(type='RandomCrop', crop_size=(512, 1024), cat_max_ratio=0.75),
    dict(type='RandomFlip', prob=0.5),
    dict(type='PhotoMetricDistortion'),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size=(512, 1024), pad_val=0, seg_pad_val=255),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_semantic_seg'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(2048, 1024),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=2,
    workers_per_gpu=2,
    train=dict(
        type='CityscapesDataset',
        data_root='data/cityscapes/',
        img_dir='leftImg8bit/train',
        ann_dir='gtFine/train',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations'),
            dict(
                type='Resize', img_scale=(2048, 1024), ratio_range=(0.5, 2.0)),
            dict(type='RandomCrop', crop_size=(512, 1024), cat_max_ratio=0.75),
            dict(type='RandomFlip', prob=0.5),
            dict(type='PhotoMetricDistortion'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size=(512, 1024), pad_val=0, seg_pad_val=255),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img', 'gt_semantic_seg'])
        ]),
    val=dict(
        type='CityscapesDataset',
        data_root='data/cityscapes/',
        img_dir='leftImg8bit/val',
        ann_dir='gtFine/val',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(2048, 1024),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='CityscapesDataset',
        data_root='data/cityscapes/',
        img_dir='leftImg8bit/val',
        ann_dir='gtFine/val',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(2048, 1024),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
log_config = dict(
    interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
cudnn_benchmark = True
optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0005)
optimizer_config = dict()
lr_config = dict(policy='poly', power=0.9, min_lr=0.0001, by_epoch=False)
runner = dict(type='IterBasedRunner', max_iters=80000)
checkpoint_config = dict(by_epoch=False, interval=8000)
evaluation = dict(interval=8000, metric='mIoU', pre_eval=True)
```

configuration íŒŒì¼ì€ íŒŒì´ì¬ íŒŒì¼ë¡œ, dictionary í˜•íƒœë¡œ ì¡´ì¬í•©ë‹ˆë‹¤.

<br>

ì´ ë¶€ë¶„ì€ ëª¨ë¸ ë¶€ë¶„ìœ¼ë¡œ backbone, neck, headë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.

```python
model = dict(
    type='EncoderDecoder',
    pretrained='open-mmlab://resnet101_v1c',
    backbone=dict(
        type='ResNetV1c',
        depth=101,
        num_stages=4,
        out_indices=(0, 1, 2, 3),
        dilations=(1, 1, 1, 1),
        strides=(1, 2, 2, 2),
        norm_cfg=dict(type='SyncBN', requires_grad=True),
        norm_eval=False,
        style='pytorch',
        contract_dilation=True),
    neck=dict(
        type='FPN',
        in_channels=[256, 512, 1024, 2048],
        out_channels=256,
        num_outs=4),
    decode_head=dict(
        type='FPNHead',
        in_channels=[256, 256, 256, 256],
        in_index=[0, 1, 2, 3],
        feature_strides=[4, 8, 16, 32],
        channels=128,
        dropout_ratio=0.1,
        num_classes=19,
        norm_cfg=dict(type='SyncBN', requires_grad=True),
        align_corners=False,
        loss_decode=dict(
            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),
    train_cfg=dict(),
    test_cfg=dict(mode='whole'))
```

ìš°ì„  ì—¬ê¸°ì„œ ìˆ˜ì •í•´ì¤˜ì•¼ í•  ë¶€ë¶„ì€ **norm_cfg** ì…ë‹ˆë‹¤. (Multi GPUë¥¼ ì‚¬ìš©í•˜ì‹  ë¶„ë“¤ì€ ìˆ˜ì •í•˜ì§€ ì•Šì•„ë„ ë©ë‹ˆë‹¤)

ëª¨ë¸ ìƒì„±ì‹œ Multi GPUë¥¼ ì‚¬ìš©í–ˆê¸° ë•Œë¬¸ì— ëª¨ë‘ **type='SyncBN'**ìœ¼ë¡œ ë¼ ìˆëŠ”ë°, ì €ì²˜ëŸ¼ colabì„ ì‚¬ìš©í•˜ì‹œê±°ë‚˜ ë¡œì»¬ë¡œ single GPUë¥¼ ì‚¬ìš©í•˜ì‹œëŠ” ë¶„ë“¤ì€ ë‹¤ìŒê³¼ ê°™ì´ **type='BN'**ìœ¼ë¡œ ë³€ê²½í•´ì•¼ í•©ë‹ˆë‹¤.

ë˜í•œ decode_headì˜ num_classesê°€ 19ë¡œ ë¼ ìˆëŠ”ë°, ì €í¬ëŠ” 3ê°œ(ë°°ê²½, ê±´ë¬¼, ë„ë¡œ)ì´ê¸° ë•Œë¬¸ì— 3ìœ¼ë¡œ ë³€ê²½í•´ì¤ë‹ˆë‹¤.

**âœ“ í˜„ì¬ configuration íŒŒì¼ì—ëŠ” auxiliary_headê°€ ì—†ëŠ”ë° ë§Œì•½ ì‚¬ìš©í•˜ë ¤ëŠ” ëª¨ë¸ì˜ configuration íŒŒì¼ì— auxiliary_headê°€ ìˆë‹¤ë©´, ë§ˆì°¬ê°€ì§€ë¡œ num_classesë¥¼ ë³€ê²½í•´ì¤˜ì•¼ í•©ë‹ˆë‹¤.**

<br>

Training, Validation pipelineì„ êµ¬ì„±í•˜ëŠ” ë¶€ë¶„ì…ë‹ˆë‹¤.

ì´ ë¶€ë¶„ì„ ìˆ˜ì •í•¨ìœ¼ë¡œì¨ ë‹¤ì–‘í•œ augmentationì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**ì°¸ê³ í• ë§Œí•œ ë¬¸ì„œ**

- [Customize Data Pipelines](https://mmsegmentation.readthedocs.io/en/latest/tutorials/data_pipeline.html)
- [Image Data Augmentation Overview](https://hoya012.github.io/blog/Image-Data-Augmentation-Overview/)

```python
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
crop_size = (512, 1024)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(type='Resize', img_scale=(2048, 1024), ratio_range=(0.5, 2.0)),
    dict(type='RandomCrop', crop_size=(512, 1024), cat_max_ratio=0.75),
    dict(type='RandomFlip', prob=0.5),
    dict(type='PhotoMetricDistortion'),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size=(512, 1024), pad_val=0, seg_pad_val=255),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_semantic_seg'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(2048, 1024),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
```

ì£¼ì–´ì§„ ë°ì´í„° ì„¸íŠ¸ëŠ” ëª¨ë‘ 1024x1024 í¬ê¸°ë¥¼ ê°–ê³  ìˆê¸° ë•Œë¬¸ì— dict(type='Resize', img_scale=(2048, 1024), ratio_range=(0.5, 2.0)) ì´ ë¶€ë¶„ì—ì„œ img_scaleë§Œ (1024, 1024)ë¡œ ë³€ê²½í•´ì£¼ì—ˆìŠµë‹ˆë‹¤.

+ë°ì´í„° ì¦ëŒ€ë¥¼ ì‚¬ìš©í•˜ê³  ì‹¶ì§€ ì•Šì€ ê²½ìš° ì£¼ì„ì²˜ë¦¬í•˜ê±°ë‚˜ ì§€ì›Œì„œ ì‚¬ìš©í•˜ì§€ ì•Šì„ ìˆ˜ ìˆë‹¤ëŠ”ë°, resizeë§Œ ë‚¨ê¸°ê³  ì£¼ì„ì²˜ë¦¬ í•˜ë‹ˆ ì—ëŸ¬ê°€ ë°œìƒí•´ Resize, RandomCropë§Œ ì‚¬ìš©í•˜ê³  ì§„í–‰í–ˆìŠµë‹ˆë‹¤.

ë°©ë²•ì„ ì•„ì‹œëŠ” ë¶„ì´ ê³„ì‹œë‹¤ë©´ ëŒ“ê¸€ ë‚¨ê²¨ì£¼ì„¸ìš” ğŸ˜¥

[How to remove augmentation pipelines in the train_pipeline and val_pipeline? #1026](https://github.com/open-mmlab/mmsegmentation/issues/1026)

<br>

ë°ì´í„° ì„¸íŠ¸ ì„¤ì • ë¶€ë¶„ì¸ë°, dataset_typeì„ ìœ„ì—ì„œ CustomDataset í´ë˜ìŠ¤ë¥¼ ìƒì†í•´ ë§Œë“  SIADatasetë¡œ ë³€ê²½í•´ì¤¬ê³ , ì´ì™¸ì— ê²½ë¡œ ì„¤ì • ë¶€ë¶„ì„ ë³€ê²½í•´ì¤¬ëŠ”ë° ì•„ë˜ configuration setting ë¶€ë¶„ì—ì„œ ì„¤ëª…í•˜ê² ìŠµë‹ˆë‹¤.

ê·¸ë¦¬ê³  samples_per_gpu, workers_per_gpuê°€ batch sizeë¥¼ ì§€ì •í•˜ëŠ” ë³€ìˆ˜ì¸ë°, ëª¨ë‘ 8ë¡œ ë³€ê²½í–ˆìŠµë‹ˆë‹¤.

```python
dataset_type = 'CityscapesDataset'
data_root = 'data/cityscapes/'

data = dict(
    samples_per_gpu=2,  #batch size
    workers_per_gpu=2,  
    train=dict(
        type='CityscapesDataset',
        data_root='data/cityscapes/',
        img_dir='leftImg8bit/train',
        ann_dir='gtFine/train',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations'),
            dict(
                type='Resize', img_scale=(2048, 1024), ratio_range=(0.5, 2.0)),
            dict(type='RandomCrop', crop_size=(512, 1024), cat_max_ratio=0.75),
            dict(type='RandomFlip', prob=0.5),
            dict(type='PhotoMetricDistortion'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size=(512, 1024), pad_val=0, seg_pad_val=255),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img', 'gt_semantic_seg'])
        ]),
    val=dict(
        type='CityscapesDataset',
        data_root='data/cityscapes/',
        img_dir='leftImg8bit/val',
        ann_dir='gtFine/val',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(2048, 1024),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='CityscapesDataset',
        data_root='data/cityscapes/',
        img_dir='leftImg8bit/val',
        ann_dir='gtFine/val',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(2048, 1024),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
```

<br><br>

### 6. Configuration Setting

ë¨¼ì € ëª¨ë¸ ë¶€ë¶„ì˜ norm_cfg ë¶€ë¶„ì˜ typeì„ BNìœ¼ë¡œ ë°”ê¾¸ê³ , í´ë˜ìŠ¤ ê°œìˆ˜ë¥¼ 3ê°œë¡œ ë³€ê²½í–ˆìŠµë‹ˆë‹¤.

```python
cfg.norm_cfg = dict(type='BN', requires_grad=True)
cfg.model.backbone.norm_cfg = cfg.norm_cfg
cfg.model.decode_head.norm_cfg = cfg.norm_cfg

cfg.model.decode_head.num_classes = 3
```

<br>

ì´í›„ train_pipelineê³¼ test_pipelineì˜ img_scaleë§Œ (1024, 1024)ë¡œ ë°”ê¿”ì£¼ì—ˆê³  ë‚˜ë¨¸ì§€ëŠ” ê·¸ëŒ€ë¡œ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.

*RandomFlipì´ë‚˜ PhotoMetricDistortion, Paddingì„ ì‚¬ìš©í•˜ê³  ì‹¶ì§€ ì•Šì€ ê²½ìš° ì£¼ì„ ì²˜ë¦¬í•´ë„ ë©ë‹ˆë‹¤.*

*ë‹¨ ë‚˜ë¨¸ì§€ëŠ” ê·¸ëŒ€ë¡œ ë‘ì…”ì•¼í•©ë‹ˆë‹¤.*

```python
cfg.img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
cfg.crop_size = (512, 1024)
cfg.train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(type='Resize', img_scale=(1024, 1024), ratio_range=(0.5, 2.0)),
    dict(type='RandomCrop', crop_size=cfg.crop_size, cat_max_ratio=0.75),
    dict(type='RandomFlip', flip_ratio=0.5),
    dict(type='PhotoMetricDistortion'),
    dict(type='Normalize', **cfg.img_norm_cfg),
    dict(type='Pad', size=cfg.crop_size, pad_val=0, seg_pad_val=255),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_semantic_seg']),
]

cfg.test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(1024, 1024),
        # img_ratios=[0.5, 0.75, 1.0, 1.25, 1.5, 1.75],
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(type='Normalize', **cfg.img_norm_cfg),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img']),
        ])
]
```

<br>

dataset_typeì„ ìœ„ì—ì„œ ì •ì˜í•œ SIADatasetë¥¼ ì‚¬ìš©í–ˆê³ , ê²½ë¡œë¥¼ ì§€ì •í•´ì¤¬ìŠµë‹ˆë‹¤.

```python
cfg.dataset_type = 'SIADataset'
cfg.data_root = '/content/drive/MyDrive/SIA'

cfg.data.train.type = 'SIADataset'
cfg.data.train.data_root = '/content/drive/MyDrive/SIA'
cfg.data.train.img_dir = 'images'
cfg.data.train.ann_dir = 'labels'
cfg.data.train.pipeline = cfg.train_pipeline
cfg.data.train.split = 'splits/train.txt'

cfg.data.val.type = 'SIADataset'
cfg.data.val.data_root = '/content/drive/MyDrive/SIA'
cfg.data.val.img_dir = 'images'
cfg.data.val.ann_dir = 'labels'
cfg.data.val.pipeline = cfg.test_pipeline
cfg.data.val.split = 'splits/val.txt'

cfg.data.test.type = 'SIADataset'
cfg.data.test.data_root = '/content/drive/MyDrive/SIA'
cfg.data.test.img_dir = 'images'
cfg.data.test.ann_dir = 'labels'
cfg.data.test.pipeline = cfg.test_pipeline
cfg.data.test.split = 'splits/val.txt'
```

<br>

```
SIA
 | 
 ã…¡ã…¡ images: train/validationì—ì„œ ì‚¬ìš©í•˜ëŠ” ëª¨ë“  ì´ë¯¸ì§€
 |
 ã…¡ã…¡ labels: ground truth (ê°ê°ì˜ ì¹´í…Œê³ ë¦¬ ê°’ìœ¼ë¡œ ë§ˆìŠ¤í‚¹ëœ ì´ë¯¸ì§€) 
 |
 ã…¡ã…¡ splits
          |
          ã…¡ã…¡ train.txt: trainingì— ì‚¬ìš©í•  ì´ë¯¸ì§€ëª…
          |
          ã…¡ã…¡ val.txt: validationì— ì‚¬ìš©í•  ì´ë¯¸ì§€ëª…
```

í˜„ì¬ ë°ì´í„°ëŠ” ë‹¤ìŒê³¼ ê°™ì€ êµ¬ì¡°ë¡œ êµ¬ì„±ë¼ ìˆê¸° ë•Œë¬¸ì— data_root ë¶€ë¶„ì„ **'/content/drive/MyDrive/SIA'**ë¡œ ì„¤ì •í–ˆê³ ,

ì›ë³¸ ì´ë¯¸ì§€ë“¤ì€ image ë””ë ‰í† ë¦¬ì— ìˆê¸° ë•Œë¬¸ì— img_dirë¥¼ **images**ë¡œ, gray scaleë¡œ maskingí•œ ì´ë¯¸ì§€ê°€ labels ë””ë ‰í† ë¦¬ ë°‘ì— ìˆê¸° ë•Œë¬¸ì— ann_dirë¥¼ **'labels'**ë¡œ ì„¤ì •í–ˆìŠµë‹ˆë‹¤.

ë§ˆì°¬ê°€ì§€ë¡œ, trainì— ì‚¬ìš©ë˜ëŠ” ì´ë¯¸ì§€ëª…ì€ splits ë””ë ‰í† ë¦¬ ë°‘ì˜ train.txtì— ìˆê¸° ë•Œë¬¸ì— splitì€ **'splits/train.txt'**ë¡œ ì„¤ì •í–ˆìŠµë‹ˆë‹¤.

**âœ“ ì´ ë•Œ ì ˆëŒ€ê²½ë¡œì™€ ìƒëŒ€ê²½ë¡œê°€ í˜¼ìš©ë˜ì„œ ì‚¬ìš©ë˜ê¸° ë•Œë¬¸ì— ê²½ë¡œ ì„¤ì •ì— ì£¼ì˜í•´ì•¼ í•©ë‹ˆë‹¤.** 

*img_dir, ann_dir, splitì˜ ì‹œì‘ì—ëŠ” /ê°€ ë¶™ì§€ ì•ŠìŒ*

```python
cfg.data.train.type = 'SIADataset'
cfg.data.train.data_root = '/content/drive/MyDrive/SIA'
cfg.data.train.img_dir = 'images'
cfg.data.train.ann_dir = 'labels'
cfg.data.train.pipeline = cfg.train_pipeline
cfg.data.train.split = 'splits/train.txt'
```

<br>

pipeline ë¶€ë¶„ì€ ìœ„ì—ì„œ ë§Œë“  cfg.train_pipelineê³¼ cfg.test_pipelineì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.

<br>

cfg.load_fromì€ ì‚¬ìš©í•  ëª¨ë¸ íŒŒì¼ì˜ ê²½ë¡œë¥¼ ì €ì¥í•˜ëŠ” ë³€ìˆ˜ì´ê³ , cfg.work_dirëŠ” ëª¨ë¸ í•™ìŠµì‹œ ì§€ì •í•œ iterationë§ˆë‹¤ pth íŒŒì¼ë¡œ ëª¨ë¸ íŒŒì¼ì´ ìƒì„±ë˜ê²Œ ë˜ëŠ”ë° ê·¸ íŒŒì¼ì˜ ì €ì¥ ê²½ë¡œë¥¼ ê°–ê³  ìˆëŠ” ë³€ìˆ˜ì…ë‹ˆë‹¤.

```python
cfg.load_from = '/content/mmsegmentation/checkpoints/fpn_r101_512x1024_80k_cityscapes_20200717_012416-c5800d4c.pth'

# Set up working dir to save files and logs.
cfg.work_dir = '/content/drive/MyDrive/SIA/semantic_checkpoint'
```

<br>

MMSegmentationì€ epoch ê¸°ë°˜ì´ ì•„ë‹Œ iteration ê¸°ë°˜ìœ¼ë¡œ ë™ì‘í•©ë‹ˆë‹¤.

ë³´í†µ Detectionì´ë‚˜ Segmentationì—ì„œ epochë¥¼ ê¸°ì¤€ìœ¼ë¡œ í•˜ëŠ”ë° MMSegmentationì€ ë‹¬ë¼ì„œ ì°¾ì•„ë³¸ ê²°ê³¼,

epoch ê¸°ë°˜ë³´ë‹¤ iteration ê¸°ë°˜ì´ ë” ìœ ì—°í•˜ê³  (epochëŠ” í•œ epochì´ ì™„ë£Œë  ë•Œë§Œ ì €ì¥í•  ìˆ˜ ìˆì§€ë§Œ iterationì€ ì›í•  ë•Œ ì €ì¥í•  ìˆ˜ ìˆì–´ì„œ), CSAIL semantic segmentation, torchcv ê°™ì€ í˜„ì¥ì—ì„œë„ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì— iteration ê¸°ë°˜ìœ¼ë¡œ ì„¤ê³„í–ˆë‹¤ê³  í•©ë‹ˆë‹¤.

[Why mmseg uses IterBasedRunner rather than EpochBasedRunner #76](https://github.com/open-mmlab/mmsegmentation/issues/76)

+Epoch ê¸°ë°˜ìœ¼ë¡œ ë³€ê²½í•˜ê¸° [runner type selection](https://issueexplorer.com/issue/open-mmlab/mmsegmentation/926)

```python
cfg.runner.max_iteTrs = 200
cfg.log_config.interval = 50
cfg.evaluation.interval = 1000  # ëª¨ë¸ í•™ìŠµì‹œ í‰ê°€ë¥¼ ëª‡ ë²ˆì§¸ iterationë§ˆë‹¤ í•  ê²ƒì¸ì§€ ì§€ì •
cfg.checkpoint_config.interval = 1000  # ëª¨ë¸ í•™ìŠµì‹œ í•™ìŠµí•œ ëª¨ë¸ì„ ëª‡ ë²ˆì§¸ iterationë§ˆë‹¤ ì €ì¥í•  ê²ƒì¸ì§€ ì§€ì •

cfg.runner = dict(type='IterBasedRunner', max_iters=4000)  # Iterationìœ¼ë¡œ ë™ì‘, Epochë¡œ ë™ì‘í•˜ê²Œ ë³€ê²½í•  ìˆ˜ë„ ìˆìŒ
# cfg.runner = dict(type='EpochBasedRunner', max_epochs=4000)  # Epochë¡œ ë³€ê²½
cfg.workflow = [('train', 1)]

# Set seed to facitate reproducing the result
cfg.seed = 0
set_random_seed(0, deterministic=False)
cfg.gpu_ids = range(1)

# Let's have a look at the final config used for training
print(f'Config:\n{cfg.pretty_text}')
```

ë³€ê²½í•˜ë©´ ë‹¤ìŒê³¼ ê°™ì´ ì¶œë ¥ë©ë‹ˆë‹¤.

```python
Config:
norm_cfg = dict(type='BN', requires_grad=True)
model = dict(
    type='EncoderDecoder',
    pretrained='open-mmlab://resnet101_v1c',
    backbone=dict(
        type='ResNetV1c',
        depth=101,
        num_stages=4,
        out_indices=(0, 1, 2, 3),
        dilations=(1, 1, 1, 1),
        strides=(1, 2, 2, 2),
        norm_cfg=dict(type='BN', requires_grad=True),
        norm_eval=False,
        style='pytorch',
        contract_dilation=True),
    neck=dict(
        type='FPN',
        in_channels=[256, 512, 1024, 2048],
        out_channels=256,
        num_outs=4),
    decode_head=dict(
        type='FPNHead',
        in_channels=[256, 256, 256, 256],
        in_index=[0, 1, 2, 3],
        feature_strides=[4, 8, 16, 32],
        channels=128,
        dropout_ratio=0.1,
        num_classes=3,
        norm_cfg=dict(type='BN', requires_grad=True),
        align_corners=False,
        loss_decode=dict(
            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),
    train_cfg=dict(),
    test_cfg=dict(mode='whole'))
dataset_type = 'SIADataset'
data_root = '/content/drive/MyDrive/SIA'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
crop_size = (512, 1024)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(type='Resize', img_scale=(1024, 1024), ratio_range=(0.5, 2.0)),
    dict(type='RandomCrop', crop_size=(512, 1024), cat_max_ratio=0.75),
    dict(type='RandomFlip', flip_ratio=0.5),
    dict(type='PhotoMetricDistortion'),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size=(512, 1024), pad_val=0, seg_pad_val=255),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_semantic_seg'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(1024, 1024),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=8,
    workers_per_gpu=8,
    train=dict(
        type='SIADataset',
        data_root='/content/drive/MyDrive/SIA',
        img_dir='images',
        ann_dir='labels',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations'),
            dict(
                type='Resize', img_scale=(1024, 1024), ratio_range=(0.5, 2.0)),
            dict(type='RandomCrop', crop_size=(512, 1024), cat_max_ratio=0.75),
            dict(type='RandomFlip', flip_ratio=0.5),
            dict(type='PhotoMetricDistortion'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size=(512, 1024), pad_val=0, seg_pad_val=255),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img', 'gt_semantic_seg'])
        ],
        split='splits/train.txt'),
    val=dict(
        type='SIADataset',
        data_root='/content/drive/MyDrive/SIA',
        img_dir='images',
        ann_dir='labels',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(1024, 1024),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ],
        split='splits/val.txt'),
    test=dict(
        type='SIADataset',
        data_root='/content/drive/MyDrive/SIA',
        img_dir='images',
        ann_dir='labels',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(1024, 1024),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ],
        split='splits/val.txt'))
log_config = dict(
    interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = '/content/mmsegmentation/checkpoints/fpn_r101_512x1024_80k_cityscapes_20200717_012416-c5800d4c.pth'
resume_from = None
workflow = [('train', 1)]
cudnn_benchmark = True
optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0005)
optimizer_config = dict()
lr_config = dict(policy='poly', power=0.9, min_lr=0.0001, by_epoch=False)
runner = dict(type='IterBasedRunner', max_iters=4000)
checkpoint_config = dict(by_epoch=False, interval=1000)
evaluation = dict(interval=1000, metric='mIoU', pre_eval=True)
work_dir = '/content/drive/MyDrive/SIA/semantic_checkpoint'
seed = 0
gpu_ids = range(0, 1)
```

<br><br>

### 7. Training

ì´ì œ ëª¨ë¸ í•™ìŠµì„ ì§„í–‰í•´ ë³´ê² ìŠµë‹ˆë‹¤.

```python
from mmseg.datasets import build_dataset
from mmseg.models import build_segmentor
from mmseg.apis import train_segmentor

# Build the dataset
datasets = [build_dataset(cfg.data.train)]

# Build the detector
model = build_segmentor(
    cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))

# Add an attribute for visualization convenience
model.CLASSES = datasets[0].CLASSES

# Create work_dir
mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))
train_segmentor(model, datasets, cfg, distributed=False, validate=True, 
                meta=dict(CLASSES=classes, PALETTE=palette))
```

<img width="416" alt="ìŠ¤í¬ë¦°ìƒ· 2021-12-14 ì˜¤í›„ 2 23 18" src="https://user-images.githubusercontent.com/76269316/145938167-94a28f97-b6ee-417a-95e2-67ef6d17051b.png">

ì„¤ì •í•œ iterationë§ˆë‹¤ ì´ë ‡ê²Œ ì‹¤í–‰ ê²°ê³¼ê°€ ë‚˜ì˜¤ê²Œ ë©ë‹ˆë‹¤.

<br>

### 8. Inference

ë‹¤ìŒê³¼ ê°™ì´ ì´ë¯¸ì§€ë¥¼ inference í•´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
checkpoint_file = '/content/drive/MyDrive/SIA/checkpoints/iter_28000.pth'  #í•™ìŠµëœ ëª¨ë¸

# checkpoint ì €ì¥ëœ model íŒŒì¼ì„ ì´ìš©í•˜ì—¬ ëª¨ë¸ì„ ìƒì„±, ì´ë•Œ ConfigëŠ” ìœ„ì—ì„œ updateëœ config ì‚¬ìš©. 
model_ckpt = init_segmentor(cfg, checkpoint_file, device='cuda:0')  #cuda gpu ì‚¬ìš©

img = mmcv.imread('/content/drive/MyDrive/SIA/images/BLD01552_PS3_K3A_NIA0373.png')
result = inference_segmentor(model_ckpt, img)
show_result_pyplot(model_ckpt, img, result, palette)
```

<img src="https://user-images.githubusercontent.com/76269316/145939512-3189bb3b-59b5-4947-99ee-3f685a121a7a.png" alt="image" style="zoom: 67%;" />

