---
title: "[대학원 면접] GIST 면접 질문 정리"
excerpt: "GIST 면접 질문 정리"
toc: true
toc_label: "GIST 면접 질문 정리"
toc_sticky: true

categories:
  - MS
tags:
  - 대학원
last_modified_at: 2022-07-31
---

### 딥러닝에서의 지도학습

지도학습은 기계 학습 방법 중 하나로, 데이터에 대한 명시적인 정답 (label)이 주어진 상태로 학습을 시키는 방법입니다.

딥러닝(2개 이상의 은닉층으로 이루어진 인공신경망)에서 데이터 학습 과정은 두가지 방향성을 가지는데, 먼저 입력층->은닉층->출력층을 순서대로 지나는 forward propagation을 통해 예측값을 계산한 뒤, 실제값과의 차이를 손실(Loss)로 계산합니다.

이후 출력층->은닉층->입력층을 역방향으로 계산하여 손실을 최소화 할 수 있도록 가중치를 업데이트하는 back propagation을 진행합니다.

지도학습에서는 손실 값이 최소가 되는 방향으로 forward propagation, back propagation을 반복하며 학습하게 됩니다.

<br>

### 활성화 함수를 사용하는 이유?

활성화 함수는 입력 신호의 총합을 출력 신호로 변화하는 함수로, 출력값을 활성화할 것인지 말 것인지를 결정하며, 모델의 표현력을 향상시켜주기 위해 사용합니다.

선형 함수를 활성화 함수로 사용하면, 비선형성을 표현할 수 없기 때문에 비선형 함수를 활성화 함수로 사용함으로써 모델이 비선형 데이터를 표현할 수 있게 합니다.

<br>

### 활성화 함수의 종류

- Sigmoid

![스크린샷 2022-08-01 오후 10 05 13](https://user-images.githubusercontent.com/76269316/182154327-708910a2-1908-453b-8318-b903c738ccda.png)

도함수에서 x가 0일때 최댓값 0.25를 갖고 입력값이 점점 작아지거나 커질수록 기울기가 0에 수렴하기 때문에 back propagation 연산을 할 때, 가중치가 갱신되지 않는 gradient vanishing 문제가 발생하게 된다는 단점이 있습니다.

exp 연산으로 시간이 오래 걸리며, 또한 함숫값 중심이 0이 아니고 출력값이 항상 양수이기 때문에 가중치에 대한 기울기가 항상 양수 또는 음수가 돼 학습이 잘되지 않는 zigzag 문제가 발생할 수 있습니다.

- Tanh

![스크린샷 2022-08-01 오후 10 10 50](https://user-images.githubusercontent.com/76269316/182155363-f43f56d3-a045-4c9e-b18f-528b09b89c84.png)

함숫값 중심을 0으로 옮김으로써 시그모이드가 갖고 있던 최적화 과정에서 느려지는 문제를 해결했지만, gradient vanishing 현상은 해결하지 못하였습니다.

- ReLU

<img src="https://user-images.githubusercontent.com/76269316/182155529-2e0e1538-2ad4-401a-b3e9-61e497631c89.png" alt="스크린샷 2022-08-01 오후 10 11 46" style="zoom: 67%;" />



함수값의 중심이 0이 아니라, zigzag 문제도 발생하며 0보다 작은 값에 대해서는 함수 값이 0이 되기 때문에 이후 뉴런들의 출력값이 0이되는 dying ReLU 문제가 발생하지만, sigmoid, tanh보다 수렴 속도가 빠르고(*기울기가 1로 일정하기 때문에*) 연산 비용이 적으며, 구현이 매우 간단하여 ReLU를 사용한다. (또한 sigmoid나 tanh보다 접선의 기울기가 0이 되는 부분이 적어서 사용한다.)

<br>

### ROCT

##### [Radius-based Class Overlap Cleaning Technique](https://ieeexplore.ieee.org/document/9529661)

2021 IEEE COMPSAC Wuhan University

software defect prediction 데이터셋 사용

Class Overlap Problem이 Class Imbalance Problem보다 더 큰 성능 저하의 원인인데, 많은 연구들이 COP보다 CIP 문제에 치중돼 있고, 또한 COP cleaning 테크닉들은 하이퍼 파라미터에 의존적이라는 문제가 존재 (최적의 하이퍼 파라미터를 찾는 것이 어렵기 때문)

1. 각 인스턴스를 hypersphere의 중심으로 두고, 최적의 radius를 찾음 (Differential Evolution 알고리즘 사용)
2. 해당 hypersphere 내에 있는 인스턴스 중, 중심 클래스와 반대되는 클래스는 overlap 돼 있다고 판단해 제거

<img width="464" alt="스크린샷 2022-07-30 오후 1 56 41" src="https://user-images.githubusercontent.com/76269316/181875352-1c7f2d1b-fcd7-4281-a33b-f9d7d2b2c5be.png">

<br>

##### [Differential Evolution](https://www.kgsjournal.org/articles/xml/2b7B/)

비선형, 미분 불가능한 연속공간함수를 빠르게 탐색하여 최적해(optimal minimum)를 구하기 위한 목적으로 제안

초기 개체군을 랜덤하게 생성하고 돌연변이(Mutation), 교배(Crossover), 선택(Selection) 등의 단계를 거쳐 다음 세대를 구성

지정된 세대수에 도달하거나, 새로운 개체가 최적값을 만족할 때까지 진화 연산이 반복 수행됨

scipy 메소드로 구현

<br>

**돌연변이 (Mutation)**

이전 세대의 개체 집단 <img src="https://user-images.githubusercontent.com/76269316/181875854-25a64d63-3de5-49a8-b953-380acbb14e68.png" alt="image" style="zoom: 50%;" />에서 임의의 개체 3개를 선택하여 교배용 벡터를 생성(F는 돌연변이 상수로 0~2 사이의 값을 갖는다)

<img width="255" alt="스크린샷 2022-07-30 오후 2 21 11" src="https://user-images.githubusercontent.com/76269316/181875976-661f2288-7770-411a-9a40-338249e40142.png">

<br>

**교배 (Crossover)**

시행벡터(trial vector)를 생성하기 위해 부모 개체와 돌연변이 벡터(mutant vector)가 교배됨(CR은 교배상수로 0~1 사이의 값을 가짐, <img src="https://user-images.githubusercontent.com/76269316/181876078-595cab8d-4b93-45dc-8cf0-f98f51f9d77d.png" alt="image" style="zoom:50%;" />는 [1, 2, ··· D]의 무작위 정수)

<img width="367" alt="스크린샷 2022-07-30 오후 2 22 55" src="https://user-images.githubusercontent.com/76269316/181876028-a703a8f5-35da-4caf-9dec-4411a0141f2b.png">

<br>

**선택 (Selection)**

<img width="310" alt="스크린샷 2022-07-30 오후 2 26 05" src="https://user-images.githubusercontent.com/76269316/181876126-db86e73f-5893-4871-aaf6-489d23726b9a.png">

목표벡터(target vector) <img src="https://user-images.githubusercontent.com/76269316/181876203-acb0750d-eb4c-4916-bea0-fedff425ab5a.png" alt="image" style="zoom:50%;" />와 시행벡터(trial vector) <img src="https://user-images.githubusercontent.com/76269316/181876230-344ad0c3-9c0c-4e13-9d86-6133e733e7cb.png" alt="image" style="zoom:50%;" />와 비교해 교배상수로 다음 세대를 구성할 개체를 선택함

<br><br>

### Modeling Tabular Data using Conditional GAN

Tabular data는 discrete와 continuous한 columns를 학습시킬 때, 다양한 문제가 발생

- continuous data: 확률 분포가 여러 개의 봉우리를 갖게 되는 multimodal distribution 문제
- discrete data:카테고리별 빈도수가 다른 문제 (imbalance)

➡️ tabular data를 보다 좋은 성능으로 생성할 수 있는 방법 및 데이터 생성 알고리즘의 성능을 평가할 수 있는 benchmarking 시스템 제안

<br>

Generator G가 기존 테이블 T(Nc개의 continuous columns, Nd개의 discrete columns를 갖고 있음, 각각의 컬럼은 joint distribution)를 기반으로 T sync를 생성 ➡️ 두가지 metric으로 T sync를 평가

- Likelihood fitness: T sync에 있는 columns가 Ttrain에 있는 columns의 joint distribution을 잘 따르는가?

이를 평가하기 위해 simulated data를 사용 -> 데이터셋의 실제 분포를 정확하게 알 수 있음

![스크린샷 2022-07-31 오전 9 48 35](https://user-images.githubusercontent.com/76269316/182004994-9607e383-2bf3-4921-9a9e-d89adead25c1.png)

L(sync)는 생성 모델이 overfitting될수록 잘 나오기 때문에, 이를 피하기 위해 test데이터와 synthesize 데이터 사이의 likelihood를 구한 L(test)도 사용하게 된다.

- Machine learning efficacy: Ttrain을 통해 생성된 T sync를 학습한 ML 모델의 성능과 실제 데이터인 Ttest를 통해 학습한 ML 모델의 성능은 얼마나 비슷한지?

ML efficacy를 평가하기 위해 이번에는 real data를 사용

![스크린샷 2022-07-31 오전 9 53 20](https://user-images.githubusercontent.com/76269316/182005076-3a961b82-15a2-4dd6-bd0a-fccb63482d64.png)

<br>

이러한 metric이 좋은 성능을 내기 위해서는 tabular data에의 Mixed data types(discrete & continuous columns), Non-Gaussian distributions(continuous data의 경우), Multimodal distributions(확률분포가 여러 봉우리 가짐), Learning from sparse one-hot-encoded vectors, Highly imbalanced categorical columns (mode collapse 발생) 등의 문제를 해결해야 한다.

<br>

**Mode-specific Normalization**

tabular data를 생성하기 전, normalization 과정을 거쳐야 한다. dicsrete 변수는 단순히 전체 카테고리 개수만큼 one-hot encoding을 진행한다.

continuous 변수에 속한 데이터들의 확률 분포는 여러 개의 봉우리(Gaussian Mixture)로 표현된 경우가 많은데, 이 경우 데이터를 생성하기 어렵기 때문에 normalization 과정을 거쳐야 한다.

<p align = "center">
  <img src = "https://user-images.githubusercontent.com/76269316/182003032-13ed2f9a-9907-456b-9819-47e4a617ca1d.png">
</p>
<p align = "center">
  Gaussian Mixture
</p>


▶️ 봉우리 개수만큼의 gaussian 확률 분포를 따르는 여러개의 sub distribution으로 나눠줌 (Gaussian Mixture Model인 VGM이 사용됨)

![스크린샷 2022-07-31 오전 8 09 54](https://user-images.githubusercontent.com/76269316/182003087-ab51fa45-ac36-45c8-bd83-de0a4a4c0f05.png)

sub distribution의 표준 편차, weight를 구한다.

이후 i번째 column, j번째 row에 해당하는 데이터인 C(i,j)의 확률을 계산해(가운데 그림) 가장 확률이 높게 나오는 sub distribution을 구해 이를 one-hot encoding [0, 0, 1]로 표현한다. (3번째 mode가 가장 확률이 높으므로)

또한 각 sub distribution의 평균(<img src="https://user-images.githubusercontent.com/76269316/182003595-f0252b87-791e-406d-b252-aa1b54c2f941.png" alt="스크린샷 2022-07-31 오전 8 38 03" style="zoom:50%;" />), 표준편차(<img src="https://user-images.githubusercontent.com/76269316/182003601-c0a6a4f6-c23a-4ae6-87c3-e3a154379289.png" alt="스크린샷 2022-07-31 오전 8 38 28" style="zoom:50%;" />)를 통해 scalar로 표현된 가중치 값 알파를 구한 뒤, continuous columns와 discrete columns를 concatenate함으로써 각 rows를 normalization 해준다.

![스크린샷 2022-07-31 오전 8 14 17](https://user-images.githubusercontent.com/76269316/182003183-eb604672-004b-44a8-aa8e-096ec55c9001.png)

<br>

**Conditional Generator and Training by Sampling**

discrete 변수의 경우 각 카테고리마다 빈도가 다른데, 이를 고려하지 않고 학습시킬 경우 원래 데이터의 특징이 사라지게 된다. 이를 해결하기 위해 **Training by Sampling** 개념이 도입되었다.

1. Nd개의 discrete columns 중 한 개를 랜덤으로 선택 (이를 i\*라고 표현)
2. 선택된 column(i*)에 대해 PMF(Probability Mass Function, 확률 질량 함수)를 구한다.
3. PMF를 따르는 확률 분포에 따라 값 하나를 선택한다. (이를 k\*번째 값이라고 표현)
4. conditional vector를 i\*와 k\* 값을 고려하여 생성한다.

![스크린샷 2022-07-31 오전 8 48 52](https://user-images.githubusercontent.com/76269316/182003822-4c86bb74-023d-40f9-bb11-3f896bdfedd2.png)

이렇게 taining-by-sampling 을 통해 학습을 진행할 경우, discrete column에 대하여 각 category 별로 기존 데이터의 빈도와 비슷하게 학습이된다.

<br>

**Network Structure**

- Generator

![스크린샷 2022-07-31 오전 9 35 43](https://user-images.githubusercontent.com/76269316/182004742-6fbf4c82-4bc1-4ddc-a7a7-cb1091cf75f8.png)

latent vector를 입력으로 2개의 hidden layer를 거친 뒤, 알파, 베타, d 값을 구한다.

알파값은 scalar이기 때문에 hyperbolic tangent를 activation function으로 사용했고, 베타와 d는 벡터이므로 다중 클래스에 대한 classification이 가능한 gumbel softmax를 사용했다.

학습에 사용된 loss는 Generator loss로 one-hot encoding된 벡터 m과 d 사이의 cross-entropy loss를 사용한다.

<br>

- Discriminator

![스크린샷 2022-07-31 오전 9 35 53](https://user-images.githubusercontent.com/76269316/182004745-9d0f720b-316d-4f95-b179-5863d5f751a3.png)

mode collapse(Generator가 비슷한 이미지만 계속 생성하는 것)를 막기 위해 10개의 sample이 한 번에 들어가며, 10개의 conditional vecotr도 함께 들어간다. (PacGAN 구조)

마지막 레이어에서 1개의 노드가 real 데이터라면 1, fake라면 0으로 예측 ➡️ WGAN loss가 사용되며, optimizer는 Adam이 사용됨

<br><br>

### 차원 축소 기법

- feature selection: 전체 피처 중 중요한 피처를 일부 선택하는 방법
- feature extract: 전체 피처를 적은 수의 피처로 융합하는 방법

<br>

##### [t-SNE  (t-distributed Stochastic Neighbor Embedding)](https://m.blog.naver.com/xorrms78/222112752837)

**SNE (Stochastic Neighbor Embedding)**

n차원에 분포된 이산 데이터를 k(n 이하의 정수) 차원으로 축소하며 거리 정보를 보존하되, 거리가 가까운 데이터의 정보를 우선하여 보존하기 위해 고안된 방법

cf) LLE(Locally Linear Embedding)과 비슷하나 LLE는 가까운 정도를 True, False로 규정, SNE는 연속적인 확률 분포(가우시안 분포)로서 가중치를 부여

![스크린샷 2022-07-31 오후 2 36 20](https://user-images.githubusercontent.com/76269316/182011837-ff55ebec-9517-409d-b62d-ce9341e453ea.png)

<span style="color:blue">p</span>:  원형 데이터에서 노드 i를 기준으로, 노드 j의 정보를 담을 확률 (데이터 사이의 거리가 가까울수록 e의 차수 증가)

<span style="color:red">q</span>: 축소된 차원에서 노드 i에 대한 j의 거리 정보를 담을 확률

<br><br>

### Classification

분류는 지도학습의 대표적인 태스크 중 하나로, **정답(label)이 있는 데이터를 가지고 데이터가 어떤 클래스에 속하는지를 학습한 다음 새롭게 관측된 데이터에 대한 클래스를 판별하는 것**입니다.

<br>

##### Decision Tree (결정 트리)

결정 트리는 데이터에 있는 규칙을 학습을 통해 자동으로 찾아내 트리(Tree) 기반의 분류 규칙을 만드는 알고리즘입니다.

아래 그림은 결정 트리의 구조를 간략하게 나타낸 것으로, 규칙 노드(Decision Node)로 표시된 노드는 규칙 조건이 되고, 새로운 규칙 조건마다 서브 트리(Sub Tree)가 생성됩니다.

리프 노드(Leaf Node)로 표시된 노드는 결정된 클래스 값입니다.

<img width="1512" alt="스크린샷 2022-07-14 오후 8 32 12" src="https://user-images.githubusercontent.com/76269316/178973105-34f4043f-3391-4c10-bcd6-0439d4ec5d73.png">

규칙 노드는 데이터의 특징을 나타내는 피처가 결합해 새로운 규칙 조건을 만들 때마다 생성됩니다. 하지만 많은 규칙이 있다는 건 분류를 결정하는 방식이 복잡해진다는 것이고, 이는 과적합(학습데이터를 과하게 학습하는 것)으로 이어지게 됩니다.

즉, 트리의 깊이(depth)가 깊어질수록 결정 트리의 예측 성능이 저하되게 됩니다.

따라서 가능한 한 적은 규칙 노드로 높은 예측 정확도를 가져야 하는데 이를 위해서는, 최대한 균일한 데이터 세트를 구성할 수 있도록 분할(Split)하는 것이 필요합니다.

<br>

**균일한 데이터세트란?**

<img src="https://user-images.githubusercontent.com/76269316/126084685-9a654ae8-37ed-4f7b-8a8c-06028853d29e.png" alt="image" style="zoom:67%;" />

다음과 같이 흑백으로 된 공이 있다고 할 때, 균일한 순서대로 나열하면 C -> B -> A입니다.

C는 모든 공이 검은 공이므로 가장 균일하고, B는 일부 하얀 공을 갖고 있지만 대부분은 검은 공으로 구성돼 있어 다음으로 균일도가 높습니다. A는 검은 공과 하얀 공이 비슷하게  있어 균일도가 가장 낮습니다.

<br>

결정 노드는 정보 균일도가 높은 데이터 세트를 먼저 선택할 수 있도록 규칙 조건을 만들고, 이후 나머지 데이터 세트에 대해서도 균일도가 높게 자식 데이터 세트를 쪼개는 것을 반복하면서 데이터 값을 예측합니다.

<br>

- 형태 : 동그라미, 네모, 세모

- 색깔 : 노랑, 빨강, 파랑

각각의 형태와 색깔을 갖는 레고 블록이 다음과 같이 섞여있다고 하면, 결정 트리에서 가장 첫 번째로 만들어지는 규칙 노드는 **if 색깔 == '노란색'**입니다.

색깔이 노란색인지 아닌지만 비교함으로써 모든 노란 동그라미 블록을 예측할 수 있고, 그 다음 나머지 블록에 대해 다시 균일도가 높은 조건을 찾아 분류하는 것이 가장 효율적이기 때문입니다.

<br>

##### Decision Tree 특징

|                             장점                             |                             단점                             |
| :----------------------------------------------------------: | :----------------------------------------------------------: |
| - 직관적이다.<br />- 피처의 스케일리이나 정규화 등의 사전 가공 영향도가 크지 않다. | - 모든 데이터 상황을 만족하는 완벽한 규칙을 만들려고 하게되고(그럴 수 없음에도 불구하고) 결국, 트리의 깊이가 깊어지고 트리가 복잡해져서 예측 성능이 떨어지게 됨<br />➡️ 이를 극복하기 위해 트리의 크기를 사전에 제한하는 튜닝이 필요 |

### Ensemble Learning (앙상블 학습)

앙상블 학습은 여러 개의 분류기(Classifier)를 생성해 결합함으로써 보다 정확한 최종 예측을 도출하는 기법으로 Bagging, Voting, Boosting, Stacking 등이 있습니다.

- Bagging : 모두 같은 유형(대부분 결정 트리 알고리즘)의 알고리즘 분류기 중 투표를 통해 최종 예측 결과를 결정하는 방식
- Voting : 서로 다른 알고리즘 분류기 중 투표를 통해 최종 예측 결과를 결정하는 방식

Bagging과 Voting은 투표 방식이라는 점에서 유사하지만, Bagging은 같은 종류의 모델들을 사용하고 Voting은 다른 종류의 알고리즘 모델들을  사용한다는 차이점이 있습니다.

|                           Bagging                            |                            Voting                            |
| :----------------------------------------------------------: | :----------------------------------------------------------: |
| <img width="373" alt="스크린샷 2022-07-16 오후 10 35 56" src="https://user-images.githubusercontent.com/76269316/179357218-55fa3f03-538a-4e2a-9d62-346d765313c1.png"> | <img width="376" alt="스크린샷 2022-07-16 오후 10 35 20" src="https://user-images.githubusercontent.com/76269316/179357196-2e0f2fc5-ec35-479f-8766-0f718b62cf45.png"> |

Voting과 Bagging은 학습하는 데이터 세트가 다른데,

Bagging 방식은 원본 학습 데이터를 샘플링해 추출한 다음, 개별 분류기에 할당해서 학습하는데 이렇게 개별 Classifier에게 데이터를 샘플링해서 추출하는 방식을 **Bootstrapping 분할 방식**이라고 합니다.

<img src="https://user-images.githubusercontent.com/76269316/179231715-7b50826c-c640-4c1c-8d39-b5dec152a58f.png" alt="image" style="zoom: 67%;" />

출처: [A Trip to Random Forest](https://medium.com/greyatom/a-trip-to-random-forest-5c30d8250d6a)

개별 분류기가 Bootstrapping 방식으로 샘플링된 데이터 세트로 학습한 다음 예측을 수행한 결과를 Voting을 통해 최종 예측 결과를 선정하는 방식이 Bagging Ensemble 방식입니다.

교차 검증이 데이터 세트 간에 중첩을 허용하지 않는 것과 다르게 Bagging 방식은 중첩을 허용합니다. (10,000개의 데이터를 10개의 분류기가 배깅 방식으로 나누더라도 각 1000개의 데이터 내에는 중복 데이터가 있음)

<br>

### Voting

Voting 방법에는 Hard Voting, Soft Voting 두 가지가 있는데, 하드 보팅보다는 소프트 보팅이 예측 성능이 좋아서 더 많이 사용됩니다.

- Hard Voting : 예측한 결과값들 중 다수의 분류기가 결정한 예측값을 최종 보팅 결과값으로 선정
- Soft Voting : 분류기들의 레이블 값 결정 확률을 모두 더하고 이를 평균해서 이들 중 확률이 가장 높은 레이블 값을 최종 보팅 결과값으로 선정

|                         Hard Voting                          |                         Soft Voting                          |
| :----------------------------------------------------------: | :----------------------------------------------------------: |
| <img width="613" alt="스크린샷 2022-07-16 오후 10 36 40" src="https://user-images.githubusercontent.com/76269316/179357234-cb108af4-bdb5-4c11-a6de-548b55331850.png"> | <img width="609" alt="스크린샷 2022-07-16 오후 10 39 15" src="https://user-images.githubusercontent.com/76269316/179357340-0594d382-4b0b-47d0-92e6-a121d4fd37a1.png"> |

앞서 설명한 결정 트리 알고리즘은 훈련 데이터의 정확한 예측을 위해 트리의 깊이를 깊게하면, 과적합이 발생해 실제 테스트 데이터에서 예측 성능이 떨어지게 됩니다.

하지만 앙상블 학습에서는 결정 트리 알고리즘의 단점을 수십~수천 개의 많은 분류기를 결합해 다양한 상황을 학습하게 함으로써 극복합니다.

결정 트리 알고리즘의 장점은 그대로 취하고 단점은 보완하면서 편향-분산 트레이드오프 효과를 극대화 한다는 것입니다.

<br>

##### Random Forest

랜덤 포레스트는 Bagging Ensemble 방식을 사용한 알고리즘으로 여러 개의 Decision Tree를 만들어, 각 트리에서 분류한 결과를 투표해 가장 많이 득표한 결과를 최종 분류 결과로 선택하는 알고리즘입니다.

랜덤 포레스트가 생성한 일부 트리는 overfitting 될 수 있지만, 많은 수의 트리를 생성함으로써 예측하는데 있어 과적합이 큰 영향을 미치지 못 하도록 합니다.

![스크린샷 2022-07-16 오후 11 42 44](https://user-images.githubusercontent.com/76269316/179359655-11872371-e3b3-429d-a493-a8136b0a4f6d.png)

*나무가(Tree) 여러 개 있는 모습이 숲(Forest) 같아서 이름을 이렇게 지은건가..?*

<br><br>

### Boosting

Boosting 알고리즘은 여러 개의 약한 학습기(weak learner)를 결합해, 순차적으로 학습-예측하면서 잘못 예측한 데이터에 가중치를 부여해 오류를 개선해 나가는 학습 방식입니다.

Boosting 계열의 대표적인 모델로는 AdaBoost(Adaptive boosting)와 Gradient Boost가 있습니다.

<br>

##### AdaBoost

AdaBoost에 대해서는 유튜브에 잘 정리돼 있어서 해당 링크를 참고하시면 될 것 같습니다.

- AdaBoost 정리 유튜브 👉  [AdaBoost, Clearly Explained](https://www.youtube.com/watch?v=LsK-xG1cLYA)

- 해당 유튜브 내용을 한글로 정리한 블로그 글 👉 [머신러닝 - 14. 에이다 부스트(AdaBoost)](https://bkshin.tistory.com/entry/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-14-AdaBoost)

저는 AdaBoost가 어떻게 학습을 진행하는지 대략적으로만 살펴보겠습니다.

![image](https://user-images.githubusercontent.com/76269316/126178465-10a3db0f-c8d5-4b90-8604-c08ea4e8a01f.png)

맨 왼쪽 그림과 같이 +, -로 된 피처 데이터 세트가 있다면

- Step 1은 첫 번째 약한 학습기가 분류 기준 1로 +와 -를 분류한 것입니다. 동그라미로 표시된 ⊕ 데이터는 잘못 분류된 오류 데이터입니다.
- Step 2에서는 이 오류 데이터에 대해 가중치 값을 부여합니다. 가중치가 부여된 오류 데이터 +는 다음 약한 학습기가 잘 분류할 수 있게 크기가 커졌습니다.
- Step 3는 두 번째 약한 학습기가 분류 기준 2로 +와 -를 분류했습니다. 마찬가지로 동그라미로 표시된 ⊖ 데이터는 잘못 분류된 오류 데이터입니다.
- Step 4에서 잘못 분류된 - 오류 데이터에 대해 다음 약한 학습기가 잘 분류할 수 있게 더 큰 가중치를 부여합니다. (크기가 커짐)
- Step 5에서 세 번째 약한 학습기가 분류 기준 3으로 +와 -를 분류하고 오류 데이터를 찾습니다.
- 마지막으로 맨 아래에 첫 번째, 두 번째, 세 번째 약한 학습기를 모두 결합한 예측 결과입니다. 개별 약한 학습기보다 훨씬 정확도가 높아졌음을 알 수 있습니다.

<br>

##### Gradient Boosting Algorithm

GBM(Gradient Boost Machine)은 AdaBoost와 유사하나, 가중치 업데이트를 경사 하강법(Gradient Descent)을 이용하는 것이 큰 차이점입니다.

GBM은 과적합에도 뛰어난 예측 성능을 가진 알고리즘이지만 수행 시간이 오래 걸린다는 단점이 있어, GBM에 기반한 XGBoost, LightGBM 등의 모델이 많이 사용되는 추세입니다.

<br>

**XGBoost (eXtra Gradient Boost)**

<img src="https://user-images.githubusercontent.com/76269316/179359086-9ac10a5d-f8f0-4cc4-9a48-e4d16a2e162f.png" alt="image" style="zoom:67%;" />

XGBoost는 GBM에 기반하고 있지만 GBM의 단점인 느린 수행 시간 및 과적합 규제(Regularization) 부재 등의 문제를 해결해서 매우 각광 받고 있습니다.

cf) 규제(Regularization)란? 머신러닝에서 모델이 가질 수 있는 파라미터의 값에 제약을 부여해 과적합을 방지하고 모델의 강건함을 높이는 방법론

<br>

**XGBoost의 장점**

| 항목                              | 설명                                                         |
| :-------------------------------- | :----------------------------------------------------------- |
| 뛰어난 예측 성능                  | 일반적으로 분류와 회귀 영역에서 뛰어난 예측 성능을 발휘합니다. |
| GBM 대비 빠른 수행 시간           | 일반적인 GBM은 순차적으로 weak learner가 가중치를 증감하는 방법으로 학습하기 때문에 속도가 느림<br />하지만 XGBoost는 병렬 수행 및 다양한 기능으로 GBM에 비해 빠른 수행 성능을 보장<br />일반적인 GBM에 비해 수행 시간이 빠른 것이지 다른 머신러닝 알고리즘(ex 랜덤 포레스트)보다 빠르지는 않습니다. |
| 과적합 규제<br />(Regularization) | 표준 GBM의 경우 과적합 규제 기능이 없으나 XGBoost는 자체 과적합 규제 기능으로 과적합에 좀 더 강한 내구성을 가질 수 있습니다. |
| 나무 가지치기<br />(Tree pruning) | GBM은 분할 시 부정 손실이 발생하면 분할을 더 이상 수행하지 않지만, 이런 방식도 지나치게 많은 분할을 발생시킬 수 있습니다.<br />다른 GBM과 마찬가지로 XGBoost도 max_depth 파라미터로 분할 깊이를 조정하지만, tree pruning으로 더 이상 긍정 이득이 없는 분할을 가지치기 해서 분할 수를 더 줄일 수 있습니다. |
| 자체 내장된 교차 검증             | XGBoost는 반복 수행 시마다 내부적으로 학습 데이터 세트와 평가 데이터 세트에 대한 교차 검증을 수행해 최적화된 반복 수행 횟수를 가질 수 있습니다.<br />지정된 반복 횟수가 아니라 교차 검증을 통해 평가 데이터 세트의 평가 값이 최적화되면 반복을 중간에 멈출 수 있는 조기 중단 기능이 있습니다. |
| 결손값 자체 처리                  | XGBoost는 결손값을 자체 처리할 수 있는 기능을 갖고 있습니다. |

<br>

**LightGBM**

<img src="https://user-images.githubusercontent.com/76269316/179359473-d82a934f-3a11-4d91-9efd-e7adb5e619dd.png" alt="스크린샷 2022-07-16 오후 11 38 46" style="zoom:67%;" />

대부분 트리 기반 알고리즘은 트리의 깊이를 효과적으로 줄이고, 과적합에 더욱더 강한 구조를 갖는다고 알려진 균형 트리 분할 (Level Wise) 방식을 사용합니다.

<img width="672" alt="스크린샷 2022-07-16 오후 11 18 20" src="https://user-images.githubusercontent.com/76269316/179358690-25466406-27d5-4dfc-9164-18a113a8c100.png">

LightGBM은 일반 GBM 계열 트리 분할 방법과 다르게 리프 중심 트리 분할 (Leaf Wise) 방식을 사용합니다.

<img width="1077" alt="스크린샷 2022-07-16 오후 11 19 42" src="https://user-images.githubusercontent.com/76269316/179358740-97a933e7-061a-4414-a067-b9d35915b3f8.png">

리프 중심 트리 분할 방식은 트리의 균형을 맞추지 않고, 최대 손실 값(max delta loss)을 갖는 리프 노드를 지속적으로 분할하면서 트리의 깊이가 깊어지고 비대칭적인 규칙 트리를 생성합니다.

이렇게 생성된 규칙 트리는 학습을 반복할수록 균형 트리 분할 방식보다 예측 오류 손실을 최소화 할 수 있다는 것이 LightGBM의 구현 개념입니다.

<br>

**LightGBM의 XGBoost 대비 장점**

- 더 빠른 학습, 예측 수행 시간
- 더 작은 메모리 사용량
- 카테고리형 피처의 자동 변환, 최적 변환(원-핫 인코딩등을 사용하지 않고도 카테고리형 피처를 최적으로 변환하고 이에 따른 노드 분할 수행)

LightGBM의 단점은 적은 데이터 세트(일반적으로 10,000건 이하)에 사용할 경우 과적합이 발생하기 쉽다고 합니다.

<br><br>

### Feature Importance

##### Feature Importance from Mean Decrease in Impurity

**Gini Impurity**

각 샘플이 클래스에 속할 확률을 <img src="https://user-images.githubusercontent.com/76269316/182012655-0c066314-a00e-4eb2-b3b8-b6d6ff34abfb.png" alt="image" style="zoom:67%;" />라고 할 때, 특정 노드 <img src="https://user-images.githubusercontent.com/76269316/182012692-b2dba013-89c2-475d-8e66-2622d2d58739.png" alt="image" style="zoom: 50%;" />에서 지니 불순도는 다음과 같이 표현됩니다.

![스크린샷 2022-07-31 오후 3 10 58](https://user-images.githubusercontent.com/76269316/182012729-e6e744a0-43a5-4cd5-b173-5b3f3535aec9.png)

1에서 전체 데이터 개수 중 레이블이 차지하는 개수의 비율을 제곱해서 빼주면 된다.

총 4개의 데이터에서 레이블 A가 3개, B가 1개 포함돼 있다면 다음과 같이 계산한다.

![스크린샷 2022-07-31 오후 3 16 54](https://user-images.githubusercontent.com/76269316/182012918-360e995b-12ad-4066-8a16-650552c98083.png)

<br>

**Information Gain (=Node Importance)**

![스크린샷 2022-07-31 오후 3 33 21](https://user-images.githubusercontent.com/76269316/182013364-ed05ddbc-dcd7-43ff-90bf-1c95e3888646.png)

불순도를 계산하면 정보 획득량을 다음과 같이 계산할 수 있다. (이전 단계 불순도에서 다음 단계 불순도 합을 뺌)

Information Gain = 0.5 - (0 + 0.375 + 0) = 0.125

**분할된 데이터 세트들의 불순도가 작을수록 정보 획득량은 증가한다.**

Decision Tree에서는 Information Gain을 최대화하는 피처를 기준으로 트리를 생성합니다. 어떤 노드의 노드 중요도 값이 클수록, 그 노드에서 불순도가 크게 감소함

<img width="413" alt="스크린샷 2022-07-31 오후 3 59 32" src="https://user-images.githubusercontent.com/76269316/182014125-196ab8bd-d51c-42d4-a2de-7fc51b61bd4e.png">

전체 노드의 중요도를 합한 것 대비 i번째 feature에 의해 나눠진 노드들의 중요도를 합한 것이 i번째 피처의 중요도가 됨

<br>

**불순도 기반 피처 중요도의 한계**

- 연속형 변수 또는 카테고리 개수가 많은 변수(high cardinality)들에 중요도가 편향될 가능성이 높음

*cardinality가 큰 변수일 수록, 노드를 나누는게 훨씬 더 많아서 중요도가 높게 나온듯*

▶️ 이를 확인할 수 있는 방법? 트리의 max depth를 제한하면서 비교 실험 -> max depth가 줄어들수록 자식 노드 수가 줄어들기 때문에 연속형 변수(또는 high cardinality 변수)의 영향력이 줄어듦 -> 피처 중요도가 내려감

- 불순도 기반 중요도는 훈련 과정 중에 계산되므로, 테스트 데이터셋(일반화된 데이터)에선 유용한 피처의 기능을 반영하지 않을 수 있음

<br>

##### [Permutation Importance](https://soohee410.github.io/iml_permutation_importance)

피처값을 무작위로 섞어 노이즈를 생성해 훈련한 뒤 예측 -> 예측시 정확도가 크게 감소할 경우 모델이 해당 피처에 크게 의존하고 있다는 의미

permutation importance는 partial importance가 아니기 때문에 피처 값을 랜덤하게 섞을 경우, 상호작용하고 있는 피처의 연결고리가 끊어지게 돼 두 개의 피처 중요도 각각에 중복 포함됨

![스크린샷 2022-07-31 오후 5 14 53](https://user-images.githubusercontent.com/76269316/182016793-bd0924e8-3e38-4ebb-8669-cb809fb59382.png)

<br>

**Permutation Importance의 단점**

- 특정 피처를 무작위로 섞기 때문에, 실행마다 결과가 매우 달라질 수 있음 -> 시행 횟수를 늘림으로써 예측 에러의 분산을 줄일 수는 있지만, 피처 개수가 많을 경우 연산량이 증가함
- 피처를 무작위로 섞다보면 매우 비현실적인 데이터 조합이 생성될 가능성이 있음

키, 몸무게 피처가 있을 때 키 값을 랜덤으로 섞다보면 키는 2m인데 몸무게가 30kg인 데이터가 만들어 질 수도 있음 -> 이러한 비현실성, 비개연성이 증가하면 예측값에 지대한 영향을 미칠 수 있고, 중요도가 높게 나온다 하더라도 제대로된 결과가 아닐 수도 있음

➡️ 미리 변수간 상관관계를 확인한 뒤 이를 염두에 두고 결과를 해석해야 함

<br><br>

### 분류 평가 지표

##### 1. 정확도 (Accuracy)

<img src="https://user-images.githubusercontent.com/76269316/124422386-2a595180-dd9e-11eb-9ce0-3e76a6957078.png" alt="image" style="zoom: 80%;" />

정확도는 실제 데이터에서 예측 데이터가 얼마나 같은지를 판단하는 지표입니다.

직관적으로 모델 예측 성능을 평가할 수 있지만, 이진 분류의 경우 데이터 구성에 따라 ML 모델 성능을 왜곡할 수 있기 때문에 여러가지 분류 지표와 함꼐 사용됩니다. (불균형한(imbalanced) 레이블 값 분포에서 ML 모델 성능 평가시 정확도는 적합한 평가 지표가 아님)

<br><br>

##### 2. 오차 행렬 (Confusion Matrix)

오차 행렬은 이진 분류의 예측 오류가 얼마인지와 더불어 어떤 유형의 예측 오류가 발생하고 있는지를 함께 나타내는 지표입니다.

다음과 같이 4분면 행렬에서 실제 레이블 클래스 값과 예측 레이블 클래스 값이 어떤 유형을 갖고 매핑되는지를 나타냅니다.

<img src="https://user-images.githubusercontent.com/76269316/124429422-d43ddb80-dda8-11eb-94e7-9862bd0cc5d8.png" alt="image" style="zoom: 67%;" />

앞 문자는 True/False로 예측값과 실제값이 같은지 틀린지를 나타내고, 뒤에 문자는 Negative/Positive로 예측 결과값이 부정(0), 긍정(1)을 의미합니다.

- TN : 예측값을 Negative(0)으로 예측했고 실제값 역시 Negative(0)
- FP : 예측값을 Positive(1)로 예측했는데 실제값은 Negative(0)
- FN : 예측값을 Negative(0)로 예측했는데 실제값은 Positive(1)
- TP : 예측값을 Positive(1)로 예측했고, 실제값 역시 Positive(1)

이 값을 조합해 Classifier 성능을 측정할 수 있는 주요 지표인 정확도 (Accuracy), 정밀도(Precision), 재현율(Recall) 값을 알 수 있습니다.

먼저, 정확도는 예측 결과와 실제 값이 동일한 건수 / 전체 데이터 수였으므로, 다음과 같이 재정의될 수 있습니다.

<img src="https://user-images.githubusercontent.com/76269316/124430538-42cf6900-ddaa-11eb-809f-b24c9098981e.png" alt="image" style="zoom:50%;" />

<br>

일반적으로 불균형한 레이블 클래스를 갖는 이진 분류 모델에서는 많은 데이터 중에서 중점적으로 찾아야 하는 적은 수의 결괏값에 positive를 설정해 1 값을 부여하고, 그렇지 않은 값에 negative로 0으로 부여합니다.

<br>

예를 들어 사기 행위 예측 모델에서는 사기 행위를 postive로 정상 행위를 negative 값으로 할당하고, 암 검진 예측 모델에서는 양성일 경우 positive, 음성일 경우 negative로 할당합니다.

이런 불균형한 이진 분류 데이터 세트에서는 positive 건수가 매우 작으므로 데이터에 기반한 ML 알고리즘은 negative로 예측 정확도가 높아지는 경향(negative로 예측하려는 경향이 강해짐)이 발생합니다.

따라서 TN은 매우 커지고, TP는 매우 작아집니다. 또, negative로 예측할 때 정확도가 높기 때문에 FN 또한 작게되고, positive로 예측하는 경우도 적기 때문에 FP도 작아집니다.

<img src="https://user-images.githubusercontent.com/76269316/124431991-0bfa5280-ddac-11eb-80f1-87a26dfbcf16.png" alt="image" style="zoom: 67%;" />

*빨간색으로 표시한건 증가, 파란색으로 표시한건 감소*

결과적으로 positive에 대한 예측 정확도를 판단하지 못한 상태에서 negative에 대한 예측 정확도만 가지고 높은 정확도가 나타나는 수치적인 판단 오류가 발생하게 되는 것입니다.

<br><br>

##### 3. 정밀도, 재현율 (Precision, Recall)

정밀도와 재현율은 postivie 데이터 세트의 예측 성능에 좀 더 초점을 맞춘 평가 지표입니다.

<img src="https://user-images.githubusercontent.com/76269316/124432235-5e3b7380-ddac-11eb-8d50-af9b7e3d2527.png" alt="image" style="zoom:67%;" />

**정밀도는** **예측을 positive로 한 대상 중 예측과 실제 값이 positive로 일치한 데이터의 비율**을 의미합니다.

분모는 예측을 positive로 한 모든 데이터 건수이며, 분자는 예측과 실제 값이 positive로 일치한 데이터 건수입니다.

positive 예측 성능을 더 정밀하게 측정하기 위한 평가 지표로 양성 예측도라고도 불립니다.

<br>

**재현율**은 **실제 값이 positive인 대상 중에 에측과 실제 값이 positive로 일치한 데이터의 비율을** 의미합니다.

분모는 실제 값이 positive인 모든 데이터 건수이고, 분자는 예측과 실제 값이 positive로 일치한 데이터 건수입니다.

민감도(Sensitivity) 또는 TPR(True Positive Rate)이라고도 불립니다.

정밀도와 재현율 중 이진 분류 모델 업무 특성에 따라 특정 지표가 더 중요한 지표로 간주될 수 있습니다.

<br>

- 재현율이 중요 지표인 경우: 실제 positive 데이터를 negative로 잘못 판단하게 되면 업무상 큰 영향이 발생하는 경우

암 판단 모델의 경우 실제 양성(positive)인 암 환자를 음성(negative)으로 잘못 판단할 경우 환자가 목숨을 잃을 수 있기 때문에 재현율이 중요합니다.

✚ 음성인 환자를 양성으로 예측(양성이라고 예측했는데 음성이였음 - FP)해도 재검사를 해야하는 금전적 추가 비용이 따르지만 생명에는 지장이 없으므로 상관이 없는데, 양성인 환자를 음성으로 예측(음성으로 예측했는데 양성이였음 - FN)하면 늦장 대응으로 생명에 지장이 갈 수도 있음

→ FN이 중요 → 재현율 중요

<br>

- 정밀도가 중요 지표인 경우: 실제 negative 데이터를 positive로 잘못 판단하게 되면 업무상 큰 영향이 발생하는 경우

스팸 메일 여부를 판단하는 모델의 경우 실제 스팸 메일(positive)을 일반 메일(negative)로 분류해도 사용자가 불편함을 느낄 뿐이지만, 

일반 메일(negative)을 스팸 메일(positive)로 분류할 경우 만약 업무 관련 메일이였을 경우 업무에 차질이 생기게 됩니다. 

✚ 스팸 메일을 일반 메일로 분류(일반메일이라고 예측했는데 스팸 메일이였음 - FN)해도 상관없지만 일반 메일을 스팸 메일로 분류(스팸 메일이라고 예측했는데 일반 메일이였음 - FP)하면 문제가 생김

→ FP가 중요 → 정밀도 중요

<br>

**정밀도/재현율 트레이드 오프**

정밀도 또는 재현율을 높이기 위해 분류의 결정 임계값(threshold)을 조정해 정밀도 또는 재현율의 수치를 높일 수 있습니다.

하지만, 정밀도와 재현율은 상호 보완적인 평가 지표이기 때문에 어느 한쪽을 강제로 높이면 다른 하나의  수치는 떨어지게 됩니다.

이를 정밀도/재현율의 트레이드오프(Trade-off)라고 부릅니다.

![image](https://user-images.githubusercontent.com/76269316/179391148-47a58941-893c-4718-a19d-9d6a43ccaa3f.png)

위 그림은 임계값을 변경함에 따라 정밀도와 재현율의 수치가 변한 모습입니다.

이런 변경은 두 개의 수치를 상호 보완할 수 있는 수준에서 적용돼야 하며, 단순히 하나의 성능 지표를 높이기 위한 수단으로 사용돼서는 안됩니다.

<br>

**정밀도를 100%로 만드는 방법**

확실한 기준이 되는 경우만 positive로 예측하고 나머지는 모두 negative로 예측합니다.

![image](https://user-images.githubusercontent.com/76269316/124456282-79ff4380-ddc5-11eb-8694-65fe3658095b.png)

예를 들어, 전체 환자 1000명 중 확실한 positive 징후만 가진 환자가 단 한명이라고 하면 이 한 명만 positive로 예측하고 나머지는 모두 negative로 예측하더라도 FP = 0, TP = 1이 되므로 1/(1+0)이 되서 100%가 되게 됩니다.

<br>

**재현율을 100%로 만드는 방법**

모든 환자를 positive로 예측합니다.

![image](https://user-images.githubusercontent.com/76269316/124456490-b763d100-ddc5-11eb-8522-bf79791d4cf7.png)

전체 환자 1000명을 다 positive로 예측하면 이 중 실제 양성인 사람이 30명이여도 TN이 수치에 포함되지 않고, FN은 아예 0이므로 30/(30+0)으로 100%가 됩니다.

<br><br>

##### 4. F1 스코어 (F1 Score)

F1 스코어는 정밀도와 재현율을 결합한 지표입니다.

F1 스코어는 정밀도와 재현율이 어느 한 쪽으로  치우치지 않는 수치를 나타낼 때 상대적으로 높은 값을 갖습니다.

정밀도와 재현율을 결합한 지표이기 때문에, 결정 임계값을 변경함에 따라 F1 스코어 값도 변화하게 됩니다.

![image](https://user-images.githubusercontent.com/76269316/124457217-8506a380-ddc6-11eb-8396-7f14c9eca630.png)

<br><br>

##### 5. ROC 곡선과 AUC

ROC 곡선은 FPR(False Positive Rate)이 변할 때, TPR(True Positive Rate)이 어떻게 변하는 지를 나타내는 곡선입니다. (FPR을 X축으로, TPR을 Y축으로 두고 그린 그래프)

TPR은 재현율을 나타내는데, TPR에 대응하는 지표로는 TNR(True Negative Rate)이라고 불리는 특이성(Specificity)이 있습니다.

- 민감도(TPR) : 실제값 positive가 정확히 예측돼야 하는 수준을 나타냄. (질병이 있는 사람은 질병이 있는 것으로 양성 판정)
- 특이성(TNR) : 실제값 negative가 정확히 예측돼야 하는 수준을 나타냄. (질병이 없는 건강한 사람은 질병이 없는 것으로 음성 판정)

![image](https://user-images.githubusercontent.com/76269316/124475751-09fcb780-dddd-11eb-836d-7210da1f8a9a.png)

<br>

FPR은 FP / (FP + TN)이므로 1 - TNR로 표현할 수 있습니다.

![image](https://user-images.githubusercontent.com/76269316/124476621-0289de00-ddde-11eb-89e3-0144aba6fac2.png)

<br>

![image](https://user-images.githubusercontent.com/76269316/124476999-762beb00-ddde-11eb-8dd1-5ab8e6585307.png)

다음은 ROC 곡선의 예입니다. 가운데 직선은 ROC 곡선의 최저 값으로, 동전을 무작위로 던져 앞/뒤를 맞추는 랜덤 수준의 이진 분류 ROC 직선입니다.

ROC 곡선이 가운데 직선에 가까울수록 성능이 떨어지는 것이며, 멀어질수록 성능이 뛰어난 것입니다.

<br>

ROC 곡선은 FPR을 0부터 1까지 변경하면서 TPR의 변화값을 구합니다.

FPR은 분류 결정 임계값을 변경함으로써 변경할 수 있습니다.

분류 결정 임계값은 positive 예측값을 결정하는 확률의 기준이기 때문에 FPR을 0으로 만들려면 임계값을 1로 지정하면 됩니다.

1로 지정하면 positive 예측 기준이 매우 높아 분류기(Classifier)가 임계값보다 높은 확률을 가진 데이터를 positive로 예측할 수 없게되어 FPR = FP / (FP+TN) 중 FP가 0이되어 FPR이 0이되게 됩니다.

FPR을 1로 만들기 위해서는 분류 결정 임계값을 0으로 만들면 됩니다. 그러면 분류기(Classifier)의 확률 기준이 너무 낮아 모두 positive로 예측하게 되고, negative 예측이 없어 TN이 0이 되게되어 FPR이 1이 됩니다.

<br>

일반적으로 ROC 곡선 자체는 FPR과 TPR의 변화 값을 보는데 사용하며, 분류의 성능 지표로 사용되는 것은 AUC입니다.

AUC(Area Under Curve) 값은 ROC 곡선 밑의 면적을 구한 것으로서 일반적으로 1에 가까울수록 좋은 수치입니다.

AUC 수치가 커지려면 FPR이 작은 상태에서 얼마나 큰 TPR을 얻을 수 있느냐가 관건입니다. 

가운데 직선에서 멀어지고 왼쪽 상단 모서리 쪽으로 가파르게 곡선이 이동할수록 직사각형에 가까운 곡선이 되어 면적이 1에 가까워지게 됩니다.

가운데 대각선 직선은 랜덤 수준(동전 던지기 수준) 이진 분류 AUC 값으로 0.5입니다. 따라서 보통의 분류는 0.5 이상의 AUC 값을 갖습니다.

<br><br>

### 군집화 (Clustering)

레이블이 지정되어 있지 않은 데이터를 그룹핑하는 분석 알고리즘

<br>

##### K-평균 알고리즘 (K-Means Clustering)

군집 중심점(centroid)을 선택해 해당 중심에서 가장 가까운 포인트들을 선택하는 군집화 기법

![image](https://user-images.githubusercontent.com/76269316/181763137-9d542f70-466a-4266-a846-76759be4035b.png)

<br>

|    장점     |                             단점                             |
| :---------: | :----------------------------------------------------------: |
| 쉽고 간결함 | 거리 기반 알고리즘으로 피처의 개수가 많을 경우 군집화 정확도가 떨어짐 (차원 축소를 적용해야 할 수도 있음)<br />반복 횟수가 많을 경우 수행 시간이 매우 느려짐<br />몇 개의 군집을 선택해야 할 지 정하기 어려움 |

<br>

##### 평균 이동 (Mean Shift)

평균 이동은 K-means와 유사하게 군집의 중심을 지속적으로 움직이면서 군집화를 수행

K-means는 소속된 데이터의 평균 중심으로 이동, Mean Shift는 데이터의 확률 밀도가 가장 높은 곳으로 이동시킴

![image](https://user-images.githubusercontent.com/76269316/130313187-efa6018d-70d0-406a-b617-64fb124de4ae.png)

지정된 반복(Iteration) 횟수만큼 전체 데이터에 대해서 KDE((Kernel Density Estimation)) 기반으로 데이터를 이동시키면서 군집화 시킨 뒤, 집중적으로 데이터가 모여있어 확률 밀도 함수(probability denstiy function)가 피크인 점을 군집 중심점으로 선정합니다.

<br>

##### 군집화 평가 방법

**실루엣 분석 (Silhouette Analysis)**

실루엣 분석은 각 군집 간 거리가 얼마나 효율적으로 분리돼 있는지를 나타내는 지표로, 효율적으로 잘 분리돼 있다는 것은 다른 군집과의 거리는 떨어져있고, 동일 군집내의 데이터는 서로 가깝게 잘 뭉쳐 있다는 의미

![image](https://user-images.githubusercontent.com/76269316/130302511-132aedf9-777c-4de7-828e-8cb0211d44eb.png)

<br>

실루엣 계수(Silhouette Coefficient) 해당 데이터가 같은 군집 내의 데이터와는 얼마나 가깝게 군집화 돼 있고, 다른 군집에 있는 데이터와는 얼마나 멀리 분리돼 있는지를 나타내는 지표

<p align = "center">
  <img src = "https://user-images.githubusercontent.com/76269316/130302905-973466ac-9e91-4b47-a2ce-fb3f8a521215.png">
</p>
<p align = "center">
  i번째 데이터 포인트의 실루엣 계수 s(i)
</p>


-1에서 1 사이의 값을 가지며, 1로 가까워질수록 근처 군집과 더 멀리 떨어져 있다는 것이고, 0에 가까울수록 근처 군집과 가까움.

음수 값은 아예 다른 군집에 데이터 포인트가 할당됐음을 의미

<br>

**좋은 군집화의 조건**

1. 전체 실루엣 계수의 평균값이 0 ~ 1 사이의 값을 가지며, 1에 가까울수록 좋음
2. 개별 군집의 평균값의 편차가 크지 않아야 함 (개별 군집의 실루엣 계수값이 전체 실루엣 계수의 평균값에서 크게 벗어나지 않아야 함, 특정 군집의 실루엣 계수값만 유난히 높고, 다른 군집의 실루엣 계수값이 낮은 경우 -> 좋은 군집화 X)

<br><br>

### 컴퓨터 비전

##### Semantic Segmentation

##### [FCN (Fully Convolutional Networks)](https://medium.com/@msmapark2/fcn-%EB%85%BC%EB%AC%B8-%EB%A6%AC%EB%B7%B0-fully-convolutional-networks-for-semantic-segmentation-81f016d76204)

FCN은 Semantic Segmentation 모델을 위해 기존에 이미지 분류에서 우수한 성능을 보인 CNN 기반 모델(AlexNet, VGG16, GoogLeNet)을 segmentation에 맞게 변형시킨 것이다.

<br>

<img width="650" alt="스크린샷 2022-07-30 오후 9 14 54" src="https://user-images.githubusercontent.com/76269316/181913799-9453ce00-7274-48e0-a5f2-ade0a7d48caa.png">

기존 이미지 분류 모델들은 출력층이 fully connected layer로 구성돼 있는데, 이는 입력층에서부터 중간부분까지 convolution network를 이용하여 이미지의 특징을 추출한 뒤 fully connected layer에서 이미지를 분류한다.

<br>

**fully connected layer의 문제점**

1.이미지의 위치 정보가 사라진다.

<p align = "center">
  <img src = "https://user-images.githubusercontent.com/76269316/181914298-6e1da209-7c63-4042-9cf1-cc0f53cbfcc8.png">
</p>
<p align = "center">
  fully connected layer 연산 이후 receptive field 개념이 사라짐
</p>


<br>

2.입력 이미지 크기가 고정된다.

<p align = "center">
  <img src = "https://user-images.githubusercontent.com/76269316/181914498-1c4ba61c-157e-473e-9059-94f4740f3a4a.png">
</p>
<p align = "center">
  Dense layer에 가중치 개수가 고정돼 있기 때문에 피처맵 크기가 고정되며, 연쇄적으로 각 레이어의feature map, Input image 크기 역시 고정됨
</p>


<br>

Segmentation 목적은 원본 이미지의 각 픽셀에 대해 클래스를 구분하고 인스턴스 및 배경을 분할하는 것이기 때문에 위치 정보가 매우 중요하다.

이러한 fc layer의 한계를 보완하기 위해 모든 fc layer를 convert layer로 대체(feature map이 원본 이미지의 위치 정보를 내포할 수 있게 됨)

하지만 semantic segmentation의 최종 목적인 픽셀 단위 예측과 비교했을 때, 피처맵은 너무 coarse(거친, 알맹이가 큰) 함 -> 원본 이미지 크기에 가까운 dense map으로 변환해야 함

cf) Pooling을 사용하지 않거나, Pooling의 stride를 줄임으로써 Feature map의 크기가 작아지는 것을 처음부터 피할 수도 있지만, Receptive Field가 줄어들어 이미지의 컨텍스트를 놓치게 됨

또한, pooling의 중요한 역할 중 하나는 피처맵의 크기를 줄임으로써 학습 파라미터 수를 감소시키는 것인데, 이러한 과정이 사라지면 파라미터 수가 급격히 증가해 더 많은 학습 시간이 요구됨

<br>

**Deconvolution**

- Bilinear Interpolation

![스크린샷 2022-07-30 오후 10 39 52](https://user-images.githubusercontent.com/76269316/181916999-7047baa9-c49a-4df9-93fe-2074742b6191.png)

Bilinear Interpolation을 통해 피처맵의 빈 영역을 추정할 수 있음

![스크린샷 2022-07-30 오후 10 40 58](https://user-images.githubusercontent.com/76269316/181917035-d1065d79-2002-4a84-8553-8eb9983f5b41.png)

- Backwards Convolution

![스크린샷 2022-07-30 오후 10 42 08](https://user-images.githubusercontent.com/76269316/181917094-28a0fb1c-99c3-416b-af5c-30a810b9956c.png)

Convolution 연산을 반대로 함으로써 Up-sampling을 학습

![스크린샷 2022-07-30 오후 10 43 56](https://user-images.githubusercontent.com/76269316/181917159-8add537e-6a1c-4209-b98e-a6b7349f2c77.png)

<br>

FCNs에서는 Bilinear interpolation과 Backwards convolution 두 가지 방법을 사용하여 Coarse Feature map으로부터 Dense prediction을 구함

하지만 근본적으로 feature map의 크기가 너무 작기 때문에 예측된 dense map의 정보는 여전히 거칠수 밖에 없다.

![스크린샷 2022-07-30 오후 10 44 43](https://user-images.githubusercontent.com/76269316/181917192-c388a700-fd77-4afe-b566-efc17e687dbf.png)

▶️ 보다 정교한 Segmentation을 위해 추가적인 작업이 필요

<br>

**Skip Architecture**

입력 이미지에 대해 얕은 층에서는 주로 직선 및 곡선, 색상 등의 낮은 수준의 특징이 활성화되고, 깊은 층에서는 보다 복잡하고 포괄적인 개체 정보가 활성화 됨

또한 얕은 층에선 local feature, 깊은 층에선 global feature를 감지한다고 볼 수 있음

![스크린샷 2022-07-30 오후 11 00 28](https://user-images.githubusercontent.com/76269316/181917774-c658ef3a-ff4b-4787-ac8b-21876ecb89b0.png)

<br>

Dense map에 얕은 층의 정보를 결합함으로써 segmentation 품질을 개선함

![스크린샷 2022-07-30 오후 11 02 15](https://user-images.githubusercontent.com/76269316/181917843-e493d255-3781-4ce3-83e7-077eee34969b.png)

![스크린샷 2022-07-30 오후 11 02 26](https://user-images.githubusercontent.com/76269316/181917852-c1c0421a-4adf-4a93-a86a-21621b834ade.png)

<br>

**정리**

FCNs은 기존의 딥러닝 기반 이미지 분류를 위해 학습이 완료된 모델의 구조를 Semantic Segmentation 목적에 맞게 수정하여 Transfer learning 하였다.

Convolutionalized 모델을 통해 예측된 Coarse map을 원본 이미지 사이즈와 같이 세밀(Dense)하게 만들기 위해 Up-sampling을 수행하였다.

또한 Deep Neural Network에서 얕은 층의 Local 정보와 깊은 층의 Semantic 정보를 결함하는 Skip architecture를 통해 보다 정교한 Segmantation 결과를 얻을 수 있었다.

FCNs은 End-to-End 방식의 Fully-Convolution Model을 통한 Dense Prediction 혹은 Semantic Segmentation의 초석을 닦은 연구로써 이후 많은 관련 연구들에 영향을 주었다.

<br><br>

##### U-Net

U-Net은 Biomedical 분야에서 Image Segmentation을 목적으로 제안된 End-to-End 방식의 Fully-Convolutional Network 기반 모델이다.

![스크린샷 2022-07-30 오후 11 09 56](https://user-images.githubusercontent.com/76269316/181918159-e4bc41e2-6ff7-461a-be94-a0200c3f29bd.png)

U-Net은 이미지의 전반적인 컨텍스트 정보를 얻기 위해 localization을 위해 네트워크가 대칭 형태로 구성돼 있다.

<br>

**Contracting Path**

![스크린샷 2022-07-30 오후 11 11 01](https://user-images.githubusercontent.com/76269316/181918209-a20fe435-e62b-4bd1-a717-467325c1da3a.png)

![스크린샷 2022-07-30 오후 11 18 39](https://user-images.githubusercontent.com/76269316/181918495-9110f023-c369-47ee-b609-72f34d9479b0.png)

- 3x3 convolution 연산을 두 번씩 반복 (패딩이 없기 때문에 피처맵이 조금씩 줄어듦)
- 활성화 함수는 ReLU
- Contracting Step마다 2x2 max-pooling(stride: 2) 연산을 수행 -> 이 때 피처맵의 크기가 절반으로 줄어듦
- Down-sampling마다 채널 수가 2배로 늘어남

<br>

**Expanding Path**

![스크린샷 2022-07-30 오후 11 11 56](https://user-images.githubusercontent.com/76269316/181918245-81bf6dd0-d7d2-45cc-a4e7-3870f634db7d.png)

![스크린샷 2022-07-30 오후 11 18 50](https://user-images.githubusercontent.com/76269316/181918502-b28e772d-703f-4b83-9bf4-cc3944281dba.png)

Expanding Path의 경우 Contracting Path의 최종 특징 맵으로부터 보다 높은 해상도의 Segmentation 결과를 얻기 위해 몇 차례의 Up-sampling을 진행한다. (Coarse Map에서 Dense Prediction을 얻기 위한 구조로 Contracting Path의 반대 연산)

- Expanding Step마다 2x2 up convolution 수행 -> 피처 맵의 크기가 두 배로 늘어남
- Expanding Step마다 3x3 convolution을 두 차례 반복 (패딩이 없으므로 피처맵이 조금씩 줄어듦)
- 활성화 함수는 ReLU
- Up-sampling 할 때마다 채널 수가 절반씩 줄어듦
- 마지막에 1x1 convolution 연산 (비선형 예측을 위해)

 **최종 출력인 Segmentation map의 크기는 Input Image 크기보다 작다. Convolution 연산에서 패딩을 사용하지 않았기 때문이다.**

<br>

FCN의 Skip Architecture 개념을 도입 ➡️ 각 Expanding step마다 Up-conv된 피처맵과 Contracting path의 cropped된 피처맵과 concatenate함(얕은 층의 피처맵을 깊은 층의 피처맵과 결합)

<br>

**Overlap Title Input**

Fully Convolutional Network 구조 특성상 입력 이미지 크기에 제약이 없기 때문에 U-Net 연구팀은 이미지 크기가 큰 경우 overlap-title 전략을 사용했다.

![스크린샷 2022-07-30 오후 11 30 34](https://user-images.githubusercontent.com/76269316/181918936-e37d4e7b-b476-4ab9-9823-1e5a900de282.png)

위 그림에서 왼쪽 노란색 박스 영역을 segmentation 하기 위해서는 파란색 영역의 이미지 데이터가 필요합니다. (작은 영역을 예측하기 위해 큰 영역을 학습 시켜야 함, 의료 영상 이미지는 고해상도 이미지라 연산량이 많이 필요)

하지만 이렇게 예측을 하게 되면 기존에 가지고 있는 원본 이미지보다 훨씬 더 작은 영역만 예측이 가능할겁니다. 하지만 우리는 입력한 전체 이미지의 분할 결과를 얻을 수 있어야 하므로, 누락되는 부분을 원본 이미지를 미러링해서 채워넣어서 전체 입력 이미지에 대해 분할할 수 있도록 하였습니다. 

왼쪽 그림을 보면 노란 테두리의 이미지가 원본 이미지와 거울을 댄 것처럼 대칭임(픽셀 값을 복사(미러링)함으로써 메모리의 추가적인 사용을 줄이고 원본 이미지 크기의 예측 결과를 얻어냄)

<br>

![스크린샷 2022-07-30 오후 11 40 09](https://user-images.githubusercontent.com/76269316/181919335-f5acdff7-6142-4831-88c1-c70972469207.png)

노란색 영역, 즉 타일을 예측하게 되면 다음 타일로 넘어가는데 필요한 영역이 이전에 예측을 위해 사용했던 영역과 겹치게(overlap) 되기 때문에 이를 overlap-title이라고 부름

논문에서는 overlap-tile 전략은 "GPU 메모리가 한정되어 있을 때 큰 이미지들을 인공 신경망에 적용하는데 장점이 있다"고 언급함.

<br>

**Touching Cells Separation**

![스크린샷 2022-07-30 오후 11 41 47](https://user-images.githubusercontent.com/76269316/181919398-a1998333-847a-419c-b8ac-4c3527bba909.png)

세포 분할 작업에서 주요한 과제 중 하나는 동일한 클래스의 인접한 개체를 분리하는 것인데, 이를 위해 손실 함수를 재정의함 (Ground-Truth에 대한 Weight map을 구해 학습에 반영)

weight map loss를 의미하는 항을 추가했는데 가장 가까운 세포의 경계까지의 거리와 두번째로 가까운 세포의 경계까지의 거리의 합이 최대가 되도록 하는 손실함수입니다. 

이렇게 하면 모델은 낮은 손실함수를 갖는 방향으로 학습하기 때문에 두 세포 사이의 간격을 넓히는 식, 즉 두 인스턴스 사이의 배경을 넓히는 방향으로 학습하게 됩니다. 

이렇게 하면 세포나 조직이 뭉쳐있는 경우에도 정확하게 인스턴스별로 분할이 가능하게 됩니다.

이런 의미에서 (d)에서 세포 객체들 사이에 존재하는 배경/틈에 높은 가중치가 부여된 것을 확인할 수 있습니다. 

<br>

**정리**

U-Net은 FCNs보다 확장된 개념의 Up-sampling과 Skip Architecture를 적용한 모델을 제안하였다.

결과적으로 U-Net의 구조는 아주 적은 양의 학습 데이터만으로 Data Augmentation을 활용하여 여러 Biomedical Image Segmentation 문제에서 우수한 성능을 보여주었다.

<br><br>

### Self Supervised Learning(SSL)이란?

Self Supervised Learning은 직역하자면 자기 지도 학습으로, 레이블이 없는 데이터를 활용하여 모델이 좋은 특징(representation)을 추출할 수 있도록 학습하는 방법론입니다.

연구 초기에는 Unsupervised Learning(비지도 학습)의 하위 개념 정도로 분류 됐었는데, 현재 Meta AI Research인 Yann LeCun 교수님이 Self Supervised Learning의 개념을 구체화하면서 2019년부터 각각의 독립된 학습 방식으로 나뉘게 됩니다.

![스크린샷 2022-07-12 오후 11 47 43](https://user-images.githubusercontent.com/76269316/178518595-b1c9ee91-09b0-4adf-9675-f8e66742ab19.png)

<br>

##### Self Supervised Learning vs Unsupervised Learning

Self Supervised Learning과 Unsupervised Learning의 차이는 supervision(label이라고 생각하면 좋을 듯)의 유무입니다.

Unsupervised Learning은 레이블이 없는 데이터에서 패턴을 학습하는 방식으로 (e.g. [군집화](https://seominseok4834.github.io/machine%20learning/7.clustering/)) supervision이 아예 없습니다.

하지만 Self Supervised Learning(이하 SSL)은 아래에서 설명하겠지만, 원본 데이터에서 스스로 supervision을 생성해 학습을 진행하는 방식이기 때문에 이를 unsupervised learning의 일종으로 보는 것은 맞지 않다는 것이 Yann LeCun 교수님의 주장입니다.

<br>

SSL의 연구 과정은 다음과 같습니다.

1. Label이 없는 데이터를 가지고, 좋은 representation을 추출할 수 있도록 Backbone 모델을 훈련한다.
2. 1에서 훈련한 backbone 모델을 가지고, 적용하고자하는 downstream task로 transfer learning을 진행한다.

downstream task는 실제로 우리가 하고자 하는 태스크로, image classification이나 object detection 같은 걸 의미합니다. 2에서 transfer learning을 하는 이유는 pretext task를 학습한 모델은 object detection이나 segmentation을 할 수 없기 때문에 다시 학습을 진행하는 것입니다.

![스크린샷 2022-07-13 오후 9 21 00](https://user-images.githubusercontent.com/76269316/178732143-dd0803c3-aa05-4a08-8841-2ca0670d3f51.png)

SSL 연구는, Backbone 모델에서 더 좋은 feature(Representation)을 추출할 수 있도록하여 차후 task에서 성능을 올리는 것(Supervised Learning으로 학습한 모델보다)이 주된 목표인 듯합니다.

현재 연구 동향은 Pretext Task, Contrastive Learning 두 가지로 나뉘는데 레이블이 없는 데이터에서 좋은 representation을 뽑는 backbone 모델을 훈련할 때 pretext task로 할 것인지, contrastive learning으로 진행하는지의 차이입니다.

먼저 Pretext Task에 대해 알아보겠습니다.

<br><br>

### Pretext Task

SSL 초기 연구에서 진행됐던 방법으로, 연구자가 직접 만든 pretext task로 모델을 훈련한 뒤 이를 downstream task로 transfer learning하는 방식입니다.

매우 다양한 pretext task가 있는데, 몇 가지만 소개하겠습니다.

##### Exemplar, 2014 NIPS

[Discriminative Unsupervised Feature Learning with Exemplar Convolutional Neural Networks](https://arxiv.org/abs/1406.6909) 논문에서 제안한 pretext task로

![스크린샷 2022-07-13 오전 12 35 28](https://user-images.githubusercontent.com/76269316/178529621-bd091ac5-7af7-4c47-80f9-767ffd12c09b.png)

96x96의 이미지에서 object가 있을만한 곳을 crop하여 32x32 크기의 seed patch를 생성합니다. (위 그림에서는 왼쪽 최상단)

이후 seed patch에 augmentation을 적용해, 24개의 이미지를 확보한 뒤 classifier가 24개의 patch들과 seed patch를 동일한 클래스로 예측하도록 학습을 진행하는 방식입니다.

<br>

##### Context Prediction

다음으로 소개할 pretext task는  [Unsupervised Visual Representation Learning by Context Prediction](https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Doersch_Unsupervised_Visual_Representation_ICCV_2015_paper.pdf)에서 제안한 방식으로, 

![스크린샷 2022-07-13 오전 12 44 12](https://user-images.githubusercontent.com/76269316/178532992-9b463829-2854-497e-88c2-b965ed5f1786.png)

이미지에서 9개의 patch를 가져와 중간의 patch와 다른 1개의 patch를 주고, 다른 1개의 patch의 위치가 어느 방향에 위치할지를 찾는 문제입니다.

<br>

하지만 이러한 방식은 이미지 하나하나가 하나의 클래스를 부여받는다는 문제점이 존재했습니다. 데이터 개수가 클래스 개수가 되니 메모리 문제 등으로 큰 데이터셋에 대해서는 이를 적용하기 어려웠고, Contrastive Learning이 주목받게 됩니다.

<br><br>

### Contrastive Learning

##### Motivation

Image classification에서 레오폴드 이미지를 분류한 뒤 예측 확률 값을 확인해 보았더니, 재규어나 치타 같이 레오폴드와 유사한 동물의 클래스 값이 높았다고 합니다.

레오폴드가 재규어나 치타랑 유사하다는 정보는 전혀 주어지지 않았는데도(레이블 정보는 one-hot 벡터로 들어가기 때문에) 저렇게 예측했다는 것은 이미지끼리 공유하는 특징이 있다는 것이고, 이러한 관측치 사이의 유사성을 기반으로 해서 학습한다면 좋은 representation을 얻을 수 있지 않을까하는 동기에서 contrastive learning 연구가 시작됐다고 합니다.

[Unsupervised Feature Learning via Non-Parametric Instance Discrimination](https://openaccess.thecvf.com/content_cvpr_2018/CameraReady/0801.pdf)

![스크린샷 2022-07-13 오전 12 59 13](https://user-images.githubusercontent.com/76269316/178538522-1abd1b2e-ca42-4f4b-87fe-b5182cb2b9bd.png)

<br>

하지만 MNIST만 하더라도 관측치가 60,000개

<img src="https://user-images.githubusercontent.com/76269316/178719166-180979d0-ee47-4af6-a5ae-9d4aa627f918.png" alt="image"  />

ImageNet 같은 경우는 관측치가 1,200,000개 이상이기 때문에 소프트맥스를 사용하기 어렵습니다.

<img src="https://user-images.githubusercontent.com/76269316/178719562-ad2cbc98-c189-4466-91fc-0e05bd4c9786.png" alt="image" style="zoom:67%;" />

<br>

이러한 문제와 유사한 것이 word embedding인데, word embedding은 단어 사이의 관계를 학습하기 위해 context 뒤에 올 단어를 예측하면서 representation을 학습합니다.

word embedding에서도 단어의 개수가 클래스 개수가 되다보니 전체를 softmax로 계산할 수 없게 되는데, 일부만 샘플링하여 계산하는 방법을 사용하였습니다.

<img src="https://user-images.githubusercontent.com/76269316/178744096-5d4e4971-25ad-400e-9c86-edb074913820.png" alt="스크린샷 2022-07-13 오후 10 23 50" style="zoom:67%;" />

<br>

Contrastive Learning에서는 memory bank를 사용하여 이와 유사한 방식을 적용하였습니다.

![스크린샷 2022-07-13 오전 1 34 13](https://user-images.githubusercontent.com/76269316/178545812-f0a4834f-9c0c-41ac-9503-79cb6003063b.png)

먼저, 이미지는 고차원이기 때문에 128차원으로 임베딩해서 사용합니다.

이후, Iteration에서 얻은 모든 임베딩 벡터를 저장하는 memory bank에서 현재 target 이미지인 강아지(anchor)와 매칭되는 임베딩 정보와 나머지 이미지들을 샘플링합니다. (분포를 가정하지 않고 랜덤하게 샘플링)

매칭되는 임베딩 정보는 positive example, 나머지 이미지들은 negative example로 놓고 anchor와 positive의 코사인 유사도는 가깝게 anchor와 negative pair의 코사인 유사도는 멀어지도록 학습합니다.

<br>

<img src="https://user-images.githubusercontent.com/76269316/178724408-6e93294c-5256-4dc5-8e69-3a1acb1d1c22.png" alt="image" style="zoom: 50%;" />

이러한 과정을 거쳐 representation을 잘 학습한다면 다음과 같이 관측치가 배치된다고 합니다.

<br>

##### MoCo

[Momentum Contrast for Unsupervised Visual Representation Learning](https://arxiv.org/pdf/1911.05722.pdf)

MoCo는 Facebook에서 발표한 논문으로 앞서 설명한 contrastive learning에서 memory bank의 문제점을 개선한 방식입니다.

memory bank는 관측치 전체에 대한 임베딩 정보를 계속 저장하고 있어야 하고, negative example을 랜덤 샘플링 하다보니 학습에 한 번도 사용하지 않는 데이터가 존재할 수 있다는 문제점이 있습니다.

MoCo에서는 Memory Queue를 사용해 모든 샘플이 동등한 횟수로 학습에 이용되며, 사용할때마다 임베딩하여 메모리 이슈도 해결하였습니다.  

![스크린샷 2022-07-13 오후 8 40 48](https://user-images.githubusercontent.com/76269316/178725495-c407d921-c9d3-4f46-a0e6-a597984eca0b.png)

<br>

Memory Queue에서 임베딩 벡터를 만들 때, Momentum Encoder가 네트워크로 사용됩니다.

<img src="https://user-images.githubusercontent.com/76269316/178725810-33041276-634d-4169-aa70-aa79a84b1c3c.png" alt="스크린샷 2022-07-13 오후 8 42 53" style="zoom:67%;" />

Target 네트워크는 stochastic gradient로 학습되지만, Momentum Encoder는 과거 target 네트워크 모델 weight의 가중 평균으로 업데이트 됩니다.

이러한 방식은 Semi Supervised Learning의 [Mean Teacher](https://arxiv.org/pdf/1703.01780.pdf)에서 차용한 것으로 과거 모델 weight들의 가중 평균을 이와 비슷하게 만들어 감으로써 모델을 학습시키는 방식입니다.

<br>

##### SimCLR

[A Simple Framework for Contrastive Learning of Visual Representations](https://arxiv.org/pdf/2002.05709.pdf)

SimCLR는 구글에서 제안한 논문으로 '배치 사이즈를 크게 가져가면 충분한 양의 negative 샘플을 뽑을 수 있지 않을까?'하는 개념에서 시작됐습니다.

SimCLR에서는 관측치별로 2번의 augmentation을 적용한 뒤 anchor와 같은 이미지에서 나온 이미지를 positive example, 나머지를 negative example로 정의한 뒤 학습을 진행합니다.

<img src="https://user-images.githubusercontent.com/76269316/178730186-587b7ff8-fadd-48b9-a9e8-06ec58ccb53a.png" alt="스크린샷 2022-07-13 오후 9 09 31" style="zoom:67%;" />

<br>

실험 결과 2048개 ~ 4096개의 배치 사이즈를 사용했을 때 충분한 성능 향상이 이루어졌다고 합니다.

![스크린샷 2022-07-13 오후 9 11 57](https://user-images.githubusercontent.com/76269316/178730566-d6a436cb-21d7-4c1d-b783-32fc9c0510bd.png)

하지만 4096개의 배치 사이즈를 사용한다고 하면, 2번의 augmentation을 적용해 8192개의 샘플에 대해 연산을 해야하므로 많은 자원(gpu)이 필요하게 됩니다.

또한 다양한 data augmentation 기법과 조합을 사용해 실험을 진행했습니다.

![스크린샷 2022-07-13 오후 9 14 33](https://user-images.githubusercontent.com/76269316/178730961-3fcc4a9f-0ff8-4cd6-a928-24a059abe968.png)

<br>

### BYOL

Contrastive Learning은 pretext task보다 더 높은 성능을 달성할 수 있었지만, 여전히 한계점이 존재했습니다.

1.Require careful treatment of negative pairs: negative example을 확보하기 위해 많은 노력이 필요함

2.Choice of Image Augmentation: augmentation 조합에 따라 모델의 성능이 크게 좌우됨

![스크린샷 2022-07-13 오후 9 26 29](https://user-images.githubusercontent.com/76269316/178733120-03e53c20-5d7f-4729-b4bd-6bc38902a10e.png)

3.Requires comparing each representation of an augmented view with many negative examples: 수많은 negative 샘플을 비교하는 과정이 필요함

BYOL은 positive pair만을 사용하여 이러한 한계점을 극복하고자 하였습니다.

<br>

BYOL은 Online Network, Target Network로 구성돼 있습니다.

![스크린샷 2022-07-13 오후 9 38 13](https://user-images.githubusercontent.com/76269316/178735300-272c8106-fc8b-4cbc-ac34-4da977635afd.png)

각각의 네트워크는 하나의 이미지에서 다른 augmentation이 적용된 이미지를 입력으로 받습니다.

이후 Encoder에서 이미지의 특징을 담은 representation 벡터를 추출하고, Projector에서 representation 벡터를 projection 벡터로 변환하여 loss 값을 계산하기 좋게 변환합니다.

이후 online network에서 나온 projection 벡터로, target network에서 나온 projection 벡터를 예측하는 과정을 통해 학습하기 때문에 Predictor는 online network에만 존재합니다.

이후 online network에서는 손실 함수에서 계산한 gradient로 파라미터를 업데이트하고, target network에서는 online network와 target network의 파라미터를 가중 평균한 값으로 업데이트합니다. 이를 Exponential Moving Average라고 합니다.

또한 negative pair를 사용하지 않기 때문에 Contrastive Loss가 아닌, L2 loss를 사용합니다.

<br>

##### Collapsed Representation

![스크린샷 2022-07-13 오후 9 50 36](https://user-images.githubusercontent.com/76269316/178737614-1ec1a3cd-c81f-4af5-b838-fbce918a8d17.png)

BYOL에서는 negative pair를 전혀 사용하지 않기 때문에, 모델이 고정된 값을 갖는 constant vector를 출력하는 representation collapse 문제가 발생할 수 있는데, BYOL에서는 이를 해결했다고 한다.

<br>

<img src="https://user-images.githubusercontent.com/76269316/178738550-1e4c23c5-e1ca-4e43-8fbf-5dcb93947388.png" alt="image" style="zoom:50%;" />

그런데 어떻게 방지했는지는 모른다고 한다 .. ¿¿

**batch normalization 때문이다 -> 아니다 -> batch statistics를 통한 implict constrastive 효과를 받지 않는 이상 높은 성능을 발휘 할 수 없다 -> 아니다**

현재도 많은 논쟁이 오가고 있는 것 같다. 추후에 관련 논문들을 읽어봐야겠다.
