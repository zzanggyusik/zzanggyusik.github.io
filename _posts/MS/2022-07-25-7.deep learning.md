---
title: "[대학원 면접] 딥러닝 정리"
excerpt: "딥러닝 정리"
toc: true
toc_label: "딥러닝 정리"
toc_sticky: true

categories:
  - MS
tags:
  - 대학원
last_modified_at: 2022-07-25
---

> <img src="https://user-images.githubusercontent.com/76269316/181256814-8da4d686-bad3-4b91-a73f-1fbb77c7b8fa.png" alt="image" style="zoom:67%;" />
>
> [실전 인공지능으로 이어지는 딥러닝 개념 잡기](https://www.inflearn.com/course/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%9C%EB%85%90)를 수강하고 공부한 내용을 정리한 포스팅입니다.

<br>

##### 인공신경망의 장점?

전통적인 머신러닝은 모델이 학습을 잘 할 수 있도록, 사람이 데이터를 가공하여 좋은 변수를 만들어야 함

이러한 과정을 피처 엔지니어링이라고 하는데 딥러닝에서는 별도의 가공 없이 데이터를 주더라도 스스로 피처를 학습하는 feature learning 개념을 갖고 있음

사용자가 다양한 구조를 만들 수 있기 때문에 다양한 분야에서 사용 가능

<br>

##### 딥러닝이란?

인공 신경망을 깊게 만들어 모델을 학습시키는 방법

<br>

### 인공 신경망 (Artificial Neural Network)

![스크린샷 2022-07-25 오후 9 18 12](https://user-images.githubusercontent.com/76269316/180775846-282bf12d-0d90-436a-a5b8-0b45b99ae426.png)

각 층 사이의 계산은 행렬 연산을 통해서 이루어짐

![스크린샷 2022-07-25 오후 9 24 52](https://user-images.githubusercontent.com/76269316/180776845-961b72b3-d910-4ebb-a332-c2e2ea27a107.png)

<br>

##### 활성화 함수 (Activation Function)

<img src="https://user-images.githubusercontent.com/76269316/180777937-c5bc5a7d-bd2b-4d7f-b1d7-5e8c5b291003.png" alt="스크린샷 2022-07-25 오후 9 31 36" style="zoom:67%;" />

인공 신경망은 1차 결합 형태로 돼 있음

👉 미분이 쉬움

👉 계산이 쉬움

하지만 실제 현실 세계에서는 선형적인 관계만 존재하는게 아님 ➡️ **비선형적인 관계를 표현하기 위해 활성화 함수를 사용!**

<img src="https://user-images.githubusercontent.com/76269316/180778606-5a562409-9905-44b8-a10b-4bc6b896e03a.png" alt="스크린샷 2022-07-25 오후 9 35 21" style="zoom:67%;" />

<br>

- 시그모이드 함수

다층의 관계를 비선형적으로 만들어줌, 미분이 가능, 모든 값을 0 ~ 1 사이로 변환

![스크린샷 2022-07-25 오후 9 37 03](https://user-images.githubusercontent.com/76269316/180778894-90136d2c-7c7a-4b6e-8c87-01ac2f15796b.png)

- 하이퍼볼릭 탄젠트

-1 ~ 1 사이의 값을 가짐. 미분 가능, 시그모이드 보다 가파른 기울기를 갖고 있음

![스크린샷 2022-07-25 오후 9 37 27](https://user-images.githubusercontent.com/76269316/180778957-3a740039-a7b4-4a90-8916-f44d29559c3b.png)

- ReLU

음수 값이 들어오면 0으로, 양수 값이 들어오면 그대로 내보냄. (직선 두 개를 합쳤기 때문에 비선형 함수이지만, 선형식의 성질을 갖고 있음 - 계산·미분이 쉬움)

음수 값은 미분시 0, 양수 값은 1, 0일 때는? **미분 불가능**

![스크린샷 2022-07-25 오후 9 38 16](https://user-images.githubusercontent.com/76269316/180779102-e513c7f1-6eb9-4c4c-b528-c918bd44d9f0.png)

❗️Subgradient

0 기준 왼쪽은 미분값이 0, 오른쪽은 1이므로 0에서는 0 ~ 1 사이의 기울기 값을 가짐 👉 미분이 불가능한 지점에서도 구간을 가지고 있다면 일부의 값을 미분값으로 취할 수 있음

<br>

- Leaky ReLU

음수 값도 기울기가 있는 직선으로 대체

![스크린샷 2022-07-25 오후 9 46 21](https://user-images.githubusercontent.com/76269316/180780601-c23217bf-79a7-4b42-944c-0f269191e5f6.png)

- ELU

음수 값을 곡선으로 대체

![스크린샷 2022-07-25 오후 9 47 23](https://user-images.githubusercontent.com/76269316/180780809-be28dda8-a1fb-4b64-b8df-dcc20dabfc4a.png)

- Softmax

모든 입력 값에 대해 0 ~ 1 사이의 값을 가짐. 모든 성분의 합은 항상 1

![스크린샷 2022-07-25 오후 9 50 17](https://user-images.githubusercontent.com/76269316/180781354-9fef2f58-dfe7-45c4-a6a1-5c8f3561d837.png)

분자에 지수 함수를 사용한 이유는 음수 값이 입력으로 들어왔을 때 이를 그대로 사용하면 확률값으로 만들 수 없기 때문 (입력값이 양수든 음수든 항상 0 ~ 1 사이의 값이 나오도록 하는 장치)

<br>

##### XOR 문제 (XOR Problem)

XOR 연산을 퍼셉트론을 가지고 해결할 수 있는가?에 대한 문제

![스크린샷 2022-07-25 오후 9 53 02](https://user-images.githubusercontent.com/76269316/180781847-d1be5ca7-fb2e-4fe1-9570-ad46135014da.png)

<br>

선형적인 관계만 표현할 수 있던 퍼셉트론으로는 해결할 수 없었음

![스크린샷 2022-07-25 오후 10 00 46](https://user-images.githubusercontent.com/76269316/180783299-bc936092-54a5-4fd0-88a6-ae463fb8ccec.png)

<br>

은닉층을 만들어서 해결 👉 MLP 

![스크린샷 2022-07-25 오후 10 02 26](https://user-images.githubusercontent.com/76269316/180783617-5b40abae-9a57-42f1-89df-722e9136757c.png)

<br>

여러 입력값을 전치 행렬(Transpose)을 통해 한 번에 계산할 수 있음

![스크린샷 2022-07-25 오후 10 09 03](https://user-images.githubusercontent.com/76269316/180784893-b2d11090-be98-4b80-a9aa-33b366cb76c0.png)

<br>

##### 손실 함수 (Loss Function)

실제값과 예측값의 차이, 예측이 얼마나 정확한지를 나타내는 척도

<br>

**회귀(Regression)**

결과값이 연속적인 변수인 것을 예측하는 문제

- 평균 절대 오차 (Mean Absolute Error)

실제값과 예측값의 차이(잔차-residual)의 절댓값을 기반으로 한 손실 함수

![스크린샷 2022-07-25 오후 10 17 05](https://user-images.githubusercontent.com/76269316/180786329-422e1111-9584-478b-9a79-b9e705a994f0.png)

절댓값이기 때문에 미분 불가능한 지점이 존재

- 평균 제곱 오차(Mean Square Error)

실제값과 예측값의 수직 거리의 제곱의 평균으로 표현한 손실 함수

![스크린샷 2022-07-25 오후 10 18 03](https://user-images.githubusercontent.com/76269316/180786525-d83d2d88-2f36-42c3-b8ff-4980437bd5e7.png)

모든 점에서 미분 가능, 제곱식이 들어가기 때문에 MAE 보다는 큰 loss 값이 나옴, 이상치가 많은 데이터의 경우 MAE보다 성능이 안 좋을 수도 있음

<img src="https://user-images.githubusercontent.com/76269316/180786924-e0f49bdc-892d-48de-86a1-bbc5da900ac6.png" alt="스크린샷 2022-07-25 오후 10 19 53" style="zoom:67%;" />

<br>

- 평균 제곱근 오차 (Root Mean Square Error)

MSE가 원래 단위를 제곱한 것이기 때문에 loss의 크기를 원래 데이터의 단위와 동일하게 해주기위해 제곱근을 씌운 손실 함수

<br>

**분류(Classification)**

유한한 모임으로 분류되는 문제

- 교차 엔트로피 함수 (Cross Entropy Function)

![스크린샷 2022-07-25 오후 10 28 18](https://user-images.githubusercontent.com/76269316/180788660-e6097073-f67e-4c7e-bda4-e1ff9ede928e.png)

<img src="https://user-images.githubusercontent.com/76269316/180788803-7e3ed4d1-81bb-414d-aa37-e3ec1061606c.png" alt="스크린샷 2022-07-25 오후 10 28 54" style="zoom:67%;" />

- 이진 교차 엔트로피 함수 (Binary Cross Entropy Function)

![스크린샷 2022-07-25 오후 10 29 31](https://user-images.githubusercontent.com/76269316/180788925-2255bf9c-6d5c-4754-a0f3-c32546e1c700.png)

클래스가 두 개이기 때문에 원-핫 벡터로 표현하지 않고 0, 1로 표현 -> 내적이 다음과 같이 간단하게 표현됨

![스크린샷 2022-07-25 오후 10 30 37](https://user-images.githubusercontent.com/76269316/180789180-c50c3876-991d-4cb8-a0a9-2c7048bcd273.png)

✚ 예측시 소프트맥스 대신 시그모이드를 사용해도 됨

<img src="https://user-images.githubusercontent.com/76269316/180789537-579b856d-36e4-4127-833a-2607de0c08a0.png" alt="스크린샷 2022-07-25 오후 10 32 28" style="zoom:80%;" />

<br>

##### 최적화 (Optimization)

<img src="https://user-images.githubusercontent.com/76269316/180997076-74ef1cbb-3227-410f-9b37-f5403358ce69.png" alt="스크린샷 2022-07-26 오후 8 37 59" style="zoom:80%;" />

모델에 입력 데이터를 넣으면 예측값을 출력 -> 예측값과 실제값의 차이를 나타내는 척도가 Loss -> loss 값이 작게 나올수록 예측이 잘되는 것 -> Loss Function을 작게하는 파라미터 w 값을 찾는 것이 목표! (w 초기 값은 임의의 값으로 세팅)

cf) Maximum으로 정의된 Loss Function이 있음 -> 앞에 -를 붙여주면 Minimum Loss Function과 동일해짐

<br>

##### 하강법 (Descent Method)

![image](https://user-images.githubusercontent.com/76269316/180998040-3bed1040-2365-4c4c-9a3f-f9ac06d668e3.png)

![스크린샷 2022-07-26 오후 8 44 37](https://user-images.githubusercontent.com/76269316/180998084-d1e33bb8-faae-43c2-89a5-eb6062ba4a19.png) 👈 이 식을 만족하는 방향으로 이동

- 초기 값에 따라 global minimum을 찾지 못할 수도 있음

<br>

![스크린샷 2022-07-26 오후 8 47 36](https://user-images.githubusercontent.com/76269316/180998624-501fa9d5-85da-4562-bda5-1ea9ef150dfb.png)

a·(-a) < 0이므로 (a가 실수일 때), <img src="https://user-images.githubusercontent.com/76269316/180999104-24ae7683-ad43-419a-92fd-96fad563b1b0.png" alt="스크린샷 2022-07-26 오후 8 50 23" style="zoom:67%;" />

<img src="https://user-images.githubusercontent.com/76269316/180999312-59cebb7b-927c-4ca0-be53-849098a770dd.png" alt="스크린샷 2022-07-26 오후 8 51 26" style="zoom:67%;" />를 치환하면 <img src="https://user-images.githubusercontent.com/76269316/180999269-43db5f22-7828-4004-b0e4-75fa43967e85.png" alt="스크린샷 2022-07-26 오후 8 51 14" style="zoom:67%;" />

<br>

![스크린샷 2022-07-26 오후 8 52 48](https://user-images.githubusercontent.com/76269316/180999543-4ee83108-15dd-425c-830c-8edec3e95d29.png)

<br>

![스크린샷 2022-07-26 오후 8 59 02](https://user-images.githubusercontent.com/76269316/181000696-b6c0efe4-2e42-4728-bba4-f5dc580e948d.png)

<br>

![스크린샷 2022-07-26 오후 8 59 17](https://user-images.githubusercontent.com/76269316/181000736-14c5e138-2fad-4722-a590-0de28aeebf82.png)

<br>

##### 확률적 경사 하강법 (Stochastic Gradient Descent)

<img src="https://user-images.githubusercontent.com/76269316/181000990-369b541e-4a3f-4814-b4f3-9c14cd9abedc.png" alt="스크린샷 2022-07-26 오후 9 00 35" style="zoom:67%;" />

기존 경사하강법은 데이터 전체를 사용하기 때문에 연산량이 많아지는 문제점이 있음

<br>

<img src="https://user-images.githubusercontent.com/76269316/181001144-8caeefc3-551e-4b1b-96cb-47cdd4742244.png" alt="스크린샷 2022-07-26 오후 9 01 40" style="zoom:67%;" />

이를 해결하기 위해 데이터 전체를 미니 배치로 쪼갠 뒤, 무작위로 섞어 사용 -> 미니배치를 사용해서 업데이트를 진행

<br>

학습률이 상수이기 때문에, 유연하게 학습을 진행하기 어려움 -> 모멘텀 기반 / 가변학습률

![스크린샷 2022-07-26 오후 9 04 12](https://user-images.githubusercontent.com/76269316/181001583-dd97e84d-04f9-434f-ad57-a78dc9e195a7.png)

- 모멘텀 기반: <img src="https://user-images.githubusercontent.com/76269316/181001792-9040dcad-dd8e-4014-a224-dacaf5677e40.png" alt="스크린샷 2022-07-26 오후 9 05 41" style="zoom:67%;" />에 탄력에 대한 식 <img src="https://user-images.githubusercontent.com/76269316/181001840-da3d6116-a8ef-4009-becd-579428cf5e9d.png" alt="스크린샷 2022-07-26 오후 9 05 58" style="zoom:67%;" />를 붙여줌 (현재 스텝 속도를 저장했다가 다음 속도를 계산해 그 값을 반영시킴)
- 가변학습률(Adaptive learning rate): 고정된 학습률 대신 가변학습률을 적용
- 모멘텀 + 가변학습률 개념을 합친 방법론 ➡️ Adam

<br>

##### ADAM (Adaptive Moment Estimation)

RMSProp과 Momentum 개념을 합친 방법론

![스크린샷 2022-07-26 오후 9 12 12](https://user-images.githubusercontent.com/76269316/181002936-d8bc1beb-5ee5-458c-8e50-c3ad2f60b540.png)

gradient와 step size에 이전 정보를 기억해서 현재에 반영

<br>

##### Scheduling

스텝 사이즈를 특정 시간에 따라 조절하는 방법론

- StepLR
- ExponentialLR
- Cosine Annealing

<br>

##### Vanishing Gradient

![스크린샷 2022-07-26 오후 9 21 03](https://user-images.githubusercontent.com/76269316/181004431-2a93b47d-ea49-44a8-8bb7-3b6499014c10.png)

가중치는 backpropagation을 통해 업데이트되게 됨

<br>

![스크린샷 2022-07-26 오후 9 21 58](https://user-images.githubusercontent.com/76269316/181004606-417b54a7-8f6c-49cb-b068-1f43b55e9f67.png)

앞서 살펴본 활성함수 중 시그모이드는 미분시 0 ~ 1 사이의 값을 갖게 되는데, backpropagation 과정에서 연쇄 법칙을 통해 계산되면 미분값이 0에 가까워지는 문제점이 생김 -> 가중치가 업데이트 되지 않는 문제가 생김

<br>

![스크린샷 2022-07-26 오후 9 23 50](https://user-images.githubusercontent.com/76269316/181004966-3100e944-24ab-4872-980f-5f7da50f5765.png)

ReLU나 Leaky ReLU에서는 이를 방지할 수 있음

<br>

##### 하강법의 한계

<img src="https://user-images.githubusercontent.com/76269316/181005278-1194ee15-80b8-4939-b8d1-740542807cbe.png" alt="스크린샷 2022-07-26 오후 9 25 47" style="zoom:67%;" />

시작점에 따라 local minimum에 빠질 수 있음 -> 손실함수 설계시 convex function(볼록 함수)으로 설계하는 것이 좋음

[Convex Optimization](http://sanghyukchun.github.io/63/)

<br>

![스크린샷 2022-07-26 오후 9 31 48](https://user-images.githubusercontent.com/76269316/181006393-029cb388-cc19-441f-a185-6061b258684d.png)

concave한 형태는 maximize function -> -를 붙임으로써 minimization으로 변경할 수 있음 (convex로 변경됨)

<br>

##### Convexity

![스크린샷 2022-07-26 오후 9 28 37](https://user-images.githubusercontent.com/76269316/181005824-d8e2dc96-c197-4043-9922-65bf567941c8.png)

<br>

![스크린샷 2022-07-26 오후 9 35 35](https://user-images.githubusercontent.com/76269316/181007081-2eae5e8e-95fd-4aad-83c0-132d52758241.png)

<br>

### 컴퓨터 비전 (Computer Vision)

<img src="https://user-images.githubusercontent.com/76269316/181239867-edbedc25-7ad1-4f56-bbf9-240c5a4c8d7f.png" alt="스크린샷 2022-07-27 오후 8 50 18" style="zoom:80%;" />

이미지 데이터는 RGB 컬러 세 장의 이미지가 겹쳐져 있음 -> 이미지 처리는 3차원 행렬을 계산하는 것❗️

<br>

인공신경망을 사용하기 이전에는 이미지 데이터를 하고자하는 태스크에 맞게 전처리 해줬어야 했음 (아래 예시는 경계 검출을 위한 전처리 과정)

<img src="https://user-images.githubusercontent.com/76269316/181240234-e4f4d2a0-ec78-473c-b601-e37250df71a5.png" alt="스크린샷 2022-07-27 오후 8 52 29" style="zoom:67%;" />

<br>

##### MLP에서의 정보 손실

<img src="https://user-images.githubusercontent.com/76269316/181240614-2dda1c82-9f31-4cf0-95f9-e51a458cf164.png" alt="스크린샷 2022-07-27 오후 8 54 35" style="zoom:80%;" />

MLP에 이미지 데이터를 넣기 위해서는 3차원 벡터를 1차원으로 변환해야 함

<br>

![스크린샷 2022-07-27 오후 8 55 45](https://user-images.githubusercontent.com/76269316/181240825-3122115c-f4ab-44f6-b491-e7e41cf96f11.png)

위 이미지는 모두 1을 표현한 2차원 행렬인데 이를 1차원으로 변환하면 정보의 손실이 발생함

<br>

![스크린샷 2022-07-27 오후 9 01 54](https://user-images.githubusercontent.com/76269316/181242030-0bfacf4f-1533-4b1e-bf8d-55299b34054e.png)

CNN에서는 필터를 이동시키며 정보를 추출함으로써 이러한 문제를 해결함

<br>

##### 합성곱 연산 (Convolutional Operation)

![스크린샷 2022-07-27 오후 9 02 57](https://user-images.githubusercontent.com/76269316/181242204-2cc26905-f5cb-4afe-9da3-e801af283814.png)

필터에 대응되는 이미지 값을 필터값과 곱한 뒤 이를 더함 -> **특징값**

<br>

![스크린샷 2022-07-27 오후 9 04 26](https://user-images.githubusercontent.com/76269316/181242441-009f7ba9-a348-4614-9cad-3f1a1de1a5d1.png)

<br>

✚ 합성곱 연산을 적용한 뒤 활성화 함수(activation function)을 적용시킬 수 있음 (Non-Linear 관계로 만들기 위해)

![스크린샷 2022-07-27 오후 9 23 45](https://user-images.githubusercontent.com/76269316/181245864-f8c88cbc-94ce-43cb-9fad-2fed1faae94c.png)

<br>

필터를 몇 칸씩 이동할 것인지를 **stride**라고 함

![스크린샷 2022-07-27 오후 9 05 09](https://user-images.githubusercontent.com/76269316/181242602-8e92c996-da62-4ab7-9149-4b73b38a1d92.png)

<br>

필터를 거치고 나면 항상 이미지보다 작은 크기의 피처맵(feature map)이 생성되게 되는데 이를 방지하기 위해 padding 값을 줄 수 있음

패딩 값은 일반적으로 0을 넣음 (zero padding)

cf) 패딩값이 0이 아닐 경우, 실제 이미지에는 없는 정보를 패딩이 갖고 있는 것과 같음 -> 컨볼루션 연산이 이루어질 때 쓰레기 값이 들어가게 됨

![스크린샷 2022-07-27 오후 9 06 02](https://user-images.githubusercontent.com/76269316/181242756-f3800b0a-612d-4d03-bf39-b35ac567b1b5.png)

<br>

![스크린샷 2022-07-27 오후 9 10 48](https://user-images.githubusercontent.com/76269316/181243636-5fce0335-3508-477f-a7b3-88b2a15d5d3a.png)

<br>

##### 풀링 연산 (Pooling Operation)

- Max Pooling

필터 영역에서 가장 큰 값을 피처맵으로 사용, 이 때는 필터를 겹쳐서 이동하지 않음❗️

![스크린샷 2022-07-27 오후 9 12 16](https://user-images.githubusercontent.com/76269316/181243843-5bf696c5-3030-4ab1-bf10-40e244c6c73d.png)

- Average Pooling

필터 영역 안에 있는 값들을 평균내 피처맵으로 사용

![스크린샷 2022-07-27 오후 9 13 43](https://user-images.githubusercontent.com/76269316/181244066-27df524f-6db2-4856-8f7f-b73bfc1c795d.png)

<br>

##### 다중 필터 (Multiple Filters)

![스크린샷 2022-07-27 오후 9 15 21](https://user-images.githubusercontent.com/76269316/181244378-fe85d9a8-b376-48db-a5fe-18231cdbc498.png)

필터 하나만 사용해서 이미지의 특징을 모두 추출하기는 어려움 -> 여러 개의 필터를 사용해서 이미지의 특징을 추출

<br>

##### 합성곱 신경망 (Convolutional Neural Network)

![스크린샷 2022-07-27 오후 9 20 13](https://user-images.githubusercontent.com/76269316/181245250-10db7837-fd6a-4530-ae3b-f3186627c1c5.png)

CNN은 피처맵을 생성하는 Feature Extractor와 분류를 진행하는 Classifier로 구성돼 있음

<br>

![스크린샷 2022-07-27 오후 9 24 54](https://user-images.githubusercontent.com/76269316/181246059-97cb7857-87c8-444a-86f4-23103526e9fe.png)

cf) 4차원은 3차원짜리 벡터가 몇 개 있냐로 생각하면 쉬움

<br>

![스크린샷 2022-07-27 오후 9 33 26](https://user-images.githubusercontent.com/76269316/181247555-22ec5329-1795-4772-9cdd-bed4e93cee31.png)

🔼 CNN의 학습 과정 (CNN에서 업데이트하는 값들은 필터, Fully Connected Layer의 가중치, Bias)

<br>

##### CNN 최적화

![스크린샷 2022-07-27 오후 10 14 16](https://user-images.githubusercontent.com/76269316/181255858-34aa7288-6fe0-41b6-9508-7339dfd47aa4.png)

실제 계산은 4차원이기 때문에 훨씬 복잡함, 위 이미지는 필터 일부를 업데이트하는 과정임

<br>

![스크린샷 2022-07-27 오후 10 16 52](https://user-images.githubusercontent.com/76269316/181256394-913682b0-bc97-49ac-98ca-a353b8eecb75.png)
