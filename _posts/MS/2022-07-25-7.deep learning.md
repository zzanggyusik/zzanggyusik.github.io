---
title: "[대학원 면접] 딥러닝 정리"
excerpt: "딥러닝 정리"
toc: true
toc_label: "딥러닝 정리"
toc_sticky: true

categories:
  - MS
tags:
  - 대학원
last_modified_at: 2022-07-25
---

##### 인공신경망의 장점?

전통적인 머신러닝은 모델이 학습을 잘 할 수 있도록, 사람이 데이터를 가공하여 좋은 변수를 만들어야 함

이러한 과정을 피처 엔지니어링이라고 하는데 딥러닝에서는 별도의 가공 없이 데이터를 주더라도 스스로 피처를 학습하는 feature learning 개념을 갖고 있음

사용자가 다양한 구조를 만들 수 있기 때문에 다양한 분야에서 사용 가능

<br>

##### 딥러닝이란?

인공 신경망을 깊게 만들어 모델을 학습시키는 방법

<br>

##### 인공 신경망 (Artificial Neural Network)

![스크린샷 2022-07-25 오후 9 18 12](https://user-images.githubusercontent.com/76269316/180775846-282bf12d-0d90-436a-a5b8-0b45b99ae426.png)

각 층 사이의 계산은 행렬 연산을 통해서 이루어짐

![스크린샷 2022-07-25 오후 9 24 52](https://user-images.githubusercontent.com/76269316/180776845-961b72b3-d910-4ebb-a332-c2e2ea27a107.png)

<br>

##### 활성화 함수 (Activation Function)

<img src="https://user-images.githubusercontent.com/76269316/180777937-c5bc5a7d-bd2b-4d7f-b1d7-5e8c5b291003.png" alt="스크린샷 2022-07-25 오후 9 31 36" style="zoom:67%;" />

인공 신경망은 1차 결합 형태로 돼 있음

👉 미분이 쉬움

👉 계산이 쉬움

하지만 실제 현실 세계에서는 선형적인 관계만 존재하는게 아님 ➡️ **비선형적인 관계를 표현하기 위해 활성화 함수를 사용!**

<img src="https://user-images.githubusercontent.com/76269316/180778606-5a562409-9905-44b8-a10b-4bc6b896e03a.png" alt="스크린샷 2022-07-25 오후 9 35 21" style="zoom:67%;" />

<br>

- 시그모이드 함수

다층의 관계를 비선형적으로 만들어줌, 미분이 가능, 모든 값을 0 ~ 1 사이로 변환

![스크린샷 2022-07-25 오후 9 37 03](https://user-images.githubusercontent.com/76269316/180778894-90136d2c-7c7a-4b6e-8c87-01ac2f15796b.png)

- 하이퍼볼릭 탄젠트

-1 ~ 1 사이의 값을 가짐. 미분 가능, 시그모이드 보다 가파른 기울기를 갖고 있음

![스크린샷 2022-07-25 오후 9 37 27](https://user-images.githubusercontent.com/76269316/180778957-3a740039-a7b4-4a90-8916-f44d29559c3b.png)

- ReLU

음수 값이 들어오면 0으로, 양수 값이 들어오면 그대로 내보냄. (직선 두 개를 합쳤기 때문에 비선형 함수이지만, 선형식의 성질을 갖고 있음 - 계산·미분이 쉬움)

음수 값은 미분시 0, 양수 값은 1, 0일 때는? **미분 불가능**

![스크린샷 2022-07-25 오후 9 38 16](https://user-images.githubusercontent.com/76269316/180779102-e513c7f1-6eb9-4c4c-b528-c918bd44d9f0.png)

❗️Subgradient

0 기준 왼쪽은 미분값이 0, 오른쪽은 1이므로 0에서는 0 ~ 1 사이의 기울기 값을 가짐 👉 미분이 불가능한 지점에서도 구간을 가지고 있다면 일부의 값을 미분값으로 취할 수 있음

<br>

- Leaky ReLU

음수 값도 기울기가 있는 직선으로 대체

![스크린샷 2022-07-25 오후 9 46 21](https://user-images.githubusercontent.com/76269316/180780601-c23217bf-79a7-4b42-944c-0f269191e5f6.png)

- ELU

음수 값을 곡선으로 대체

![스크린샷 2022-07-25 오후 9 47 23](https://user-images.githubusercontent.com/76269316/180780809-be28dda8-a1fb-4b64-b8df-dcc20dabfc4a.png)

- Softmax

모든 입력 값에 대해 0 ~ 1 사이의 값을 가짐. 모든 성분의 합은 항상 1

![스크린샷 2022-07-25 오후 9 50 17](https://user-images.githubusercontent.com/76269316/180781354-9fef2f58-dfe7-45c4-a6a1-5c8f3561d837.png)

분자에 지수 함수를 사용한 이유는 음수 값이 입력으로 들어왔을 때 이를 그대로 사용하면 확률값으로 만들 수 없기 때문 (입력값이 양수든 음수든 항상 0 ~ 1 사이의 값이 나오도록 하는 장치)

<br>

##### XOR 문제 (XOR Problem)

XOR 연산을 퍼셉트론을 가지고 해결할 수 있는가?에 대한 문제

![스크린샷 2022-07-25 오후 9 53 02](https://user-images.githubusercontent.com/76269316/180781847-d1be5ca7-fb2e-4fe1-9570-ad46135014da.png)

<br>

선형적인 관계만 표현할 수 있던 퍼셉트론으로는 해결할 수 없었음

![스크린샷 2022-07-25 오후 10 00 46](https://user-images.githubusercontent.com/76269316/180783299-bc936092-54a5-4fd0-88a6-ae463fb8ccec.png)

<br>

은닉층을 만들어서 해결 👉 MLP 

![스크린샷 2022-07-25 오후 10 02 26](https://user-images.githubusercontent.com/76269316/180783617-5b40abae-9a57-42f1-89df-722e9136757c.png)

<br>

여러 입력값을 전치 행렬(Transpose)을 통해 한 번에 계산할 수 있음

![스크린샷 2022-07-25 오후 10 09 03](https://user-images.githubusercontent.com/76269316/180784893-b2d11090-be98-4b80-a9aa-33b366cb76c0.png)

<br>

##### 손실 함수 (Loss Function)

실제값과 예측값의 차이, 예측이 얼마나 정확한지를 나타내는 척도

<br>

**회귀(Regression)**

결과값이 연속적인 변수인 것을 예측하는 문제

- 평균 절대 오차 (Mean Absolute Error)

실제값과 예측값의 차이(잔차-residual)의 절댓값을 기반으로 한 손실 함수

![스크린샷 2022-07-25 오후 10 17 05](https://user-images.githubusercontent.com/76269316/180786329-422e1111-9584-478b-9a79-b9e705a994f0.png)

절댓값이기 때문에 미분 불가능한 지점이 존재

- 평균 제곱 오차(Mean Square Error)

실제값과 예측값의 수직 거리의 제곱의 평균으로 표현한 손실 함수

![스크린샷 2022-07-25 오후 10 18 03](https://user-images.githubusercontent.com/76269316/180786525-d83d2d88-2f36-42c3-b8ff-4980437bd5e7.png)

모든 점에서 미분 가능, 제곱식이 들어가기 때문에 MAE 보다는 큰 loss 값이 나옴, 이상치가 많은 데이터의 경우 MAE보다 성능이 안 좋을 수도 있음

<img src="https://user-images.githubusercontent.com/76269316/180786924-e0f49bdc-892d-48de-86a1-bbc5da900ac6.png" alt="스크린샷 2022-07-25 오후 10 19 53" style="zoom:67%;" />

<br>

- 평균 제곱근 오차 (Root Mean Square Error)

MSE가 원래 단위를 제곱한 것이기 때문에 loss의 크기를 원래 데이터의 단위와 동일하게 해주기위해 제곱근을 씌운 손실 함수

<br>

**분류(Classification)**

유한한 모임으로 분류되는 문제

- 교차 엔트로피 함수 (Cross Entropy Function)

![스크린샷 2022-07-25 오후 10 28 18](https://user-images.githubusercontent.com/76269316/180788660-e6097073-f67e-4c7e-bda4-e1ff9ede928e.png)

<img src="https://user-images.githubusercontent.com/76269316/180788803-7e3ed4d1-81bb-414d-aa37-e3ec1061606c.png" alt="스크린샷 2022-07-25 오후 10 28 54" style="zoom:67%;" />

- 이진 교차 엔트로피 함수 (Binary Cross Entropy Function)

![스크린샷 2022-07-25 오후 10 29 31](https://user-images.githubusercontent.com/76269316/180788925-2255bf9c-6d5c-4754-a0f3-c32546e1c700.png)

클래스가 두 개이기 때문에 원-핫 벡터로 표현하지 않고 0, 1로 표현 -> 내적이 다음과 같이 간단하게 표현됨

![스크린샷 2022-07-25 오후 10 30 37](https://user-images.githubusercontent.com/76269316/180789180-c50c3876-991d-4cb8-a0a9-2c7048bcd273.png)

✚ 예측시 소프트맥스 대신 시그모이드를 사용해도 됨

<img src="https://user-images.githubusercontent.com/76269316/180789537-579b856d-36e4-4127-833a-2607de0c08a0.png" alt="스크린샷 2022-07-25 오후 10 32 28" style="zoom:80%;" />

<br>
