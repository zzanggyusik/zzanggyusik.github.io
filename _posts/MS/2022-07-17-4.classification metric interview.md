---
title: "[대학원 면접 준비] ML Classification Metric 정리"
excerpt: "분류 평가 지표 정리"
toc: true
toc_label: "ML Classification Metric 정리"
toc_sticky: true

categories:
  - MS
tags:
  - 대학원
last_modified_at: 2022-07-17
---

### 1. 정확도 (Accuracy)

<img src="https://user-images.githubusercontent.com/76269316/124422386-2a595180-dd9e-11eb-9ce0-3e76a6957078.png" alt="image" style="zoom: 80%;" />

정확도는 실제 데이터에서 예측 데이터가 얼마나 같은지를 판단하는 지표입니다.

직관적으로 모델 예측 성능을 평가할 수 있지만, 이진 분류의 경우 데이터 구성에 따라 ML 모델 성능을 왜곡할 수 있기 때문에 여러가지 분류 지표와 함꼐 사용됩니다. (불균형한(imbalanced) 레이블 값 분포에서 ML 모델 성능 평가시 정확도는 적합한 평가 지표가 아님)

<br><br>

### 2. 오차 행렬 (Confusion Matrix)

오차 행렬은 이진 분류의 예측 오류가 얼마인지와 더불어 어떤 유형의 예측 오류가 발생하고 있는지를 함께 나타내는 지표입니다.

다음과 같이 4분면 행렬에서 실제 레이블 클래스 값과 예측 레이블 클래스 값이 어떤 유형을 갖고 매핑되는지를 나타냅니다.

<img src="https://user-images.githubusercontent.com/76269316/124429422-d43ddb80-dda8-11eb-94e7-9862bd0cc5d8.png" alt="image" style="zoom: 67%;" />

앞 문자는 True/False로 예측값과 실제값이 같은지 틀린지를 나타내고, 뒤에 문자는 Negative/Positive로 예측 결과값이 부정(0), 긍정(1)을 의미합니다.

- TN : 예측값을 Negative(0)으로 예측했고 실제값 역시 Negative(0)
- FP : 예측값을 Positive(1)로 예측했는데 실제값은 Negative(0)
- FN : 예측값을 Negative(0)로 예측했는데 실제값은 Positive(1)
- TP : 예측값을 Positive(1)로 예측했고, 실제값 역시 Positive(1)

이 값을 조합해 Classifier 성능을 측정할 수 있는 주요 지표인 정확도 (Accuracy), 정밀도(Precision), 재현율(Recall) 값을 알 수 있습니다.

먼저, 정확도는 예측 결과와 실제 값이 동일한 건수 / 전체 데이터 수였으므로, 다음과 같이 재정의될 수 있습니다.

<img src="https://user-images.githubusercontent.com/76269316/124430538-42cf6900-ddaa-11eb-809f-b24c9098981e.png" alt="image" style="zoom:50%;" />

<br>

일반적으로 불균형한 레이블 클래스를 갖는 이진 분류 모델에서는 많은 데이터 중에서 중점적으로 찾아야 하는 적은 수의 결괏값에 positive를 설정해 1 값을 부여하고, 그렇지 않은 값에 negative로 0으로 부여합니다.

<br>

예를 들어 사기 행위 예측 모델에서는 사기 행위를 postive로 정상 행위를 negative 값으로 할당하고, 암 검진 예측 모델에서는 양성일 경우 positive, 음성일 경우 negative로 할당합니다.

이런 불균형한 이진 분류 데이터 세트에서는 positive 건수가 매우 작으므로 데이터에 기반한 ML 알고리즘은 negative로 예측 정확도가 높아지는 경향(negative로 예측하려는 경향이 강해짐)이 발생합니다.

따라서 TN은 매우 커지고, TP는 매우 작아집니다. 또, negative로 예측할 때 정확도가 높기 때문에 FN 또한 작게되고, positive로 예측하는 경우도 적기 때문에 FP도 작아집니다.

<img src="https://user-images.githubusercontent.com/76269316/124431991-0bfa5280-ddac-11eb-80f1-87a26dfbcf16.png" alt="image" style="zoom: 67%;" />

*빨간색으로 표시한건 증가, 파란색으로 표시한건 감소*

결과적으로 positive에 대한 예측 정확도를 판단하지 못한 상태에서 negative에 대한 예측 정확도만 가지고 높은 정확도가 나타나는 수치적인 판단 오류가 발생하게 되는 것입니다.

<br><br>

### 3. 정밀도, 재현율 (Precision, Recall)

정밀도와 재현율은 postivie 데이터 세트의 예측 성능에 좀 더 초점을 맞춘 평가 지표입니다.

<img src="https://user-images.githubusercontent.com/76269316/124432235-5e3b7380-ddac-11eb-8d50-af9b7e3d2527.png" alt="image" style="zoom:67%;" />

**정밀도는** **예측을 positive로 한 대상 중 예측과 실제 값이 positive로 일치한 데이터의 비율**을 의미합니다.

분모는 예측을 positive로 한 모든 데이터 건수이며, 분자는 예측과 실제 값이 positive로 일치한 데이터 건수입니다.

positive 예측 성능을 더 정밀하게 측정하기 위한 평가 지표로 양성 예측도라고도 불립니다.

<br>

**재현율**은 **실제 값이 positive인 대상 중에 에측과 실제 값이 positive로 일치한 데이터의 비율을** 의미합니다.

분모는 실제 값이 positive인 모든 데이터 건수이고, 분자는 예측과 실제 값이 positive로 일치한 데이터 건수입니다.

민감도(Sensitivity) 또는 TPR(True Positive Rate)이라고도 불립니다.

정밀도와 재현율 중 이진 분류 모델 업무 특성에 따라 특정 지표가 더 중요한 지표로 간주될 수 있습니다.

<br>

- 재현율이 중요 지표인 경우: 실제 positive 데이터를 negative로 잘못 판단하게 되면 업무상 큰 영향이 발생하는 경우

암 판단 모델의 경우 실제 양성(positive)인 암 환자를 음성(negative)으로 잘못 판단할 경우 환자가 목숨을 잃을 수 있기 때문에 재현율이 중요합니다.

✚ 음성인 환자를 양성으로 예측(양성이라고 예측했는데 음성이였음 - FP)해도 재검사를 해야하는 금전적 추가 비용이 따르지만 생명에는 지장이 없으므로 상관이 없는데, 양성인 환자를 음성으로 예측(음성으로 예측했는데 양성이였음 - FN)하면 늦장 대응으로 생명에 지장이 갈 수도 있음

→ FN이 중요 → 재현율 중요

<br>

- 정밀도가 중요 지표인 경우: 실제 negative 데이터를 positive로 잘못 판단하게 되면 업무상 큰 영향이 발생하는 경우

스팸 메일 여부를 판단하는 모델의 경우 실제 스팸 메일(positive)을 일반 메일(negative)로 분류해도 사용자가 불편함을 느낄 뿐이지만, 

일반 메일(negative)을 스팸 메일(positive)로 분류할 경우 만약 업무 관련 메일이였을 경우 업무에 차질이 생기게 됩니다. 

✚ 스팸 메일을 일반 메일로 분류(일반메일이라고 예측했는데 스팸 메일이였음 - FN)해도 상관없지만 일반 메일을 스팸 메일로 분류(스팸 메일이라고 예측했는데 일반 메일이였음 - FP)하면 문제가 생김

→ FP가 중요 → 정밀도 중요

<br>

##### 정밀도/재현율 트레이드 오프

정밀도 또는 재현율을 높이기 위해 분류의 결정 임계값(threshold)을 조정해 정밀도 또는 재현율의 수치를 높일 수 있습니다.

하지만, 정밀도와 재현율은 상호 보완적인 평가 지표이기 때문에 어느 한쪽을 강제로 높이면 다른 하나의  수치는 떨어지게 됩니다.

이를 정밀도/재현율의 트레이드오프(Trade-off)라고 부릅니다.

![image](https://user-images.githubusercontent.com/76269316/179391148-47a58941-893c-4718-a19d-9d6a43ccaa3f.png)

위 그림은 임계값을 변경함에 따라 정밀도와 재현율의 수치가 변한 모습입니다.

이런 변경은 두 개의 수치를 상호 보완할 수 있는 수준에서 적용돼야 하며, 단순히 하나의 성능 지표를 높이기 위한 수단으로 사용돼서는 안됩니다.

<br>

**정밀도를 100%로 만드는 방법**

확실한 기준이 되는 경우만 positive로 예측하고 나머지는 모두 negative로 예측합니다.

![image](https://user-images.githubusercontent.com/76269316/124456282-79ff4380-ddc5-11eb-8694-65fe3658095b.png)

예를 들어, 전체 환자 1000명 중 확실한 positive 징후만 가진 환자가 단 한명이라고 하면 이 한 명만 positive로 예측하고 나머지는 모두 negative로 예측하더라도 FP = 0, TP = 1이 되므로 1/(1+0)이 되서 100%가 되게 됩니다.

<br>

##### 재현율을 100%로 만드는 방법

모든 환자를 positive로 예측합니다.

![image](https://user-images.githubusercontent.com/76269316/124456490-b763d100-ddc5-11eb-8522-bf79791d4cf7.png)

전체 환자 1000명을 다 positive로 예측하면 이 중 실제 양성인 사람이 30명이여도 TN이 수치에 포함되지 않고, FN은 아예 0이므로 30/(30+0)으로 100%가 됩니다.

<br><br>

### 4. F1 스코어 (F1 Score)

F1 스코어는 정밀도와 재현율을 결합한 지표입니다.

F1 스코어는 정밀도와 재현율이 어느 한 쪽으로  치우치지 않는 수치를 나타낼 때 상대적으로 높은 값을 갖습니다.

정밀도와 재현율을 결합한 지표이기 때문에, 결정 임계값을 변경함에 따라 F1 스코어 값도 변화하게 됩니다.

![image](https://user-images.githubusercontent.com/76269316/124457217-8506a380-ddc6-11eb-8396-7f14c9eca630.png)

<br><br>

### 5. ROC 곡선과 AUC

ROC 곡선은 FPR(False Positive Rate)이 변할 때, TPR(True Positive Rate)이 어떻게 변하는 지를 나타내는 곡선입니다. (FPR을 X축으로, TPR을 Y축으로 두고 그린 그래프)

TPR은 재현율을 나타내는데, TPR에 대응하는 지표로는 TNR(True Negative Rate)이라고 불리는 특이성(Specificity)이 있습니다.

- 민감도(TPR) : 실제값 positive가 정확히 예측돼야 하는 수준을 나타냄. (질병이 있는 사람은 질병이 있는 것으로 양성 판정)
- 특이성(TNR) : 실제값 negative가 정확히 예측돼야 하는 수준을 나타냄. (질병이 없는 건강한 사람은 질병이 없는 것으로 음성 판정)

![image](https://user-images.githubusercontent.com/76269316/124475751-09fcb780-dddd-11eb-836d-7210da1f8a9a.png)

<br>

FPR은 FP / (FP + TN)이므로 1 - TNR로 표현할 수 있습니다.

![image](https://user-images.githubusercontent.com/76269316/124476621-0289de00-ddde-11eb-89e3-0144aba6fac2.png)

<br>

![image](https://user-images.githubusercontent.com/76269316/124476999-762beb00-ddde-11eb-8dd1-5ab8e6585307.png)

다음은 ROC 곡선의 예입니다. 가운데 직선은 ROC 곡선의 최저 값으로, 동전을 무작위로 던져 앞/뒤를 맞추는 랜덤 수준의 이진 분류 ROC 직선입니다.

ROC 곡선이 가운데 직선에 가까울수록 성능이 떨어지는 것이며, 멀어질수록 성능이 뛰어난 것입니다.

<br>

ROC 곡선은 FPR을 0부터 1까지 변경하면서 TPR의 변화값을 구합니다.

FPR은 분류 결정 임계값을 변경함으로써 변경할 수 있습니다.

분류 결정 임계값은 positive 예측값을 결정하는 확률의 기준이기 때문에 FPR을 0으로 만들려면 임계값을 1로 지정하면 됩니다.

1로 지정하면 positive 예측 기준이 매우 높아 분류기(Classifier)가 임계값보다 높은 확률을 가진 데이터를 positive로 예측할 수 없게되어 FPR = FP / (FP+TN) 중 FP가 0이되어 FPR이 0이되게 됩니다.

FPR을 1로 만들기 위해서는 분류 결정 임계값을 0으로 만들면 됩니다. 그러면 분류기(Classifier)의 확률 기준이 너무 낮아 모두 positive로 예측하게 되고, negative 예측이 없어 TN이 0이 되게되어 FPR이 1이 됩니다.

<br>

일반적으로 ROC 곡선 자체는 FPR과 TPR의 변화 값을 보는데 사용하며, 분류의 성능 지표로 사용되는 것은 AUC입니다.

AUC(Area Under Curve) 값은 ROC 곡선 밑의 면적을 구한 것으로서 일반적으로 1에 가까울수록 좋은 수치입니다.

AUC 수치가 커지려면 FPR이 작은 상태에서 얼마나 큰 TPR을 얻을 수 있느냐가 관건입니다. 

가운데 직선에서 멀어지고 왼쪽 상단 모서리 쪽으로 가파르게 곡선이 이동할수록 직사각형에 가까운 곡선이 되어 면적이 1에 가까워지게 됩니다.

가운데 대각선 직선은 랜덤 수준(동전 던지기 수준) 이진 분류 AUC 값으로 0.5입니다. 따라서 보통의 분류는 0.5 이상의 AUC 값을 갖습니다.

<br><br>

### 분류 평가 지표 관련 면접 질문

**1. 알고 있는 metric에 대해 설명해주세요**

**2. ROC 커브에 대해 설명해주실 수 있으신가요?**

<br><br>

##### Reference

**면접 질문**

- [AI Tech Interview](https://boostdevs.gitbook.io/ai-tech-interview/)