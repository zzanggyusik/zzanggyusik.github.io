---
title:  "3.Evaluation"
excerpt: "평가"
toc: true
toc_label: "Evaluation"
toc_sticky: true

categories:
  - Machine Learning
tags:
  - Machine Learning
last_modified_at: 2021-07-05

---



>![파이썬 머신러닝 완벽 가이드](https://user-images.githubusercontent.com/76269316/122906446-1fa9c000-d38d-11eb-9cab-1eb7e347a1e6.png)
>
>파이썬 머신러닝 완벽 가이드를 읽고 공부한 내용을 정리한 포스팅입니다.



### 평가

머신러닝은 데이터 가공/변환, 모델 학습/예측, 평가의 프로세스로 구성됩니다.

이전 포스팅 [타이타닉 생존자 예제](https://seominseok4834.github.io/machine%20learning/2.scikit-learn-machine-learning-in-python/#%EC%82%AC%EC%9D%B4%ED%82%B7%EB%9F%B0%EC%9C%BC%EB%A1%9C-%EC%88%98%ED%96%89%ED%95%98%EB%8A%94-%ED%83%80%EC%9D%B4%ED%83%80%EB%8B%89-%EC%83%9D%EC%A1%B4%EC%9E%90-%EC%98%88%EC%B8%A1)에서는 모델 예측 성능 평가를 위해 정확도(Accuracy)를 사용했습니다.



성능 평가 지표(Evaluation Metric)는 일반적으로 모델이 분류냐 회귀냐에 따라 여러 종류로 나뉘는데,

회귀의 경우 대부분 실제값과 예측값의 오차 평균값에 기반하는데 (오차에 절댓값을 씌운 다음 평균 오차를 구하거나, 오차의 제곱값에 루트를 씌운 뒤 평균 오차를 구하는 방법등) 이는 이후 포스팅에서 설명하겠습니다.



이번 포스팅에서는 분류의 성능 평가 지표에 대해  다루도록 하겠습니다.

분류는 결정 클래스 값 종류의 유형에 따라 긍정/부정 2개 결괏값만을 갖는 이진 분류와 여러 개의 결정 클래스 값을 갖는 멀티 분류로 나뉩니다.

아래의 분류 성능 평가 지표는 이진/멀티 분류에 모두 적용할 수 있지만, 특히 이진 분류에서 중요합니다.

왜 이진 분류에서 중요한지 하나씩 설명하도록 하겠습니다.



분류의 성능 평가 지표

- 정확도 (Accuracy)
- 오차행렬 (Confusion Matrix)
- 정밀도 (Precision)
- 재현율 (Recall)
- F1 스코어
- ROC AUC



### 1. 정확도 (Accuracy)

<img src="https://user-images.githubusercontent.com/76269316/124422386-2a595180-dd9e-11eb-9ce0-3e76a6957078.png" alt="image" style="zoom:50%;" />



정확도는 실제 데이터에서 예측 데이터가 얼마나 같은지를 판단하는 지표입니다.

직관적으로 모델 예측 성능을 평가할 수 있지만, 이진 분류의 경우 데이터 구성에 따라 ML 모델 성능을 왜곡할 수 있기 때문에 정확도 하나만 가지고 성능을 평가하진 않습니다.



타이타닉 생존자 예측 모델에서 여자인 경우 무조건 생존한다고 예측하고, 남자인 경우 사망한다고 예측할 경우 정확도를 측정해보겠습니다.



##### transform_features()

데이터 전처리를 위한 함수

```python
from sklearn.preprocessing import LabelEncoder

#Null 처리 함수
def fillna(df):
    df['Age'].fillna(titanic_df['Age'].mean(), inplace=True)
    df['Cabin'].fillna('N', inplace=True)
    df['Embarked'].fillna('N', inplace=True)
    return df

#머신러닝 알고리즘에 불필요한 속성 제거
def drop_features(df):
    df.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)
    return df

#레이블 인코딩 수행
def format_features(df):
    df['Cabin'] = df['Cabin'].str[:1]
    features = ['Cabin', 'Sex', 'Embarked']
    for feature in features:
        le = LabelEncoder()
        le = le.fit(df[feature])
        df[feature] = le.transform(df[feature])
    return df

def transform_features(df):
    df = fillna(df)
    df = drop_features(df)
    df = format_features(df)
    return df
```



##### MyDummyClassifier

사이킷런 BaseEstimator 클래스를 상속받아 아무런 학습을 하지 않고, 성별에 따라 생존자를 예측하는 MyDummyClassifier 생성

```python
import numpy as np
import sklearn
from sklearn.base import BaseEstimator

class MyDummyClassifier(BaseEstimator):
    #fit 메소드는 아무것도 학습하지 않음
    def fit(self, X, y=None):
        pass
    
    #predict() 메소드는 단순히 Sex 피처값이 1이면 0, 0이면1로 예측
    def predict(self, X):
        pred = np.zeros((X.shape[0], 1))  #179X1개의 0으로 초기화된 ndarray 생성
        for i in range(X.shape[0]):
            if X['Sex'].iloc[i] == 1:  #i번째 Sex 피처값이 1이면 0으로 예측
                pred[i] = 0
            else:  #0이면 1로 예측
                pred[i] = 1  
        return pred
```



```python
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

#원본 데이터를 재로딩, 데이터 가공, 학습 데이터/테스트 데이터 분할
titanic_df = pd.read_csv('./titanic_train.csv')
y_titanic_df = titanic_df['Survived']
X_titanic_df = titanic_df.drop('Survived', axis=1)
X_titanic_df = transform_features(X_titanic_df)
X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, test_size=0.2, random_state=0)  #712개의 학습 데이터, 179개의 테스트 데이터

#MyDummyClassifier를 통해 학습/예측/정확도 평가
myclf = MyDummyClassifier()
myclf.fit(X_train, y_train)  #실제로는 아무것도 안함

mypredictions = myclf.predict(X_test)
print('Dummy Classifier 정확도: {0:.4f}'.format(accuracy_score(y_test, mypredictions)))
```

![image](https://user-images.githubusercontent.com/76269316/124424136-7954b600-dda1-11eb-8750-d9d42e6b0721.png)



실행 결과 78.77%의 정확도가 나왔습니다.

이렇게 단순한 알고리즘으로 예측하더라도, 데이터 구성에 따라 이렇게 높은 수치가 나올 수 있기 때문에 정확도를 평가 지표로 사용할 경우 조심해야합니다. (불균형한(imbalanced) 레이블 값 분포에서 ML 모델 성능 평가시 정확도는 적합한 평가 지표가 아님)



이번에는 MNIST 데이터 세트를 변한해 불균형한 데이터 세트로 만든 다음, 정확도를 측정해보겠습니다.

MNIST 데이터 세트는 0부터 9까지 숫자 이미지의 픽셀 정보를 갖고 있으며, 이를 기반으로 숫자 digit를 예측하는데 사용됩니다.

따라서 0부터 9까지의 멀티 label 값을 갖는데, 이것을 7만 true로하고 나머지 값은 모두 false로 변환해 이진 분류 문제로 바꾸겠습니다.

![image](https://user-images.githubusercontent.com/76269316/124425364-6511b880-dda3-11eb-9203-f19bfcce9ecd.png)



MNIST 데이터 세트의 label 분포를 보면

```python
import pandas as pd
import sklearn
from sklearn.datasets import load_digits

digits = load_digits()

digits_df = pd.DataFrame(data=digits, columns=digits.feature_names)
digits_df['label'] = digits.target
digits_df['label'].value_counts()
```

![image](https://user-images.githubusercontent.com/76269316/124428246-6b099880-dda7-11eb-89e4-ba71da6234ff.png)

7이 179개이고, 7을 제외한 나머지 숫자들이1618개입니다.

저희는 이 중 label 값이 7인 것들만 1로 변환하고 나머지는 0으로 변환하겠습니다.



##### MyFakeClassifier

```python
import numpy as np
import pandas as pd
import sklearn
from sklearn.datasets import load_digits
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.base import BaseEstimator

class MyFakeClassifier(BaseEstimator):
    def fit(self, X, y):  #fit 메소드는 아무것도 학습하지 않음
        pass
    
    #입력값으로 들어오는 X 데이터 세트의 크기만큼 모두 0 값으로 만들어서 반환 (전부 0으로 예측)
    def predict(self, X):
        return np.zeros((len(X), 1), dtype=bool)
    
#사이킷런 내장 데이터 세트인 load_digits()를 이용해 MNIST 데이터 로딩
digits = load_digits()

#digits 번호가 7이면 True이고 이를 astype(int)로 변환, 7이 아니면 False이고 0으로 변환
y = (digits.target == 7).astype(int)
print('0과 1의 분포도')
print(pd.Series(y).value_counts())
X_train, X_test, y_train, y_test = train_test_split(digits.data, y, random_state=11)
```

![image](https://user-images.githubusercontent.com/76269316/124428072-2e3da180-dda7-11eb-85b4-331323c54515.png)



다음과 같이 0이 1618개, 1이 179개인 이진 label로 변환 됐습니다.

이 데이터 세트를 가지고 MyFakeClassifier를 사용해 전부 다 0으로 예측한 다음, 정확도를 측정해보겠습니다.



```python
#불균형한 레이블 데이터 분포도 확인
print('레이블 테스트 세트 크기: ', y_test.shape)
print('테스트 세트 레이블 0과 1의 분포도')
print(pd.Series(y_test).value_counts())

#MyFakeClassifier로 학습/예측/정확도 평가
fakeclf = MyFakeClassifier()
fakeclf.fit(X_train, y_train)
fakepred = fakeclf.predict(X_test)
print('모든 예측을 0으로 해도 정확도는: {0:.3f}'.format(accuracy_score(y_test, fakepred)))
```

![image](https://user-images.githubusercontent.com/76269316/124428479-bc198c80-dda7-11eb-98b9-de19689ea67e.png)



모두 0으로 예측했음에도 불구하고 예측 정확도가 90%라는 높은 결과가 나왔습니다. 

이처럼 정확도 평가 지표는 불균형한 레이블 데이터 세트에서는 성능 수치로 사용돼서는 안 됩니다.

이러한 정확도의 한계점을 극복하기 위해서는 여러 가지 분류 지표와 함께 사용돼야 합니다.



### 오차 행렬 (Confusion Matrix)

오차 행렬은 이진 분류의 예측 오류가 얼마인지와 더불어 어떤 유형의 예측 오류가 발생하고 있는지를 함께 나타내는 지표입니다.

다음과 같이 4분면 행렬에서 실제 레이블 클래스 값과 예측 레이블 클래스 값이 어떤 유형을 갖고 매핑되는지를 나타냅니다.

<img src="https://user-images.githubusercontent.com/76269316/124429422-d43ddb80-dda8-11eb-94e7-9862bd0cc5d8.png" alt="image" style="zoom: 67%;" />



앞 문자는 True/False로 예측값과 실제값이 같은지 틀린지를 나타내고, 뒤에 문자는 Negative/Positive로 예측 결과값이 부정(0), 긍정(1)을 의미합니다.



- TN : 예측값을 Negative(0)으로 예측했고 실제값 역시 Negative(0)
- FP : 예측값을 Positive(1)로 예측했는데 실제값은 Negative(0)
- FN : 예측값을 Negative(0)로 예측했는데 실제값은 Positive(1)
- TP : 예측값을 Positive(1)로 예측했고, 실제값 역시 Positive(1)



사이킷런은 오차 행렬을 구하기 위해 confusion_matrix() API를 제공합니다.

```python
from sklearn.metrics import confusion_matrix

confusion_matrix(y_test, fakepred)
```

![image](https://user-images.githubusercontent.com/76269316/124429914-7231a600-dda9-11eb-9d14-5b684ac94f60.png)



array[0, 0], array[0, 1], array[1,0], array[1,1]은 차례대로 TN, FP, FN, TP를 의미합니다.

위 결과에 따르면 TN은 405 (전체 450건 데이터 중 negative로 예측해서 true가 된 결과 405건), FN은 45 (전체 450건 데이터 중 negative로 예측해서 false가 된 결과 45건) 입니다.

전부 negative로 예측했기 때문에 FP, TP가 0인 것을 확인할 수 있습니다.



이 값을 조합해 Classifier 성능을 측정할 수 있는 주요 지표인 정확도 (Accuracy), 정밀도(Precision), 재현율(Recall) 값을 알 수 있습니다.



먼저, 정확도는 예측 결과와 실제 값이 동일한 건수 / 전체 데이터 수였으므로, 다음과 같이 재정의될 수 있습니다.

<img src="https://user-images.githubusercontent.com/76269316/124430538-42cf6900-ddaa-11eb-809f-b24c9098981e.png" alt="image" style="zoom:50%;" />



일반적으로 불균형한 레이블 클래스를 갖는 이진 분류 모델에서는 많은 데이터 중에서 중점적으로 찾아야 하는 적은 수의 결괏값에 positive를 설정해 1 값을 부여하고, 그렇지 않은 값에 negative로 0을 부여합니다.



예를 들어 사기 행위 예측 모델에서는 사기 행위를 postive로 정상 행위를 negative 값으로 할당하고, 암 검진 예측 모델에서는 양성일 경우 positive, 음성일 경우 negative로 할당합니다.



이런 불균형한 이진 분류 데이터 세트에서는 positive 건수가 매우 작으므로 데이터에 기반한 ML 알고리즘은 negative로 예측 정확도가 높아지는 경향(negative로 예측하려는 경향이 강해짐)이 발생합니다.

따라서 TN은 매우 커지고, TP는 매우 작아집니다. 또, negative로 예측할 때 정확도가 높기 때문에 FN 또한 작게되고, positive로 예측하는 경우도 적기 때문에 FP도 작아집니다.

<img src="https://user-images.githubusercontent.com/76269316/124431991-0bfa5280-ddac-11eb-80f1-87a26dfbcf16.png" alt="image" style="zoom: 67%;" />

*빨간색으로 표시한건 증가, 파란색으로 표시한건 감소*



결과적으로 positive에 대한 예측 정확도를 판단하지 못한 상태에서 negative에 대한 예측 정확도만 가지고 높은 정확도가 나타나는 수치적인 판단 오류가 발생하게 됩니다.



### 정밀도와 재현율 (Precision, Recall)

정밀도와 재현율은 postivie 데이터 세트의 예측 성능에 좀 더 초점을 맞춘 평가 지표입니다.

바로 위 MyFakeClassifier는 positive로 예측한 값이 하나도 없으므로 정밀도와 재현율 값이 모두 0입니다.



<img src="https://user-images.githubusercontent.com/76269316/124432235-5e3b7380-ddac-11eb-8d50-af9b7e3d2527.png" alt="image" style="zoom:67%;" />

**정밀도**는 예측을 positive로 한 대상 중 예측과 실제 값이 positive로 일치한 데이터의 비율을 의미합니다.

분모는 예측을 positive로 한 모든 데이터 건수이며, 분자는 예측과 실제 값이 positive로 일치한 데이터 건수입니다.

positive 예측 성능을 더 정밀하게 측정하기 위한 평가 지표로 양성 예측도라고도 불립니다.



**재현율**은 실제 값이 positive인 대상 중에 에측과 실제 값이 positive로 일치한 데이터의 비율을 의미합니다.

분모는 실제 값이 positive인 모든 데이터 건수이고, 분자는 예측과 실제 값이 positive로 일치한 데이터 건수입니다.

민감도(Sensitivity) 또는 TPR(True Positive Rate)이라고도 불립니다.



정밀도와 재현율 중 이진 분류 모델 업무 특성에 따라 특정 지표가 더 중요한 지표로 간주될 수 있습니다.



재현율이 중요 지표인 경우는 실제 positive 데이터를 negative로 잘못 판단하게 되면 업무상 큰 영향이 발생하는 경우입니다.

예를 들어 암 판단 모델의 경우 실제 양성(positive)인 암 환자를 음성(negative)으로 잘못 판단할 경우 환자가 목숨을 잃을 수 있기 때문에 재현율이 중요합니다.

+음성인 환자를 양성으로 예측(양성이라고 예측했는데 음성이였음 - FP)해도 재검사를 해야하는 금전적 추가 비용이 따르지만 생명에는 지장이 없으므로 상관이 없는데, 양성인 환자를 음성으로 예측(음성으로 예측했는데 양성이였음 - FN)하면 늦장 대응으로 생명에 지장이 갈 수도 있음

→ FN이 중요 → 재현율 중요



정밀도가 중요 지표인 경우는 실제 negative 데이터를 positive로 잘못 판단하게 되면 업무상 큰 영향이 발생하는 경우입니다.

스팸 메일 여부를 판단하는 모델의 경우 실제 스팸 메일(positive)을 일반 메일(negative)로 분류해도 사용자가 불편함을 느낄 뿐이지만, 

일반 메일(negative)을 스팸 메일(positive)로 분류할 경우 만약 업무 관련 메일이였을 경우 업무에 차질이 생기게 됩니다. 

+스팸 메일을 일반 메일로 분류(일반메일이라고 예측했는데 스팸 메일이였음 - FN)해도 상관없지만 일반 메일을 스팸 메일로 분류(스팸 메일이라고 예측했는데 일반 메일이였음 - FP)하면 문제가 생김

→ FP가 중요 → 정밀도 중요



따라서 스팸 메일 여부 판단 모델의 경우에는 정밀도가 중요합니다.



타이타닉 생존자 예측 모델에서의 오차 행렬, 정확도, 정밀도, 재현율을 구해보겠습니다.



##### transform_features()

데이터 전처리를 위한 함수

```python
from sklearn.preprocessing import LabelEncoder

#Null 처리 함수
def fillna(df):
    df['Age'].fillna(titanic_df['Age'].mean(), inplace=True)
    df['Cabin'].fillna('N', inplace=True)
    df['Embarked'].fillna('N', inplace=True)
    return df

#머신러닝 알고리즘에 불필요한 속성 제거
def drop_features(df):
    df.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)
    return df

#레이블 인코딩 수행
def format_features(df):
    df['Cabin'] = df['Cabin'].str[:1]
    features = ['Cabin', 'Sex', 'Embarked']
    for feature in features:
        le = LabelEncoder()
        le = le.fit(df[feature])
        df[feature] = le.transform(df[feature])
    return df

def transform_features(df):
    df = fillna(df)
    df = drop_features(df)
    df = format_features(df)
    return df
```



##### get_clf_eval()

오차 행렬, 정확도, 정밀도, 재현율을 한 번에 계산하기 위한 함수

```python
import sklearn
from sklearn.metrics import accuracy_score, precision_score,recall_score, confusion_matrix

def get_clf_eval(y_test, pred):
    confusion = confusion_matrix(y_test, pred)
    accuracy = accuracy_score(y_test, pred)
    precision = precision_score(y_test, pred)
    recall = recall_score(y_test, pred)
    print('오차 행렬')
    print(confusion)
    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}'.format(accuracy, precision, recall))
```



```python
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression

#원본 데이터를 재로딩, 데이터 가공, 학습 데이터/테스트 데이터 분할
titanic_df = pd.read_csv('./titanic_train.csv')
y_titanic_df = titanic_df['Survived']
X_titanic_df = titanic_df.drop('Survived', axis=1)
X_titanic_df = transform_features(X_titanic_df)

X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, test_size=0.2, random_state=11)  #712개의 학습 데이터, 179개의 테스트 데이터

lr_clf = LogisticRegression()

lr_clf.fit(X_train, y_train)
pred = lr_clf.predict(X_test)
get_clf_eval(y_test, pred)
```

![image](https://user-images.githubusercontent.com/76269316/124438544-474c4f80-ddb3-11eb-9698-25b208b813f9.png)



다음과 같이 정밀도가 재현율에 비해 낮게 나왔습니다. 정밀도(또는 재현율)를 강화하는 방법에 대해 알아보도록 하겠습니다.



##### 정밀도/재현율 트레이드오프

정밀도 또는 재현율을 높이기 위해 분류의 결정 임계값(threshold)을 조정해 정밀도 또는 재현율의 수치를 높일 수 있습니다.

하지만, 정밀도와 재현율은 상호 보완적인 평가 지표이기 때문에 어느 한쪽을 강제로 높이면 다른 하나의  수치는 떨어지게 됩니다.

이를 정밀도/재현율의 트레이드오프(Trade-off)라고 부릅니다.